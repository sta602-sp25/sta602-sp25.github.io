[
  {
    "objectID": "notes/waterOnMars.html",
    "href": "notes/waterOnMars.html",
    "title": "Water on Mars",
    "section": "",
    "text": "load libraries\nlibrary(truncnorm)\nlibrary(tidyverse)\nlibrary(coda)"
  },
  {
    "objectID": "notes/waterOnMars.html#bayesian-inverse-problems",
    "href": "notes/waterOnMars.html#bayesian-inverse-problems",
    "title": "Water on Mars",
    "section": "Bayesian inverse problems",
    "text": "Bayesian inverse problems\nIdea: writing the likelihood is difficult or impossible in closed form.\nAs usual, we wish to estimate some parameter vector \\(\\theta\\). However, \\(\\theta\\) relates to our observations \\(y\\) via some function \\(y = f(\\theta)\\). The catch is, we cannot write \\(f(\\theta)\\) directly, nor compute it exactly. Most often, all we can do is simulate from \\(f(\\theta)\\)."
  },
  {
    "objectID": "notes/waterOnMars.html#example-liquid-water-in-the-martian-mid-crust-1",
    "href": "notes/waterOnMars.html#example-liquid-water-in-the-martian-mid-crust-1",
    "title": "Water on Mars",
    "section": "Example: Liquid water in the Martian mid-crust 1",
    "text": "Example: Liquid water in the Martian mid-crust 1\n\n\n\nInSight. Photo credit: NASA. Image retrieved from https://science.nasa.gov/mission/insight/\n\n\nThe Interior Exploration using Seismic Investigations, Geodesy and Heat Transport (InSight) mission from NASA sent a robotic lander to Mars on May 5, 2018. The goal of the mission, which ended December 2022, was to study the crust, mantle and core of Mars.\n\nData\nWatch the video here to see the data that InSight collects from earthquakes on Mars.\n\nseismic_data = data.frame(y = c(4.1, 2.5, 2589),\n                          sd = c(0.2, 0.3, 157))\n\n\n\nParameter Table\nHere our parameter vector \\(\\theta = (\\alpha, \\phi, \\gamma_w, \\kappa_m, \\mu_m, \\rho_m)\\). These parameters describe the medium through which the earthquake waves propagate.\n\n\n\nSymbol in paper\nCode\nDefinition\n\n\n\n\n\\(\\alpha\\)\ntheta[1]\nPore shape aspect ratio\n\n\n\\(\\phi\\)\ntheta[2]\nPorosity\n\n\n\\(\\gamma_w\\)\ntheta[3]\nWater saturation (%)\n\n\n\\(\\kappa_m\\)\ntheta[4]\nMineral bulk modulus (GPa)\n\n\n\\(\\mu_m\\)\ntheta[5]\nMineral shear modulus (GPa)\n\n\n\\(\\rho_m\\)\ntheta[6]\nMineral density (kg/m\\(^3\\))\n\n\n\n\n\nBerryman self-consistent rock physics model\nThe function \\(f(\\theta)\\) that forward simulates data given our set of parameters is myBerry in the code below. This function serves as a wrapper to the berry_scm function, also defined below. Functions are translated into R from original MATLAB code by Wright, Morzfeld and Manga from the paper and publicly available on GitHub. 2\n\n\nShow Berryman functions\nberry_scm &lt;- function(k, mu, asp, x, ro1, P_water) {\n  # BERRYSCM - Effective elastic moduli for multi-component composite\n  # using Berryman's Self-Consistent (Coherent Potential Approximation) method.\n  # \n  # Arguments:\n  # k: Bulk moduli of the N constituent phases (numeric vector)\n  # mu: Shear moduli of the N constituent phases (numeric vector)\n  # asp: Aspect ratio for the inclusions of the N phases (numeric vector)\n  # x: Fraction of each phase. Solid, then fluid phase (numeric vector)\n  # ro1: Density of the original rock (numeric scalar)\n  # P_water: Proportion of water (numeric scalar)\n  #\n  # Returns:\n  # kbr: Effective bulk modulus (numeric scalar)\n  # mubr: Effective shear modulus (numeric scalar)\n  # vp: P-wave velocity (numeric scalar)\n  # vs: S-wave velocity (numeric scalar)\n  # ro2: Final rock density after fluid substitution (numeric scalar)\n  # k2: Rock bulk modulus after fluid substitution (numeric scalar)\n  \n  # Ensure inputs are column vectors (equivalent to MATLAB's k(:), mu(:), etc.)\n  k &lt;- as.vector(k)\n  mu &lt;- as.vector(mu)\n  asp &lt;- as.vector(asp)\n  x &lt;- as.vector(x)\n  \n  # Modify aspect ratios of inclusions that are equal to 1\n  asp[asp == 1] &lt;- 0.99\n  \n  # Initialize variables\n  theta &lt;- numeric(length(asp))\n  fn &lt;- numeric(length(asp))\n  \n  # Compute theta and fn for oblate and prolate spheroids\n  obdx &lt;- which(asp &lt; 1)\n  prdx &lt;- which(asp &gt; 1)\n  \n  theta[obdx] &lt;- (asp[obdx] / ((1 - asp[obdx]^2)^(3/2))) * (acos(asp[obdx]) - asp[obdx] * sqrt(1 - asp[obdx]^2))\n  fn[obdx] &lt;- (asp[obdx]^2 / (1 - asp[obdx]^2)) * (3 * theta[obdx] - 2)\n  \n  theta[prdx] &lt;- (asp[prdx] / ((asp[prdx]^2 - 1)^(3/2))) * (asp[prdx] * sqrt(asp[prdx]^2 - 1) - acosh(asp[prdx]))\n  fn[prdx] &lt;- (asp[prdx]^2 / (asp[prdx]^2 - 1)) * (2 - 3 * theta[prdx])\n  \n  # Initialize initial bulk and shear moduli\n  ksc &lt;- sum(k * x)\n  musc &lt;- sum(mu * x)\n  \n  # Initialize iteration parameters\n  knew &lt;- 0\n  tol &lt;- 1e-6 * k[1]\n  del &lt;- abs(ksc - knew)\n  niter &lt;- 0\n  \n  # Iterative solution for effective moduli\n  while (del &gt; abs(tol) && niter &lt; 3000) {\n    nusc &lt;- (3 * ksc - 2 * musc) / (2 * (3 * ksc + musc))\n    a &lt;- mu / musc - 1\n    b &lt;- (1 / 3) * (k / ksc - mu / musc)\n    r &lt;- (1 - 2 * nusc) / (2 * (1 - nusc))\n    \n    f1 &lt;- 1 + a * ((3 / 2) * (fn + theta) - r * ((3 / 2) * fn + (5 / 2) * theta - (4 / 3)))\n    f2 &lt;- 1 + a * (1 + (3 / 2) * (fn + theta) - (r / 2) * (3 * fn + 5 * theta)) + b * (3 - 4 * r)\n    f2 &lt;- f2 + (a / 2) * (a + 3 * b) * (3 - 4 * r) * (fn + theta - r * (fn - theta + 2 * theta^2))\n    f3 &lt;- 1 + a * (1 - (fn + (3 / 2) * theta) + r * (fn + theta))\n    f4 &lt;- 1 + (a / 4) * (fn + 3 * theta - r * (fn - theta))\n    f5 &lt;- a * (-fn + r * (fn + theta - (4 / 3))) + b * theta * (3 - 4 * r)\n    f6 &lt;- 1 + a * (1 + fn - r * (fn + theta)) + b * (1 - theta) * (3 - 4 * r)\n    f7 &lt;- 2 + (a / 4) * (3 * fn + 9 * theta - r * (3 * fn + 5 * theta)) + b * theta * (3 - 4 * r)\n    f8 &lt;- a * (1 - 2 * r + (fn / 2) * (r - 1) + (theta / 2) * (5 * r - 3)) + b * (1 - theta) * (3 - 4 * r)\n    f9 &lt;- a * ((r - 1) * fn - r * theta) + b * theta * (3 - 4 * r)\n    \n    p &lt;- 3 * f1 / f2\n    q &lt;- (2 / f3) + (1 / f4) + ((f4 * f5 + f6 * f7 - f8 * f9) / (f2 * f4))\n    \n    p &lt;- p / 3\n    q &lt;- q / 5\n    \n    # Update moduli\n    knew &lt;- sum(x * k * p) / sum(x * p)\n    munew &lt;- sum(x * mu * q) / sum(x * q)\n    \n    del &lt;- abs(ksc - knew)\n    ksc &lt;- knew\n    musc &lt;- munew\n    niter &lt;- niter + 1\n  }\n  \n  kbr &lt;- ksc\n  mubr &lt;- musc\n  \n  # Density and fluid substitution\n  rofl1 &lt;- 0.020    # density of gas\n  kfl1 &lt;- 0         # bulk modulus of gas\n  ro_water &lt;- 1000   # density of water\n  k_water &lt;- 2.2e9  # bulk modulus of water\n  P_gas &lt;- 1 - P_water\n  rofl2 &lt;- P_gas * rofl1 + P_water * ro_water\n  kfl2 &lt;- P_gas * kfl1 + P_water * k_water\n  k0 &lt;- k[1]        # bulk modulus of solid mineral phase\n  phi &lt;- x[2]       # porosity of rock\n  k1 &lt;- kbr         # dry bulk modulus\n  \n  # Perform fluid substitution using Gassmann equation\n  a &lt;- k1 / (k0 - k1) - kfl1 / (phi * (k0 - kfl1)) + kfl2 / (phi * (k0 - kfl2))\n  k2 &lt;- k0 * a / (1 + a)   # bulk modulus after fluid substitution\n  \n  # Compute final density after fluid substitution\n  ro2 &lt;- ro1 - phi * rofl1 + phi * rofl2\n  \n  # Compute seismic velocities after fluid substitution\n  mu2 &lt;- mubr\n  vp &lt;- sqrt((k2 + (4 / 3) * mu2) / ro2)\n  vs &lt;- sqrt(mu2 / ro2)\n  \n  return(list(kbr = kbr, mubr = mubr, vp = vp, vs = vs, ro2 = ro2, k2 = k2))\n}\n\nmyBerry &lt;- function(theta, H = 3) {\n  # Extract parameters from theta\n  asp &lt;- c(1, theta[1])   # Aspect ratio\n  x_phi &lt;- theta[2]       # Proportion of fluid (phi)\n  rock_vol &lt;- 1 - theta[2] # Volume of solid phase (rock)\n  x &lt;- c(rock_vol, x_phi)  # Fraction of phases\n  rock_density &lt;- theta[6] * rock_vol  # Density of solid phase (basalt)\n  gas_density &lt;- 0.020 * x_phi         # Density of fluid phase (gas)\n  rhob1 &lt;- rock_density + gas_density  # Bulk density\n  \n  # Percentage of water in pore space\n  P_water &lt;- theta[3]\n  \n  # Bulk and shear moduli (scaled by 1e9 as per MATLAB code)\n  k &lt;- c(theta[4] * 1e9, 0)  # Bulk modulus (first element)\n  mu &lt;- c(theta[5] * 1e9, 0) # Shear modulus (first element)\n  \n  # Call berryscm function (ensure berryscm function is defined in your R environment)\n  result &lt;- berry_scm(k, mu, asp, x, rhob1, P_water)\n  \n  # Return the required output from berryscm\n  return(result)\n}\n\n\n\n\nLikelihood and prior\n\nExercise\n\n\nWhy does a normal likelihood make sense?\n\nWhat priors are chosen for each unknown?"
  },
  {
    "objectID": "notes/waterOnMars.html#inference",
    "href": "notes/waterOnMars.html#inference",
    "title": "Water on Mars",
    "section": "Inference",
    "text": "Inference\n\nMCMC CodeDiagnosticsMarginal posteriorsResults\n\n\n\n\nCode\nset.seed(360)\ndtruncnormL = function(x, a, b, mean, sd) {\n  log(dtruncnorm(x, a=a, b=b, mean = mean, sd = sd))\n}\n\nrcnorm&lt;-function(n, mean=0, sd=1, a=-Inf, b=Inf){\n  u = runif(n, pnorm((a - mean) / sd), pnorm((b - mean) / sd))\n  mean + (sd * qnorm(u))\n}\n\nlogPosterior = function(theta) {\n  result = myBerry(theta)\n  y = c(result$vp / 1000, result$vs / 1000, result$ro2)\n  if(result$vp &lt; result$vs) {\n    return(-Inf)\n  }\n  else{\n  return(\n    sum(dnorm(y, mean = seismic_data$y, sd = seismic_data$sd,\n            log = TRUE))\n  )\n  }\n}\n\n# THETA[1] = alpha\n# THETA[2] = porosity\n# THETA[3] = saturation\n# THETA[4] = kappa_m\n# THETA[5] = mu_m\n# THETA[6] = rho_m\n\n# starting point\nalpha = 0.5\nporosity = 0.25 #runif(1, 0.05, 0.50)\nsaturation = 0.05 #0 to 1\nkappa_m = 78\nmu_m = 33\nrhom = 3000\ntheta = c(alpha, porosity, saturation, kappa_m, mu_m, rhom)\n\n# prior\n## indicator that parameters are in proper ranges * constant * indicator that Vp &gt; Vs\n\n# MCMC \nS = 50000\naccept = rep(0, length(theta))\n\nTHETA = NULL\nfor(i in 1:S) {\n  thetaStar = theta \n  thetaStar[1] = rcnorm(1, mean = theta[1], sd = .05,\n                        a = 0.03, b = 0.99)\n   log.r = logPosterior(thetaStar) + \n     dtruncnormL(theta[1], \n                a=0.03, b=0.99, \n                mean = thetaStar[1], sd = .05) - \n     logPosterior(theta) - \n     dtruncnormL(thetaStar[1], \n                a=0.03, b=0.99, \n                mean = theta[1], sd = .05)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[1] = accept[1] + 1 \n   }\n  \n  thetaStar = theta\n  thetaStar[2] = rcnorm(1, mean = theta[2], sd = .05,\n                        a = 0.05, b = 0.5)\n  log.r = logPosterior(thetaStar) +\n    dtruncnormL(thetaStar[2], \n                a=0.05, b=0.5, \n                mean = theta[2], sd = .05) - \n     logPosterior(theta) - \n      dtruncnormL(thetaStar[2], \n                a=0.05, b=0.5, \n                mean = theta[2], sd = .05)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[2] = accept[2] + 1 \n   }\n  \n  thetaStar = theta\n  thetaStar[3] = rcnorm(1, mean = theta[3], sd = 0.05,\n                        a = 0, b = 1)\n  \n  log.r = logPosterior(thetaStar) +\n    dtruncnormL(thetaStar[3], \n                a=0, b=1, \n                mean = theta[3], sd = 0.05) - \n     logPosterior(theta) - \n    dtruncnormL(thetaStar[3], \n                a=0, b=1, \n                mean = theta[3], sd = 0.05)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[3] = accept[3] + 1 \n   }\n  \n  thetaStar = theta\n  thetaStar[4] = rcnorm(1, mean = theta[4], sd = .5,\n                        a = 76.5, b = 80)\n  \n  log.r = logPosterior(thetaStar) +\n    dtruncnormL(thetaStar[4], \n                a=76.5, b=80, \n                mean = theta[4], sd = .5) - \n     logPosterior(theta) -\n    dtruncnormL(thetaStar[4], \n                a=76.5, b=80, \n                mean = theta[4], sd = .5)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[4] = accept[4] + 1 \n   }\n  \n  thetaStar = theta\n  thetaStar[5] = rcnorm(1, mean = theta[5], sd = 1,\n                        a = 25.6, b = 40)\n  \n  log.r = logPosterior(thetaStar) +\n    dtruncnormL(thetaStar[5], \n                a=25.6, b=40, \n                mean = theta[5], sd = 1) - \n     logPosterior(theta) -\n    dtruncnormL(thetaStar[5], \n                a=25.6, b=40, \n                mean = theta[5], sd = 1)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[5] = accept[5] + 1 \n   }\n  \n  thetaStar = theta\n  thetaStar[6] = rcnorm(1, mean = theta[6], sd = 20,\n                        a = 2689, b = 2900)\n  \n   log.r = logPosterior(thetaStar) +\n    dtruncnormL(thetaStar[6], \n                a=2689, b=2900, \n                mean = theta[6], sd = 20) - \n     logPosterior(theta) -\n    dtruncnormL(thetaStar[6], \n                a=2689, b=2900, \n                mean = theta[6], sd = 20)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    theta = thetaStar\n    accept[6] = accept[6] + 1 \n   }\n  \n   THETA = rbind(THETA, theta)\n}\n\n\n\n\n\n\nCode\nN = nrow(THETA)\nTHETA = THETA %&gt;%\n  mutate(iteration = seq(1,N))\n\nTHETA %&gt;%\n  filter(iteration &gt; 30000) %&gt;%\n  pivot_longer(cols = 1:6) %&gt;%\n  ggplot(aes(x = iteration, y = value)) +\n  geom_line() +\n  facet_wrap(~ name, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nTHETA %&gt;%\n  filter(iteration &gt; 20000) %&gt;%\n  pivot_longer(cols = 1:6) %&gt;%\n  ggplot(aes(x = value)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.5) +\n  geom_density() +\n  facet_wrap(~ name, scales = \"free\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(knitr)\n# posterior means of parameters\nposteriorMeans = \n  THETA %&gt;%\n  select(-iteration) %&gt;%\n  colMeans()\n\nposteriorMeans %&gt;% \n  kable(col.names = c(\"parameter\", \"posteriorMean\"))\n\n\n\n\n\nparameter\nposteriorMean\n\n\n\n\ntheta1\n0.2083255\n\n\ntheta2\n0.1831104\n\n\ntheta3\n0.5988736\n\n\ntheta4\n78.2017496\n\n\ntheta5\n31.7572690\n\n\ntheta6\n2816.4036103\n\n\n\n\n\n\n\nCode\n# generating data from posterior means \nresult = myBerry(posteriorMeans)\ndataFromPostMean = c(result$vp / 1000, result$vs / 1000, result$ro2)\nrbind(dataFromPostMean, seismic_data$y) %&gt;%\n  kable(col.names = c(\"Vp\", \"Vs\", \"Rho\"), digits = 3)\n\n\n\n\n\n\nVp\nVs\nRho\n\n\n\n\ndataFromPostMean\n4.603\n2.596\n2410.352\n\n\n\n4.100\n2.500\n2589.000"
  },
  {
    "objectID": "notes/waterOnMars.html#discussion",
    "href": "notes/waterOnMars.html#discussion",
    "title": "Water on Mars",
    "section": "Discussion",
    "text": "Discussion\n\nPrior sensitivity\n\nExercise\n\n\nDiscuss with a neighbor: do you think the results are sensitive to the choice of prior?\n\n\n\n\nAlternate priorMarginal posteriors\n\n\n\n\\(beta(1/2, 1/2)\\) prior on water saturation.\n\n\nlogPosterior = function(theta) {\n  result = myBerry(theta)\n  y = c(result$vp / 1000, result$vs / 1000, result$ro2)\n  if(result$vp &lt; result$vs) {\n    return(-Inf)\n  }\n  else{\n  return(\n    sum(dnorm(y, mean = seismic_data$y, sd = seismic_data$sd,\n            log = TRUE)) + \n      dbeta(theta[3], .5, .5, log = TRUE)\n  )\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel selection\nLet \\(M_1\\) be the hypothesis that there is water present under the surface of Mars and let \\(M_0\\) be the hypothesis that there is not. Really, we want to select between these two hypotheses.\nTo do this, consider the ratio of posterior probabilities\n\\[\n\\begin{aligned}\n\\underbrace{\\frac{Pr(M_1 | data)}{Pr(M_0 |data)}}_{\\text{posterior odds}}\n=\n\\underbrace{\\frac{p({data} | M_1)}{p(data | M_0}}_{\\text{Bayes factor}}\n\\underbrace{\\frac{p(M_1)}{p(M_0)}}_{\\text{prior odds}}\n\\end{aligned}\n\\]\nThe Bayes factor tells us how the data supports one hypothesis over another. Notice that we cannot compute the Bayes factor directly. We must expand,\n\\[\n\\begin{aligned}\np(data | M_i) &= \\int p(data, \\theta | M_i) d\\theta\\\\\n&= \\int p(data | \\theta) p(\\theta | M_i) d \\theta\n\\end{aligned}\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nNotice that the Bayes factor does depend on the prior \\(p(\\theta | M_i)\\)."
  },
  {
    "objectID": "notes/waterOnMars.html#footnotes",
    "href": "notes/waterOnMars.html#footnotes",
    "title": "Water on Mars",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWright, V., Morzfeld, M., & Manga, M. (2024). Liquid water in the Martian mid-crust. Proceedings of the National Academy of Sciences, 121(35), e2409983121.↩︎\nhttps://github.com/mattimorzfeld/WMM24↩︎"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html",
    "href": "notes/lec15-MetropolisHastings.html",
    "title": "Metropolis-Hastings",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(patchwork)\nlibrary(tidymodels)\nlibrary(mvtnorm)\nlibrary(coda)\nlibrary(animation)"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#notation",
    "href": "notes/lec15-MetropolisHastings.html#notation",
    "title": "Metropolis-Hastings",
    "section": "Notation",
    "text": "Notation\n\n\\(\\theta\\) is some parameter of interest.\n\\(\\pi(\\theta)\\) represents the target distribution of the parameter.\n\nQuestion: what does the phrase “explore parameter space” mean?"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#metropolis-algorithm",
    "href": "notes/lec15-MetropolisHastings.html#metropolis-algorithm",
    "title": "Metropolis-Hastings",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nSample \\(\\theta^* | \\theta^{(s)} \\sim J(\\theta | \\theta^{(s)})\\)\nCompute the acceptance ratio \\(r = \\frac{\\pi(\\theta^*)}{\\pi(\\theta^{(s)})}\\)\nLet \\[\n\\theta^{(s+1)} =\n\\begin{cases}\n\\theta^* \\text{ with probability } \\min(r, 1)\\\\\n\\theta^{(s)} \\text{ with probability } 1 - \\min(r, 1)\n\\end{cases}\n\\]\n\n\nExample 1\nLet \\(\\pi(\\theta) = \\text{dnorm}(\\theta, 10, 1)\\) and let \\(J(\\theta | \\theta^{(s)}) = \\text{normal}(\\theta^{(s)},\\delta^2)\\).\nWe have to choose \\(\\delta\\). How should we choose it? Let’s gain some intuition by trying out three different values of \\(\\delta\\).\n\nset.seed(360)\ntheta_s = 0 # starting point\nTHETA = NULL # empty object to save iterations in\nS = 10000 # number of iteations\ndelta = 1 # proposal variance\naccept = 0 # keep track of acceptance rate\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ### generate proposal and compute ratio r ###\n  theta_proposal = rnorm(1, mean = theta_s, sd = delta) \n  log.r = dnorm(theta_proposal, mean = 10, sd = 1, log = TRUE) - \n    dnorm(theta_s, mean = 10, sd = 1, log = TRUE)\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) &lt; log.r)  {\n    theta_s = theta_proposal\n    accept = accept + 1 \n  }\n  THETA = c(THETA, theta_s)\n}\n\nLet’s look at a trace plot\n\ntrace plotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf = data.frame(theta = THETA)\ndf %&gt;%\n  ggplot(aes(x = 1:nrow(df), y = theta)) + \n  geom_line() +\n  theme_bw() +\n  labs(x = \"iteration\", y = TeX(\"\\\\theta\"))\n\n\n\n\nLet’s look at how various \\(\\delta\\) let us sample the target:\n\n\\(\\delta = 1\\)\\(\\delta = 4\\)\\(\\delta = 0.1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\nThe fledglings of female song sparrows. To begin, let’s load the data.\n\n\nLoad the data\nyX = structure(c(3, 1, 1, 2, 0, 0, 6, 3, 4, 2, 1, 6, 2, 3, 3, 4, 7, \n2, 2, 1, 1, 3, 5, 5, 0, 2, 1, 2, 6, 6, 2, 2, 0, 2, 4, 1, 2, 5, \n1, 2, 1, 0, 0, 2, 4, 2, 2, 2, 2, 0, 3, 2, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, \n2, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, \n5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 6, 1, 1, 9, 9, 1, 1, 1, 1, 1, 1, \n1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 25, 16, 16, 16, 16, 16, \n16, 16, 16, 16, 16, 16, 16, 25, 16, 16, 16, 16, 25, 25, 25, 25, \n9, 9, 9, 9, 9, 9, 9, 36, 1, 1), .Dim = c(52L, 4L), .Dimnames = list(\n    NULL, c(\"fledged\", \"intercept\", \"age\", \"age2\")))\n\n\n\nyX %&gt;%\n  head(n = 5)\n\n     fledged intercept age age2\n[1,]       3         1   3    9\n[2,]       1         1   3    9\n[3,]       1         1   1    1\n[4,]       2         1   1    1\n[5,]       0         1   1    1\n\ny = yX[,1]\nX = yX[,-1]\n\nThe model:\n\\[\n\\begin{aligned}\nY | X &\\sim \\text{Poisson}(\\exp[ \\beta^T \\boldsymbol{x}])\\\\\n\\beta &\\sim MVN(0, \\sqrt{10})\n\\end{aligned}\n\\]\nThe Metropolis algorithm with\n\\[\nJ(\\beta | \\beta^{(s)}) = MVN(\\beta^{(s)}, \\hat{\\sigma}^2(X^TX)^{-1})\n\\] where \\(\\hat{\\sigma}^2\\) is the sample variance of \\(\\{\\log(y_1 + 1/2), \\ldots, \\log(y_n + 1/2)\\}\\).\n\n\n\n\n\n\nNote\n\n\n\n\nThis variance is intuitively useful choice for \\(\\delta\\) since the posterior variance would be \\(\\sigma^2 (X^TX)^{-1}\\) in a normal regression problem.\nWe use \\(\\log(y + 1/2)\\) instead of \\(\\log y\\) because if \\(y=0\\), \\(\\log y\\) would be \\(-\\infty\\).\n\n\n\n\nset.seed(360)\nn = length(y)\np = ncol(X)\n\npmn.beta = rep(0, p) # prior mean beta\npsd.beta = rep(10, p) # prior sd beta\n\nvar.prop = var(log(y + 1/2)) * solve(t(X) %*% X) # proposal variance\n\nS = 10000\nbeta = rep(0, p); accepts = 0\nBETA = matrix(0, nrow = S, ncol = p)\nset.seed(1)\n\nfor (s in 1:S) {\n  # multivariate proposal of beta\n  beta.p = t(rmvnorm(1, beta, var.prop))\n  \n  # log ratio\n  lhr = sum(dpois(y, exp(X %*%beta.p), log = TRUE)) -\n    sum(dpois(y, exp(X %*% beta), log = TRUE)) + \n    sum(dnorm(beta.p, pmn.beta, psd.beta, log = TRUE)) -\n    sum(dnorm(beta, pmn.beta, psd.beta, log = TRUE)) \n  \n  if (log(runif(1)) &lt; lhr) {\n    beta = beta.p ; accepts = accepts + 1\n  }\n  \n  BETA[s,] = beta\n}\n\nThe acceptance ratio is 0.428\nLet’s examine convergence.\n\ntrace plotsplot codeESSacf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalue = c(BETA[,1], BETA[,2], BETA[,3])\nn = length(value)\nbeta = c(rep(\"beta1\", n/3), rep(\"beta2\", n/3), rep(\"beta3\", n/3))\ndf = data.frame(value = value,\n                beta = beta) \n\ndf %&gt;%\n  ggplot(aes(x = 1:nrow(df), y = value)) + \n  geom_line() + \n  facet_wrap(~ beta, scales = \"free_x\") +\n  theme_bw() +\n  labs(x = \"iteration\")\n\n\n\n\n# effective sample size\nBETA %&gt;%\n  apply(2, effectiveSize)\n\n[1] 867.4750 825.6214 692.0495\n\n\n\n\n\npar(mfrow=c(1,3))\nacf(BETA[,1])\nacf(BETA[,2])\nacf(BETA[,3])"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#metropolis-hastings",
    "href": "notes/lec15-MetropolisHastings.html#metropolis-hastings",
    "title": "Metropolis-Hastings",
    "section": "Metropolis-Hastings",
    "text": "Metropolis-Hastings\nIf we have a vector of parameters \\(\\theta = \\theta_1, \\ldots \\theta_p\\) then we can choose a proposal \\(J(\\theta | \\theta^{(s)})\\) that updates all \\(\\theta\\) elements simultaneously (as seen above with \\(J(\\beta | \\beta^{(s)})\\).\nAlternatively, we could update blocks of \\(\\theta\\), e.g. propose an update for the first \\(j\\) elements of \\(\\theta\\), \\(J_1(\\theta_1,\\ldots \\theta_j | \\theta_1^{(s)}, \\ldots \\theta_j^{(s)})\\) and then an update for the \\(p-j\\) remaining elements, \\(J(\\theta_{j+1}, \\ldots, \\theta_{p} | \\theta_{j+1}^{(s)}, \\ldots, \\theta_{p}^{(s)})\\).\nSeparately, we could even update each element of \\(\\theta\\) individually, e.g. have an individual, different proposal on each \\(\\theta_i\\), \\(i \\in \\{1, \\ldots p\\}\\).\nWe might even combine block updates with individual updates.\nQuestion: Where have we seen block updates and individual updates within MCMC before?\nThe Metropolis-Hastings algorithm is a generalization of both the Metropolis algorithm and the Gibbs sampler.\n\nThe Metropolis-Hastings algorithm\nLet \\(\\pi(\\theta_1, \\theta_2)\\) be the target distribution. The Metropolis-Hastings algorithm proceeds:\n\nUpdate \\(\\theta_1\\):\n\n\nsample \\(\\theta_1^* \\sim J_1(\\theta_1 | \\theta_1^{(s)}, \\theta_2^{(s)})\\);\ncompute the acceptance ratio\n\n\\[\nr = \\frac{\\pi(\\theta_1^*, \\theta_2^{(s)})}{\\pi(\\theta_1^{(s)}, \\theta_2^{(s)})} \\times \\frac{J_1(\\theta_1^{(s)}| \\theta_1^*, \\theta_2^{(s)})}{\nJ_1(\\theta_1^{*}| \\theta_1^{(s)}, \\theta_2^{(s)})\n}\n\\] 3. set \\(\\theta_1^{(s+1)}\\) to \\(\\theta_1^*\\) with probability \\(\\min(1, r)\\), otherwise set \\(\\theta_1^{(s+1)}\\) to \\(\\theta_1^{(s)}\\).\n\nRepeat the above to update \\(\\theta_2\\) given \\(\\theta_1^{(s+1)}\\).\n\n\n\n\n\n\n\nImportant\n\n\n\nHere, the proposal distribution \\(J\\) need not be symmetric!"
  },
  {
    "objectID": "notes/HamiltonianMonteCarlo.html",
    "href": "notes/HamiltonianMonteCarlo.html",
    "title": "Hamiltonian Monte Carlo",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(mvtnorm)\nlibrary(coda)"
  },
  {
    "objectID": "notes/HamiltonianMonteCarlo.html#hamiltonian-monte-carlo",
    "href": "notes/HamiltonianMonteCarlo.html#hamiltonian-monte-carlo",
    "title": "Hamiltonian Monte Carlo",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\nHamiltonian Monte Carlo (HMC) is a proposal mechanism \\(J(\\theta | \\theta^{(s)})\\), that uses Hamiltonian dynamics to generate proposals that are far away from the current state of the chain with high acceptance probability. These proposals are subsequently accepted or rejected according to the Metropolis-Hastings acceptance ratio.\n\nMotivation: the banana target\n\ntarget distributioncodeplot\n\n\nposterior:\n\\[\np(\\theta | y_1, \\ldots y_n) \\propto \\underbrace{\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1)}_{\\text{likelihood}} \\cdot \\underbrace{\\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)}_{\\text{priors}}\n\\]\n\n\n\nlogPosterior = function(theta) {\n  c = theta[1] + (theta[2] ^ 2)\n  logLikelihood = sum(dnorm(y, mean = c, sd = 1, log = TRUE))\n  logPrior = dnorm(theta[1], 0, 1, log = TRUE) +\n    dnorm(theta[2], 0, 1, log = TRUE)\n    return(logLikelihood + logPrior)\n}\n\n\n# simulated data y\nset.seed(360)\nn = 30\ntheta1 = .75\ntheta2 = .5\ny = rnorm(n, (theta1 + (theta2^2)), 1)\ny\n\n [1]  2.4374945977  1.3225732383  0.7957033706  0.0009050433  0.9624998552\n [6]  0.2485689217  0.3494050797  0.8481528753  0.1619672883  1.5373043843\n[11]  1.9319327323  2.1723549678  0.5916180759  1.5788760946 -0.2521989302\n[16] -0.0956751145  2.1896602700  2.7428271328 -0.8507334992 -0.3434228915\n[21]  0.7158629051  2.9076884521 -0.0258688807  2.7880781640  1.3319085255\n[26]  1.0734242350  1.3910936322  1.8806039555  1.6171004720  1.4077704842\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion: What about this target distribution could challenge a Metropolis sampler with \\(J(\\theta_i | \\theta_i^{(s)}) = \\text{normal}(\\theta_i, \\delta)\\)?\nLet’s try it out.\n\nMetropolis samplertrajectoryESSautocorrelationtrace plots\n\n\n\n# sample from posterior\nset.seed(360)\ntheta1 = 0 # starting point\ntheta2 = 0\nTHETA1 = NULL # empty object to save iterations in\nTHETA2 = NULL\nS = 10000 # number of iterations\ndelta = .5 # proposal variance\naccept1 = 0 # keep track of acceptance rate\naccept2 = 0\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ### generate proposal 1 and compute ratio r ###\n  theta1star = rnorm(1, mean = theta1, sd = delta) \n  log.r = logPosterior(c(theta1star, theta2)) - \n    logPosterior(c(theta1, theta2))\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) &lt; log.r)  {\n    theta1 = theta1star\n    accept1 = accept1 + 1 \n  }\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n  \n   ### generate proposal 2 and compute ratio r ###\n  theta2star = rnorm(1, mean = theta2, sd = delta) \n  log.r = logPosterior(c(theta1, theta2star)) - \n    logPosterior(c(theta1, theta2))\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) &lt; log.r)  {\n    theta2 = theta2star\n    accept2 = accept2 + 1 \n  }\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffectiveSize(THETA1)\n\n    var1 \n38.28904 \n\neffectiveSize(THETA2)\n\n    var1 \n40.44706 \n\n\n\n\n\npar(mfrow=c(1,2))\nacf(THETA1)\nacf(THETA2)\n\n\n\n\n\n\n\n\n\n\n\nN = length(THETA1)\ndf = data.frame(theta = c(THETA1, THETA2), \n                theta_id = c(rep(\"theta1\", N), rep(\"theta2\", N)),\n                step = rep(1:N, 2))  \ndf %&gt;%\n  ggplot(aes(x = step, y = theta, col = theta_id)) + \n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ theta_id) +\n  labs(x = \"iteration\", y = \"value\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nHamiltonian dynamics\nIf we view the state of the Markov chain as the physical location of a particle in parameter space, then what happens if we pretend the laws of physics apply to this physical space? More specifically, let’s suppose the steps of the Markov chain are akin to a particle moving through Euclidean space and obeying Hamiltonian dynamics. The Hamiltonian of a system specifies its total energy.\nTo be a Hamiltonian system, the particle will have:\n\na location (the position in parameter space)\npotential energy\nkinetic energy\n\nQuestion: we are going to match up the negative log-posterior to either the kinetic energy or the potential energy. Which one do you think makes more sense? Why does the negative sign make sense when we think of what we are trying to do in the context of this as a physical system?\nMathematically, let \\(q\\) be the position of the particle (in parameter space) and let \\(p\\) be the momentum of the particle. So \\(q\\) and \\(p\\) are both vectors of the same dimension (the dimension of parameter space). Then the Hamiltonian, \\(H = U(q) + K(p)\\) where \\(U(q)\\) and \\(K(p)\\) are the potential and kinetic energy respectively. We will let \\(U(q) = - \\log \\pi(q)\\) where \\(\\pi(q)\\) is our target distribution.\nHamilton’s equations of motion state\n\\[\n\\begin{aligned}\n\\frac{dq_i}{dt} &= \\frac{\\partial{H}}{\\partial p_i}\\\\\n\\frac{dp_i}{dt} &= -\\frac{\\partial{H}}{\\partial q_i}\\\\\n\\end{aligned}\n\\] These equations govern the motion of the particle. They let us map from the state at time \\(t\\) to the state of the system at any future state \\(t + s\\). And it can be shown that \\(\\frac{d}{dt} H  = 0\\). In words, energy is conserved.\n\n\n\n\n\n\nImportant\n\n\n\nThe above equations elicit a need to compute \\(-\\frac{\\partial H}{\\partial q_i} = \\frac{\\partial}{\\partial q_i} \\log \\pi(q)\\), i.e. the gradient of the log-posterior.\n\n\nA simple choice of kinetic energy is:\n\\[\nK(p) = \\frac{1}{2} p^T M^{-1}p\n\\]\nwhere \\(M\\) is called the “mass matrix”.\nQuestion: this looks like the log of a kernel you know… which one?\n\n\nAlgorithm\nFundamentally, HMC is just the Metropolis algorithm with proposals generated via Hamiltonian dynamics. The equations of motion above describe a vector field, and if we integrate them numerically, we can follow the flow through joint space of parameters and momentum.\nLet’s tackle the banana target from before in an example.\n\ngradientHMC codetrajectoryESSautocorrelationtrace plots\n\n\nWe need the gradient of the log-posterior\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\theta_1} \\log \\pi(\\theta_1, \\theta_2 | y_1,\\ldots y_n) &=\n\\frac{\\partial}{\\partial\\theta_1} \\log\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1) \\cdot \\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)\\\\\n&= n \\bar{y} - n \\theta_1 - n\\theta_2^2 - \\theta_1\\\\\n&= n\\bar{y} - n\\theta_2^2 - \\theta_1(n + 1)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\theta_2} \\log \\pi(\\theta_1, \\theta_2 | y_1,\\ldots y_n) &=\n\\frac{\\partial}{\\partial\\theta_2} \\log\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1) \\cdot \\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)\\\\\n&= 2n \\bar{y} \\theta_2 - 2 n \\theta_1 \\theta_2 - 2n\\theta_2^3\n\\end{aligned}\n\\]\n\nn = length(y)\nybar = mean(y)\ngradLogPosterior = function(theta) {\n  gradTheta1 = (n*ybar) - (n * (theta[2]^2)) - ((theta[1])*(n+1))\n  gradTheta2 = (2 * n * ybar * theta[2]) - (2 * n * theta[1] * theta[2]) - \n    (2 * n * (theta[2]^3))\n  return(c(gradTheta1, gradTheta2))\n}\n\n\n\nHMC code block below from Neal (2011), see the references\n\nHMC = function (U, grad_U, epsilon, L, current_q) { \n  q = current_q\n  p = rnorm(length(q), 0, 1) # independent standard normal variates\n  current_p = p\n  # Make a half step for momentum at the beginning\n  p = p - epsilon * grad_U(q) / 2\n  # Alternate full steps for position and momentum\n  for (i in 1:L) {\n    # Make a full step for the position\n    q = q + epsilon * p\n    # Make a full step for the momentum, except at end of trajectory\n    if (i != L)\n      p = p - epsilon * grad_U(q)\n  }\n  # Make a half step for momentum at the end.\n  p = p - epsilon * grad_U(q) / 2\n  # Negate momentum at end of trajectory to make the proposal symmetric\n  p = -p\n  # Evaluate potential and kinetic energies at start and end of trajectory\n  current_U = U(current_q)\n  current_K = sum(current_p ^ 2) / 2\n  proposed_U = U(q)\n  proposed_K = sum(p ^ 2) / 2\n  # Accept or reject the state at end of trajectory, returning either\n  # the position at the end of the trajectory or the initial position\n  if (runif(1) &lt; exp(current_U - proposed_U + current_K - proposed_K))\n  {\n    return (q) # accept\n  }\n  else\n  {\n    return (current_q) # reject\n  }\n}\n\n\nset.seed(360)\nS = 10000\nTHETA1 = NULL\nTHETA2 = NULL\ncurrent_q = c(1, 0)\n\nU = function(theta) {\n  return(-1 * logPosterior(theta))\n}\n\ngradU = function(theta) {\n  return(-1 * gradLogPosterior(theta))\n}\n\n\nfor(s in 1:S) {\n  current_q = HMC(U, gradU, epsilon = .05, L = 10, current_q)\n  theta1 = current_q[1]\n  theta2 = current_q[2]\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n}\n\n\n\n\ntrajectoryDF = data.frame(theta1 = THETA1, theta2 = THETA2) %&gt;%\n  head(n = 300)\n\nTHETA %&gt;%\n  ggplot(aes(x = theta1, y = theta2)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1$\"), y = TeX(\"$\\\\theta_2$\"), fill = \"density\",\n       title = \"Trajectory of first 300 steps of HMC\") +\n  geom_path(data = trajectoryDF, color = \"orange\", alpha = 0.6, size=0.5)\n\n\n\n\n\n\n\n\n\n\n\neffectiveSize(THETA1)\n\n    var1 \n765.6712 \n\neffectiveSize(THETA2)\n\n    var1 \n301.3347 \n\n\n\n\n\npar(mfrow=c(1,2))\nacf(THETA1)\nacf(THETA2)\n\n\n\n\n\n\n\n\n\n\n\nN = length(THETA1)\ndf = data.frame(theta = c(THETA1, THETA2), \n                theta_id = c(rep(\"theta1\", N), rep(\"theta2\", N)),\n                step = rep(1:N, 2))  \ndf %&gt;%\n  ggplot(aes(x = step, y = theta, col = theta_id)) + \n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ theta_id) +\n  labs(x = \"iteration\", y = \"value\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\nGreat it works… but how do I know this is producing an ergodic Markov chain?\n\nMichael Betancourt’s conceptual intro\nRadford Neal’s comprehensive book chapter\nHow is it implemented in stan?"
  },
  {
    "objectID": "slides/lab-normal.html#data",
    "href": "slides/lab-normal.html#data",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Data",
    "text": "Data\n\nbass = read_csv(\"https://sta360-sp25.github.io/data/bass.csv\")\n\n\nglimpse(bass)\n\nRows: 171\nColumns: 5\n$ river   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ station &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ length  &lt;dbl&gt; 47.0, 48.7, 55.7, 45.2, 44.7, 43.8, 38.5, 45.8, 44.0, 40.4, 47…\n$ weight  &lt;dbl&gt; 1.616, 1.862, 2.855, 1.199, 1.320, 1.225, 0.870, 1.455, 1.220,…\n$ mercury &lt;dbl&gt; 1.60, 1.50, 1.70, 0.73, 0.56, 0.51, 0.48, 0.95, 1.40, 0.50, 0.…\n\n\nMercury, is a naturally occurring element that can have toxic effects on the nervous, digestive and immune systems of humans. Bass from the Waccamaw and Lumber Rivers (NC) were caught randomly, weighed, and measured. In addition, a filet from each fish caught was sent to the lab so that the tissue concentration of mercury could be determined for each fish. Each fish caught corresponds to a single row of the data frame. Today we will examine two columns from the data set: mercury (concentration of mercury in ppm) and weight (weight of the fish in kg). We’ll model the mercury content \\(y\\) of each fish as a function of the fish’s weight \\(x\\)."
  },
  {
    "objectID": "slides/lab-normal.html#model",
    "href": "slides/lab-normal.html#model",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Model",
    "text": "Model\nLet\n\\[\n\\begin{aligned}\nY_i | \\theta &\\sim \\text{ iid  } N(\\theta x_i, 1)\\\\\n\\theta &\\sim N(\\mu_0, 1 / \\kappa_0)\n\\end{aligned}\n\\]\nLet \\(\\mu_0 = 0\\), \\(\\kappa_0 = 1\\).\n(a). Suppose you observe data \\(y_1,\\ldots y_n\\). Write out the formula for \\(p(\\theta | y_1, \\ldots y_n)\\).\n(b). Given the data on the previous slide, use Monte Carlo simulation to plot \\(p(\\theta | y_1, \\ldots, y_n)\\). Additionally, report \\(E[\\theta | y_1,\\ldots y_n]\\) together with a 95% posterior confidence interval.\n(c). If you caught a new fish with weight 4kg, what would you predict the mercury content to be? In other words, let x = 4 and compute \\(E[\\tilde{y}|y_1,\\ldots, y_n, x = 4]\\). Additionally, plot the the posterior predictive density \\(p(\\tilde{y} | y_1, \\ldots y_n, x = 4)\\).\n(d). Critique your model. Hint: compare to the models below:\n\nlm(mercury ~ weight, data = bass)\nlm(mercury ~ 0 + weight, data = bass)"
  },
  {
    "objectID": "slides/lab-normal.html#solution-a",
    "href": "slides/lab-normal.html#solution-a",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (a)",
    "text": "Solution (a)\na\n\\[\n\\theta |  y_1, \\ldots y_n \\sim N(\\mu_n, \\tau_n^2)\n\\] \nwhere\n\n\n\n\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0 \\mu_0 + \\sum y_i x_i}{\\kappa_0 + \\sum x_i^2}\\\\\n\\tau_n^2 &= \\frac{1}{\\kappa_0 + \\sum x_i^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab-normal.html#solution-b",
    "href": "slides/lab-normal.html#solution-b",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (b)",
    "text": "Solution (b)\nb\n\ndemodemo plotsolution codesolution plotsummary\n\n\nDemo with simulated data to make sure code works:\n\n# simulated data\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\nN = 10\nx = seq(from = 1, to = 10, length = N)\ny = rnorm(N, true.theta * x, true.sigma)\n\n# prior parameters\nk0 = 1\nmu0 = 0\n\nsumYX = sum(y * x)\nd = (k0 + sum(x^2))\nmun = ((k0 * mu0) + sumYX) / d\ntn = sqrt(1 / d)\n\ntheta.postsample = rnorm(10000, mun, tn)\nhist(theta.postsample)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = bass$weight\ny = bass$mercury\n\n# prior parameters\nk0 = 1\nmu0 = 0\n\nsumYX = sum(y * x)\nd = (k0 + sum(x^2))\nmun = ((k0 * mu0) + sumYX) / d\ntn = sqrt(1 / d)\n\ntheta.postsample = rnorm(10000, mun, tn)\nhist(theta.postsample)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean(theta.postsample)\n\n[1] 0.8314533\n\nquantile(theta.postsample, c(0.025, 0.975))\n\n     2.5%     97.5% \n0.7284780 0.9356104"
  },
  {
    "objectID": "slides/lab-normal.html#solution-c",
    "href": "slides/lab-normal.html#solution-c",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (c)",
    "text": "Solution (c)\n\n# use posterior samples of theta and x = 4 to simulate ytilde\n\nytilde = rnorm(10000, theta.postsample * 4, 1)\nhist(ytilde)\n\nmean(ytilde)\n\n[1] 3.319342\n\n\nThis matches intuition (law of total expectation gives the closed form solution: 4 * 0.838 = 3.352)."
  },
  {
    "objectID": "slides/lab-normal.html#solution-d",
    "href": "slides/lab-normal.html#solution-d",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (d)",
    "text": "Solution (d)\nWe have no intercept term. We are assuming that our regression line goes through the origin. This is a strong assumption. Our model will be most similar to the lm model without an intercept term:\n\nlm(mercury ~ 0 + weight, data = bass)\n\n\nCall:\nlm(formula = mercury ~ 0 + weight, data = bass)\n\nCoefficients:\nweight  \n0.8343  \n\n\nHowever, we’ll get a different estimate of \\(\\hat{\\theta}\\) if we include an intercept term,\n\nlm(mercury ~ weight, data = bass)\n\n\nCall:\nlm(formula = mercury ~ weight, data = bass)\n\nCoefficients:\n(Intercept)       weight  \n     0.6387       0.4818"
  },
  {
    "objectID": "notes/lec11-mvn.html",
    "href": "notes/lec11-mvn.html",
    "title": "Multivariate normal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mvtnorm) \nlibrary(patchwork)"
  },
  {
    "objectID": "notes/lec11-mvn.html#visualizing-a-two-dimensional-normal",
    "href": "notes/lec11-mvn.html#visualizing-a-two-dimensional-normal",
    "title": "Multivariate normal",
    "section": "Visualizing a two-dimensional normal",
    "text": "Visualizing a two-dimensional normal\n\nparameterssimulate mvn datascatterplotdensity plot3dmarginals\n\n\n\nSigma = matrix(c(2, 0.7, 0.7, 1), \n               nrow = 2, ncol = 2)\nmu = c(0, 0)\n\n\nmu\n\n[1] 0 0\n\nSigma\n\n     [,1] [,2]\n[1,]  2.0  0.7\n[2,]  0.7  1.0\n\n\n\n\n\nset.seed(360)\nY = rmvnorm(n = 500, \n        mean = mu,\n        sigma = Sigma)\n\nY[1:5,]\n\n           [,1]       [,2]\n[1,]  2.0834251  0.7384787\n[2,] -0.5817255 -1.0144046\n[3,] -0.2769858 -0.7281417\n[4,] -0.9446903 -0.3398126\n[5,] -0.9972539  0.2615113\n\n\n\n\n\ndf = data.frame(y1 = Y[,1], y2 = Y[,2]) \nplot1 = df %&gt;%\n  ggplot(aes(x = y1, y = y2)) +\n  geom_point() +\n  theme_bw()\nplot1\n\n\n\n\n\n\n\n\n\n\n\nplot1 +\n  geom_density_2d()\n\n\n\n\n\n\n\n\n\n\n\nx = seq(-5, 5, 0.25) \ny = seq(-5, 5, 0.25)\nf  = function(x, y) dmvnorm(cbind(x, y), mu, Sigma)\nz = outer(x, y, f)\npersp(x, y, z, theta = -30, phi = 25, \n      shade = 0.75, col = \"steelblue\", expand = 0.5, r = 2, \n      ltheta = 25, ticktype = \"detailed\", xlab =\"y1\",\n      ylab = \"y2\",\n      zlab = \"\")\n\n\n\n\n\n\n\n\n\n\n\np1 = df %&gt;%\n  ggplot(aes(x = y1)) +\n  geom_histogram(aes(y = ..density..)) +\n  geom_density() +\n  theme_bw()\n\np2 = df %&gt;%\n  ggplot(aes(x = y2)) +\n  geom_histogram(aes(y = ..density..)) +\n  geom_density() +\n  theme_bw()\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDensity\nWe say a \\(p\\) dimensional vector \\(\\boldsymbol{Y}\\) has a multivariate normal distribution if its sampling density is given by\n\\[\np(\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{\n-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}- \\boldsymbol{\\theta})\n\\}\n\\]\nwhere\n\\[\n\\boldsymbol{y}=  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\\\\\n   \\vdots\\\\\n   y_p\n  \\end{array} } \\right]\n  ~~~\n   \\boldsymbol{\\theta}= \\left[ {\\begin{array}{cc}\n   \\theta_1 \\\\\n   \\theta_2\\\\\n   \\vdots\\\\\n   \\theta_p\n  \\end{array} } \\right]\n  ~~~\n  \\Sigma =\n  \\left[ {\\begin{array}{cc}\n   \\sigma_1^2 & \\sigma_{12}& \\ldots & \\sigma_{1p}\\\\\n   \\sigma_{12} & \\sigma_2^2 &\\ldots & \\sigma_{2p}\\\\\n   \\vdots & \\vdots & & \\vdots\\\\\n   \\sigma_{1p} & \\ldots & \\ldots & \\sigma_p^2\n  \\end{array} } \\right].\n\\]\n\nKey facts\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma &gt; 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] =  \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\n\nsampling from a mvt norm\nlibrary(mvtnorm) contains functions we need.\n\nrmvnorm() to sample from a multivariate normal\ndmvnorm() to compute the density\npmvnorm() to compute the distribution function\nqmvnorm() to compute quantiles of the multivariate normal"
  },
  {
    "objectID": "notes/lec11-mvn.html#matrix-algebra-fundamentals",
    "href": "notes/lec11-mvn.html#matrix-algebra-fundamentals",
    "title": "Multivariate normal",
    "section": "Matrix algebra fundamentals",
    "text": "Matrix algebra fundamentals\n\nmatrix facts\n\nmatrix multiplication proceeds row \\(\\times\\) column, so if we have the product \\(AB\\), \\(A\\) must have the same number of ___ as B has ___.\nthe determinant of a matrix, \\(|A|\\), measures the size of the matrix\nthe identity matrix is the matrix multiplicative identity. It is represented by \\(\\boldsymbol{I}\\), in general \\(\\boldsymbol{I}_p\\) is a \\(p \\times p\\) matrix with 1 on each diagonal and 0 on every off-diagonal. \\(\\boldsymbol{I}A = A \\boldsymbol{I}= A\\).\nthe inverse of a matrix \\(A^{-1}\\) works as follows: \\(A A^{-1} = A^{-1}A = \\boldsymbol{I}\\).\nthe trace of a matrix, tr(A), is the sum of its diagonal elements\norder matters: \\(AB \\neq BA\\) in general.\n\\(\\Sigma &gt; 0\\) is shorthand for saying the matrix is positive definite. This means that for all vectors \\(\\boldsymbol{x}\\), the quadratic form \\(\\boldsymbol{x}^T \\Sigma \\boldsymbol{x} &gt; 0\\). \\(\\Sigma &gt; 0 \\iff\\) all eigenvalues of \\(\\Sigma\\) are positive.\n\n\nExercise\n\n\n\n\\(\\boldsymbol{\\theta}\\) and \\(\\boldsymbol{b}\\) are \\(p \\times 1\\) vectors, \\(A\\) is a symmetric matrix. Simplify \\(\\boldsymbol{b}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T A \\boldsymbol{b}\\) what is the dimension of the result?\n\\(\\boldsymbol{y}\\) is a \\(p \\times 1\\) vector. What’s the dimension of \\(V[\\boldsymbol{y}]\\)?\n\n\n\n\n\n\nmatrix operations in R\n\n# make a matrix A\nA = matrix(c(1,.2, .2, 2), ncol = 2)\nA\n\n     [,1] [,2]\n[1,]  1.0  0.2\n[2,]  0.2  2.0\n\n# invert A (expensive for large matrices)\nAinv = solve(A)\n\n# matrix multiplication\nAinv %*% A\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n# determinant of A\ndet(A)\n\n[1] 1.96\n\n# trace of A\nsum(diag(A))\n\n[1] 3\n\n# create a vector b\nb = matrix(c(1, 2), ncol = 1)\nb\n\n     [,1]\n[1,]    1\n[2,]    2\n\n# transpose the vector b\nt(b)\n\n     [,1] [,2]\n[1,]    1    2\n\n\n\nb %*% A\n\nError in b %*% A: non-conformable arguments\n\n\n\nWhat went wrong in the code above?"
  },
  {
    "objectID": "notes/lec11-mvn.html#semiconjugate-priors",
    "href": "notes/lec11-mvn.html#semiconjugate-priors",
    "title": "Multivariate normal",
    "section": "Semiconjugate priors",
    "text": "Semiconjugate priors\n\n\n\n\n\n\nDefinition\n\n\n\nA semiconjugate or conditionally conjugate prior is a prior that is conjugate to the full conditional posterior.\n\n\n\nsemiconjugate prior for \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\Lambda_n &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1},\\\\\n\\boldsymbol{\\mu_n} &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1}(\\Lambda_0^{-1} \\boldsymbol{\\mu}_0 + n \\Sigma^{-1} \\bar{\\boldsymbol{y}}).\n\\end{aligned}\n\\]\n\nExercise\n\n\nInterpret \\(E[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\) and \\(Cov[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\).\n\n\n\n\n\nsemiconjugate prior for \\(\\Sigma\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\Sigma &\\sim \\text{inverse-Wishart}(\\nu_0, S_0^{-1}),\n\\end{aligned}\n\\]\nthen\n\\[\n\\Sigma | \\boldsymbol{y}, \\boldsymbol{\\theta}\\sim \\text{inverse-Wishart} (\\nu_0 + n, (S_0 + S_{\\theta})^{-1}),\n\\] where \\(S_\\theta = \\sum_{i=1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta})(\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T\\) is the residual sum of squares matrix for the vectors \\(\\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n\\) if the population mean is \\(\\boldsymbol{\\theta}\\).\n\n\n\nthe inverse-Wishart\nthe inverse-Wishart\\((\\nu_0, S_0^{-1})\\) density is given by\n\\[\n\\begin{aligned}\np(\\Sigma | \\nu_0, S_0^{-1}) = \\left[\n2^{\\nu_0 p / 2} \\pi^{{p \\choose 2}/2} |S_0|^{-\\nu_0/2} \\prod_{j = 1}^p \\Gamma([\\nu_0 + 1 - j]/2)\n\\right]^{-1} \\times\\\\\n|\\Sigma|^{-(\\nu_0 + p + 1)/2} \\times \\exp \\{ -\\frac{1}{2}tr(S_0 \\Sigma^{-1})\\}.\n\\end{aligned}\n\\]\n\nKey facts\n\nnotice that the first line is the normalizing constant of the density\nthe support is \\(\\Sigma &gt; 0\\) and \\(\\Sigma\\) symmetric \\(p \\times p\\) matrix. \\(\\nu_0 \\in \\mathbb{N}^+\\) and \\(\\nu_0 \\geq p\\). \\(S_0\\) is a \\(p \\times p\\) symmetric positive definite matrix.\nif \\(\\Sigma\\) is inv-Wishart\\((\\nu_0, S_0^{-1})\\) then \\(\\Sigma^{-1}\\) is Wishart\\((\\nu_0, S_0^{-1})\\).\n\\(E[\\Sigma^{-1}] = \\nu_0 S_0^{-1}\\) and \\(E[\\Sigma] = \\frac{1}{\\nu_0 - p - 1} S_0\\).\nintuition: \\(\\nu_0\\) is prior sample size. \\(S_0\\) is a prior guess of the covariance matrix.\n\n\n\nsampling from the inverse-Wishart\n\npick \\(\\nu_0 &gt; p\\), pick \\(S_0\\)\nsample \\(\\boldsymbol{z}_1, \\ldots \\boldsymbol{z}_{\\nu_0} \\sim \\text{ i.i.d. } MVN(\\boldsymbol{0}, S_0^{-1})\\)\ncalculate \\(\\boldsymbol{Z}^T \\boldsymbol{Z} = \\sum_{i = 1}^{\\nu_0} \\boldsymbol{z}_i \\boldsymbol{z}^T\\)\nset \\(\\Sigma = (\\boldsymbol{Z}^T \\boldsymbol{Z})^{-1}\\)\n\n\nlibrary(mvtnorm) # contains function rmvnorm\n\n# 2x2 example: generating 1 sample from an inv-Wishart\nset.seed(360)\np = 2\nnu0 = 3\nS0 = matrix(c(1, .1, .1, 1), ncol = 2)\nS0inv = solve(S0)\nZ = rmvnorm(n = nu0, # number of observations of the 2D vector Z\n        mean = rep(0, p), # mean 0\n        sigma = S0inv) # prior variance\nSigma = solve(t(Z) %*% Z)\neigen(Sigma)$values\n\n[1] 0.7821737 0.4174527\n\nSigma\n\n           [,1]      [,2]\n[1,]  0.5271834 -0.167273\n[2,] -0.1672730  0.672443\n\n\n\nExercise\n\n\nWhy does this work? Hint: what is \\(Var[\\boldsymbol{z}]\\)?\n\n\n\nWe can also use the monomvn package to simulate from a Wishart more succinctly,\n\nlibrary(monomvn)\n\nset.seed(360)\nSigma = solve(rwish(nu0, S0inv))\neigen(Sigma)$values\n\n[1] 0.692529 0.160428\n\nSigma\n\n          [,1]      [,2]\n[1,] 0.1899212 0.1217519\n[2,] 0.1217519 0.6630358"
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html",
    "href": "notes/lec09-mcmc-diagnostics.html",
    "title": "MCMC diagnostics",
    "section": "",
    "text": "We setup a data generative model, \\(p(y | \\boldsymbol{\\theta})\\) and a prior on the model parameters \\(p(\\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots \\theta_n\\}\\).\nNext, we wish to make inferences using the data we collect \\(\\boldsymbol{y} = \\{y_1,\\ldots y_n\\}\\). All inferences we make require the posterior \\(p(\\boldsymbol{\\theta}| \\boldsymbol{y})\\), which we obtain via Bayes’ rule.\nIn general, the inferences we wish to make, e.g. \\(p(g(\\boldsymbol{\\theta}) \\in A)\\), are complicated or impossible to compute analytically. Here, Monte Carlo approximation helps. The key idea is that we use independent samples from the posterior as an empirical approximation to make inference.\nFor non-conjugate models, obtaining samples from the posterior can be hard. We saw last time that Gibbs sampling lets us generate a series of dependent samples from the posterior as an empirical approximation to make inference. The key idea is that if we sample a large number of samples \\(S\\), we should have some number \\(S_{eff}&lt;S\\) effectively independent samples.\n\n\nGibbs sampling is one of many methods (but not the only method) to construct a Markov chain comprised of dependent samples from the target distribution.\nConstructing a Markov chain of dependent samples and using these samples to approximate the target distribution is called Markov chain Monte Carlo (MCMC).\n\nImportantly, MCMC sampling algorithms are not models. They do not generate more information than is in \\(\\boldsymbol{y}\\) and \\(p(\\boldsymbol{\\theta})\\). They are simply ways of “looking at” \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA target distribution is a distribution we are interested in sampling. In Bayesian statistics, this is typically the posterior distribution."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#the-bayesian-statistical-procedure",
    "href": "notes/lec09-mcmc-diagnostics.html#the-bayesian-statistical-procedure",
    "title": "MCMC diagnostics",
    "section": "",
    "text": "We setup a data generative model, \\(p(y | \\boldsymbol{\\theta})\\) and a prior on the model parameters \\(p(\\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots \\theta_n\\}\\).\nNext, we wish to make inferences using the data we collect \\(\\boldsymbol{y} = \\{y_1,\\ldots y_n\\}\\). All inferences we make require the posterior \\(p(\\boldsymbol{\\theta}| \\boldsymbol{y})\\), which we obtain via Bayes’ rule.\nIn general, the inferences we wish to make, e.g. \\(p(g(\\boldsymbol{\\theta}) \\in A)\\), are complicated or impossible to compute analytically. Here, Monte Carlo approximation helps. The key idea is that we use independent samples from the posterior as an empirical approximation to make inference.\nFor non-conjugate models, obtaining samples from the posterior can be hard. We saw last time that Gibbs sampling lets us generate a series of dependent samples from the posterior as an empirical approximation to make inference. The key idea is that if we sample a large number of samples \\(S\\), we should have some number \\(S_{eff}&lt;S\\) effectively independent samples.\n\n\nGibbs sampling is one of many methods (but not the only method) to construct a Markov chain comprised of dependent samples from the target distribution.\nConstructing a Markov chain of dependent samples and using these samples to approximate the target distribution is called Markov chain Monte Carlo (MCMC).\n\nImportantly, MCMC sampling algorithms are not models. They do not generate more information than is in \\(\\boldsymbol{y}\\) and \\(p(\\boldsymbol{\\theta})\\). They are simply ways of “looking at” \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA target distribution is a distribution we are interested in sampling. In Bayesian statistics, this is typically the posterior distribution."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "title": "MCMC diagnostics",
    "section": "Properties of MCMC",
    "text": "Properties of MCMC\n\ntoy example\nImagine the following target distribution (the joint probability distribution of two variables, \\(\\theta\\) and \\(\\delta\\)).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nset.seed(360)\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\nsd = rep(sqrt(1 / 3), 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # number of samples\n\ndelta = sample(d, size = N, prob = c(.45, .1, .4), replace = TRUE)\ntheta = rnorm(N, mean = mu[delta], sd = sd[delta])\n\ndf = data.frame(delta, theta)\ndf %&gt;%\n  ggplot(aes(x = theta, y = delta)) + \n  geom_bin2d(bins = 25) +\n  theme_bw() + \n  labs(y = TeX(\"\\\\delta\"), \n       x = TeX(\"\\\\theta\"))\n\n\n\n\nIn this example,\n\\[\n\\begin{aligned}\np(\\delta = d) = \\begin{cases}\n&.45 &\\text{ if } d = 1\\\\\n&.10 &\\text{ if } d = 2\\\\\n&.45 &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\{\\theta | \\delta = d\\} \\sim\n\\begin{cases}\n&N(-3, 1/3) &\\text{ if } d = 1\\\\\n&N(0, 1/3) &\\text{ if } d = 2\\\\\n&N(3, 1/3) &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\nExercise: Construct a Gibbs sampler of the joint density.\nNote: this is a toy example. We can sample from the target distribution directly as seen above. However, we will construct a Gibbs sampler for pedagogical purposes that will become apparent momentarily.\n\n\n\n\n\n\nsolution\n\n\n\n\n\nTo construct a Gibbs sampler, we need the full conditional distributions.\n\n\\(p(\\theta | \\delta)\\) is given.\n\\(p(\\delta| \\theta) = \\frac{p(\\theta | \\delta = d) p(\\delta = d)}{ \\sum_{d=1}^3p(\\theta | \\delta = d)p(\\delta = d)}\\), for \\(d \\in \\{1, 2, 3\\}\\).\n\n\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\ns2 = rep(1 / 3, 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # chain length\nw = c(.45, .1, .4) # delta probabilities\n\n## Gibbs sampler ##\nset.seed(360)\nN = 1000 # number of Gibbs samples\n\ntheta = 0 # initial theta value\nthd.mcmc = NULL\nfor(i in 1:N) {\nd = sample(1:3 , 1, prob = w * dnorm(theta, mu, sqrt(s2))) \ntheta = rnorm(1, mu[d], sqrt(s2[d]))\nthd.mcmc = rbind(thd.mcmc, c(theta,d))\n}\n# note we take advantage that sample() in R does not require the probability\n# to add up to 1\n\ndf = data.frame(theta = thd.mcmc[,1],\n                delta = thd.mcmc[,2])\n\ndf %&gt;%\n  ggplot(aes(x = seq(1, nrow(df)), y = theta)) +\n  geom_line() +\n  theme_bw() +\n  labs(y = TeX(\"\\\\theta\"),\n       x = \"iteration\",\n       title = \"Traceplot of 1000 Gibbs samples\")\n\n\n\n\nExercise:\n\ndescribe how we implement the conditional update for delta in the code above\nwhat do you notice from the traceplot above? Hint: you can imagine hopping from delta islands in the first figure of the joint target over parameter space.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe picture to visualize is that of a particle moving through parameter space.\n\n\nLet’s see how well our samples of \\(\\theta\\) approximate the true marginal \\(p(\\theta)\\)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "title": "MCMC diagnostics",
    "section": "Terms to describe MCMC",
    "text": "Terms to describe MCMC\n\nautocorrelation: how correlated consecutive values in the chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\] where \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. In practice we use acf function in R. Example:\n\nacf(thd.mcmc[,1], plot = FALSE)\n\n\nAutocorrelations of series 'thd.mcmc[, 1]', by lag\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n1.000 0.962 0.959 0.954 0.951 0.948 0.948 0.943 0.941 0.936 0.933 0.931 0.928 \n   13    14    15    16    17    18    19    20    21    22    23    24    25 \n0.927 0.923 0.920 0.915 0.911 0.907 0.906 0.908 0.905 0.902 0.899 0.898 0.897 \n   26    27    28    29    30 \n0.895 0.891 0.891 0.887 0.887 \n\n\nThe higher the autocorrelation, the more samples we need to obtain a given level of precision for our approximation. One way to state how precise our approximation is, is with effective sample size.\n\neffective sample size (ESS): intuitively this is the effective number of exact samples “contained” in the Markov chain (see Betancourt 2018). For further reading on ESS, see the stan manual. In practice we use coda::effectiveSize() function to compute. Example:\n\n\nlibrary(coda)\neffectiveSize(thd.mcmc[,1])[[1]]\n\n[1] 2.065509\n\n\nMore precisely, the effective sample size (ESS) is the value \\(S_{eff}\\) such that\n\\[\nVar_{MCMC}[\\bar{\\phi}] = \\frac{Var[\\phi]}{S_{eff}}.\n\\] In words, it’s the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. For comparison, recall \\(Var_{MC}[\\bar{\\phi}] = Var[\\phi]/S\\)\n\nStationarity is when samples taken in one part of the chain have a similar distribution to samples taken from other parts of the chain. Intuitively, we want the particle to move from our arbitrary starting point to regions of higher probability\\(^*\\), then we will say it has achieved stationarity.\n\nTraceplots are a great way to visually inspect whether a chain has converged, or achieved stationarity. In the traceplot above we can see that samples from the beginning of the chain look very different than samples at the end.\n\\(^*\\) recall that probability is really a volume in high dimensions of parameter space, and so it is not enough for a pdf to evaluate to a high value, there must also be sufficient volume.\n\nMixing: how well the particle moves between sets of high probability. Some might refer to this as how well the particle sojourns across the “typical set” (regions of high probability)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "href": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "title": "MCMC diagnostics",
    "section": "Extra practice",
    "text": "Extra practice\nGibbs sample the target above 10 thousand times. Report and discuss both the autocorrelation and ESS."
  },
  {
    "objectID": "notes/lec13-BayesianRegression2.html",
    "href": "notes/lec13-BayesianRegression2.html",
    "title": "Bayesian regression II",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(patchwork)\nlibrary(tidymodels)\nlibrary(scatterplot3d)\nlibrary(palmerpenguins)\nlibrary(mvtnorm)\nlibrary(coda)\nlibrary(animation)"
  },
  {
    "objectID": "notes/lec13-BayesianRegression2.html#gibbs-sampler",
    "href": "notes/lec13-BayesianRegression2.html#gibbs-sampler",
    "title": "Bayesian regression II",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\n\nLast time\nWe set up the model,\n\\[\n\\begin{aligned}\n\\mathbf{y} | X, \\beta, \\sigma^2 &\\sim MVN(X\\beta, \\sigma^2 I)\\\\\n\\beta &\\sim MVN(\\beta_0, \\Sigma_0)\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2/2)\n\\end{aligned}\n\\] and derived the full conditionals\n\\[\n\\begin{aligned}\n\\beta | \\mathbf{y}, X, \\sigma^2 &\\sim MVN(\\mathbf{m}, V),\\\\\n1/\\sigma^2 | \\mathbf{y}, X, \\beta & \\sim\n\\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta)]/2),\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\nV = Var[\\beta | \\mathbf{y}, X, \\sigma^2] &=\n(\\Sigma_0^{-1} + X^TX / \\sigma^2)^{-1},\\\\\n\\mathbf{m} = E[\\beta | \\mathbf{y}, X, \\sigma^2] &= (\\Sigma_0^{-1} + X^T X/ \\sigma^2)^{-1}(\\Sigma_0^{-1} \\beta_0 + X^T\\mathbf{y} / \\sigma^2).\n\\end{aligned}\n\\]\n\n\nDiffuse prior\nTo complete model specification, we must choose \\(\\beta_0\\), \\(\\Sigma_0\\), \\(\\sigma_0^2\\) and \\(\\nu_0\\).\nIf we know very little about the relationships between \\(X\\) and \\(\\mathbf{y}\\), we might wish to consider a “diffuse” prior that prescribes a large mass of uncertainty around each parameter.\n\nmath of priorpicture of prior\n\n\n\\[\n\\begin{aligned}\n\\beta & \\sim MVN(0, 1000 I)\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(1, 10)\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampler pseudo-code\n\n\n\n\n\n\npseudo-code\n\n\n\n\npick a starting \\(\\sigma^{2(0)}\\), set \\(s = 0\\). Now for \\(s\\) in 1:S perform 1-3:\nupdate \\(\\beta\\):\n\n\ncompute \\(V\\) and \\(\\mathbf{m}\\)\nsample \\(\\beta^{(s+1)} \\sim MVN(\\mathbf{m}, V)\\)\n\n\nupdate \\(\\sigma^{2}\\):\n\n\ncompute \\(SSR(\\beta^{(s+1)})\\)\nsample \\(1/\\sigma^{2(s+1)} \\sim \\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta^{s+1})]/2)\\)\n\n\nsave the states of \\(\\beta\\) and \\(\\sigma^2\\).\n\n\n\n\n\nCode\nThe Gibbs sampler for our penguin example:\n\n\nCode to reproduce penguins_subset\n# our example examines just a subset of the penguin data\npenguins_subset = penguins %&gt;%\n  select(body_mass_g, flipper_length_mm, bill_length_mm) %&gt;%\n  drop_na() %&gt;%\n  mutate(body_mass_kg = body_mass_g / 1000) %&gt;%\n  select(-body_mass_g)\n\nX = penguins_subset %&gt;%\n  select(-body_mass_kg) %&gt;%\n  mutate(one = rep(1, nrow(penguins_subset))) %&gt;%\n  relocate(one) %&gt;%\n  as.matrix() \n\ny = select(penguins_subset, \n           body_mass_kg) %&gt;%\n  as.matrix()\n\n\n\nset.seed(360)\n# prior hyperparameters \np = 2 # number of covariates\nSigma0 = 1000 * diag(rep(1, p+1)) # p + 1 for intercept term\nb0 = rep(0, p + 1)\nnu0 = 2\nsigma02 = 10\nn = nrow(y)\n\n# starting values\n## note: gamma = 1 / sigma^2\ngamma = 1 / var(penguins_subset$body_mass_kg)\n\n# values we should compute just once\nSigmaInv = solve(Sigma0)\nX2 = t(X) %*% X\nXy = t(X) %*% y\nSIB0 = SigmaInv %*% b0\na = (nu0 + n) / 2\nnu0s02 = nu0 * sigma02\n\n## empty objects to fill\nBETA = NULL\nGAMMA = NULL\n\nS = 2000\nfor (s in 1:S) {\n  ### UPDATE BETA\n  V = solve(SigmaInv + (gamma * X2))\n  m = V %*% (Xy * gamma) # simplified since b0 = 0\n  beta = rmvnorm(1, mean = m, sigma = V)\n  \n  ### UPDATE SIGMA\n  SSR1 = (y - (X %*% t(beta)))\n  SSRB = t(SSR1) %*% SSR1\n  gamma = rgamma(1, a, ((nu0s02 + SSRB) / 2))\n  \n  ### SAVE STATES\n  GAMMA = c(GAMMA, gamma)\n  BETA = rbind(BETA, beta)\n}\n\n\n\nESS?\neffectiveSize(BETA)\n\n\nvar1 var2 var3 \n2000 2000 2000 \n\n\nESS?\neffectiveSize(GAMMA)\n\n\nvar1 \n2000 \n\n\nHow do posterior mean estimates compare to the OLS estimates?\n\nposteriorMean = apply(BETA, 2, mean)\nOLS = lm(body_mass_kg ~ flipper_length_mm + bill_length_mm, data = penguins_subset) \nOLS = OLS$coefficients\nrbind(OLS, posteriorMean)\n\n              (Intercept) flipper_length_mm bill_length_mm\nOLS             -5.736897        0.04814486    0.006047488\nposteriorMean   -5.723741        0.04801443    0.006336029\n\n\nWe might have figured out this is what we were going to see already based on the the fact that the expressions for \\(E[\\beta | \\mathbf{y}, X]\\) and \\(Var[\\beta | \\mathbf{y}, X]\\) look just like \\(E[\\hat{\\beta}_{OLS} | \\beta]\\) and \\(Var[\\hat{\\beta}_{OLS} | \\beta]\\) when the prior information is diffuse.\nWhat was the point of all that extra work? Well, we don’t just have a point estimate and a confidence interval, we have a whole posterior! We can quantify uncertainty about \\(\\beta\\) in an easy and intuitive way.\nUsing the posterior, we may find 95% posterior CI, compute \\(p(\\beta_i &gt; 0 | \\mathbf{y}, X)\\), compute \\(p(\\beta_i &gt; \\beta_j | \\mathbf{y}, X)\\), compute the posterior median, and a whole host of additional queries quickly and intuitively.\nLet’s take a look at the marginal posteriors.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\nIs flipper length or bill length a “more important” predictor of penguin body mass? Why?\n\n\n\n\n\nVisually\nFor each iteration of our Gibbs sampler, we’re sampling a hyperplane, i.e. a set of \\(\\beta\\)s.\n\n\nExercise\n\n\nDiscuss how autocorrelation of \\(\\beta\\)s would affect our sampler based on the animation above."
  },
  {
    "objectID": "notes/lec13-BayesianRegression2.html#ridge-regression-and-the-normal-prior",
    "href": "notes/lec13-BayesianRegression2.html#ridge-regression-and-the-normal-prior",
    "title": "Bayesian regression II",
    "section": "Ridge regression and the normal prior",
    "text": "Ridge regression and the normal prior\nWhat if \\(p &gt; n\\)? In words: what if we have more predictors than observations? \\(X\\) will be wide and therefore have linearly dependent columns.\nIn this case, \\(X^T X\\) is \\(p \\times p\\) but is of rank \\(n &lt; p\\), i.e. \\(X^TX\\) is not full rank and thus not invertible. Therefore, \\(\\hat{\\beta}_{OLS}\\) satisfying \\((X^T X)\\hat{\\beta}_{OLS} = X^T \\mathbf{y}\\) does not exist uniquely.\nSeparately, in the case of multicollinearity, where the columns of \\(X\\) are highly correlated, some eigenvalues of \\(X^TX\\) will be very small, which means \\((X^TX)^{-1}\\) will have very large eigenvalues, i.e. \\(Var(\\hat{\\beta}_{OLS})\\) will be very large.\n\nIntuitively: we can fix this by shrinking some of the \\(\\beta_i\\) towards zero (reducing \\(p\\)).\nAlgebraically: one way we can fix this is by adding some positive quantity on the diagonals.\n\nFrequentists call this sort of algebraic fix “ridge regression” and define the problem thus:\n\\[\n\\hat{\\beta}_{ridge} = \\underset{\\beta}{\\mathrm{argmin}} \\underbrace{(\\mathbf{y} - X\\beta)^T (\\mathbf{y} - X \\beta)}_{\\text{SSR}(\\beta)} + \\underbrace{\\lambda \\beta^T \\beta}_{L_2^2 ~\\text{penalty}}\n\\] where \\(\\lambda\\) is a tuning parameter called the “ridge coefficient”.\nBayesians obtain the same objective via the following prior on \\(\\beta\\),\n\\[\n\\beta | \\sigma^2, \\lambda \\sim MVN(0, \\sigma^2 I /\\lambda)\n\\]\n\nExercise\n\n\nShow that \\(\\hat{\\beta}_{ridge} = E[\\beta | \\mathbf{y}, X, \\sigma^2, \\lambda] = ((X^TX) + \\lambda I)^{-1} X^T \\mathbf{y}\\)."
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html",
    "href": "notes/lec15-hierarchical-intro.html",
    "title": "Hierarchical modeling",
    "section": "",
    "text": "view packages used in these notes\n# load packages\nlibrary(tidyverse)\nlibrary(coda)"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#data-set-school-test-scores",
    "href": "notes/lec15-hierarchical-intro.html#data-set-school-test-scores",
    "title": "Hierarchical modeling",
    "section": "Data set: school test scores",
    "text": "Data set: school test scores\n\nExample from Hoff Ch. 8\n\nEach year, students across North Carolina take an identical standardized test. In our sample, we observe scores from students at \\(m\\) different schools. At the \\(j\\)th school, \\(n_j\\) students take the exam and \\(j \\in \\{1, \\ldots m\\}\\). The exam is designed to give an average score of 50 on a 0 to 100 scale.\n\n# load data\nmathScores = read_csv(\"https://sta360-fa24.github.io/data/mathScores.csv\")\n\n\nCodebook and glimpseSchool scoresAll mean scores\n\n\n\nschool: which school the math score came from\nmathscore: score from 0 to 100 of an individual student\n\n\n\nRows: 1,993\nColumns: 2\n$ school    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ mathscore &lt;dbl&gt; 52.11, 57.65, 66.44, 44.68, 40.57, 35.04, 50.71, 66.17, 39.4…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvert data to list for downstream processing\nY.school.mathscore &lt;- as.matrix(mathScores)\n#### Put data into list form.\nY &lt;- list()\nJ &lt;- max(Y.school.mathscore[, 1])\nn &lt;- ybar &lt;- ymed &lt;- s2 &lt;- rep(0, J)\nfor (j in 1:J) {\n  Y[[j]] &lt;- Y.school.mathscore[Y.school.mathscore[, 1] == j, 2]\n}"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#questions-about-the-data",
    "href": "notes/lec15-hierarchical-intro.html#questions-about-the-data",
    "title": "Hierarchical modeling",
    "section": "Questions about the data",
    "text": "Questions about the data\n\nHow are the schools ranked?\nDoes school 51 have a higher average score than school 41?\nWhat is the probability a single student randomly selected from school 51 performs better on the exam than a single student randomly selected from school 41?"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#model",
    "href": "notes/lec15-hierarchical-intro.html#model",
    "title": "Hierarchical modeling",
    "section": "Model",
    "text": "Model\nSuppose students scores at school \\(j\\) are exchangeable for all \\(n_j\\). By de Finetti’s theorem, this means\n\\[\n\\{y_{1,j}, \\ldots y_{n_j,j} | \\phi_j \\} \\sim \\text{ i.i.d. } p(y|\\phi_j).\n\\] That is, the student’s scores at school \\(j\\) are conditionally i.i.d. given some school specific parameters \\(\\phi_j\\). This describes our within-group sampling variability.\nNow suppose that all the schools we sampled are similar in some way. Maybe they belong to some larger population of schools across the country i.e. schools in North Carolina are somewhat distinct from schools in South Carolina. We might imagine that the school-specific parameters themselves are exchangeable for all \\(m\\). By de Finetti’s theorem, this means\n\\[\n\\{\\phi_1, \\ldots \\phi_m\\} \\sim \\text{ i.i.d. } p(\\phi|\\psi).\n\\]\nIn words, school-specific parameters are conditionally i.i.d. given some population specific parameters \\(\\psi\\). This describes our between-group sampling variability.\nFinally, if our hierarchy stops there, then to complete model specification, we may describe our prior beliefs about \\(\\psi\\) according to some prior density \\(p(\\psi)\\).\n\nExerciseSolution\n\n\nImagine variability among scores is the same across all schools, but there does exist heterogeneity in the mean scores of the schools. Write down the mathematical form of a model that describes this using the normal distribution. What are some priors you could pick on relevant parameters to make sure full conditionals are easy to compute for Gibbs sampling? What are the full conditionals?\n\n\n\n\nsampling distributions:\n\n\\[\n\\begin{aligned}\ny_j | \\theta_j, \\sigma^2 &\\sim N(\\theta_j, \\sigma^2)\\\\\n\\theta_j | \\mu, \\tau^2 &\\sim N(\\mu, \\tau^2)\n\\end{aligned}\n\\]\n\npriors distributions:\n\n\\[\n\\begin{aligned}\n1/\\sigma^2 &\\sim \\text{ gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2/2)\\\\\n1/\\tau^2 &\\sim \\text{ gamma}(\\eta_0/2, \\eta_0 \\tau_0^2/2)\\\\\n\\mu &\\sim N(\\mu_0, \\gamma_0^2)\n\\end{aligned}\n\\]\n\n\n\n\nTo facilitate Gibbs sampling, notice\n\\[\np(\\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2 | \\mathbf{y}_1, \\ldots \\mathbf{y}_m) \\propto\np(\\mu, \\tau^2, \\sigma^2) p(\\theta_1, \\ldots \\theta_m | \\mu, \\tau^2, \\sigma^2) \\times p(\\mathbf{y}_1, \\ldots \\mathbf{y}_m| \\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2)\n\\]\nIt follows that the full conditionals are:\n\\[\n\\begin{aligned}\np(\\mu | \\cdot) &\\propto p(\\mu) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\tau^2 | \\cdot) &\\propto p(\\tau^2) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\sigma^2|\\cdot) &\\propto p(\\sigma^2)\\prod_{j =1}^m \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\\\\\np(\\theta_j | \\cdot) &\\propto p(\\theta_j | \\mu, \\tau^2) \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#gibbs-sampling",
    "href": "notes/lec15-hierarchical-intro.html#gibbs-sampling",
    "title": "Hierarchical modeling",
    "section": "Gibbs sampling",
    "text": "Gibbs sampling\n\n#### MCMC approximation to posterior for the hierarchical normal model\n\n## weakly informative priors\nnu0 &lt;- 1; s20 &lt;- 100\neta0 &lt;- 1; t20 &lt;- 100\nmu0 &lt;- 50; g20 &lt;- 25\n\n## starting values\nm &lt;- length(Y)\nn &lt;- sv &lt;- ybar &lt;- rep(NA, m)\nfor (j in 1:m)\n{\n  ybar[j] &lt;- mean(Y[[j]])\n  sv[j] &lt;- var(Y[[j]])\n  n[j] &lt;- length(Y[[j]])\n}\ntheta &lt;- ybar\nsigma2 &lt;- mean(sv)\nmu &lt;- mean(theta)\ntau2 &lt;- var(theta)\n\n## setup MCMC\nset.seed(1)\nS &lt;- 5000\nTHETA &lt;- matrix(nrow = S, ncol = m)\nMST &lt;- matrix(nrow = S, ncol = 3)\npredictiveY = NULL\n\n## MCMC algorithm\nfor (s in 1:S)\n{\n  # sample new values of the thetas\n  for (j in 1:m)\n  {\n    vtheta &lt;- 1 / (n[j] / sigma2 + 1 / tau2)\n    etheta &lt;- vtheta * (ybar[j] * n[j] / sigma2 + mu / tau2)\n    theta[j] &lt;- rnorm(1, etheta, sqrt(vtheta))\n  }\n  \n  #sample new value of sigma2\n  nun &lt;- nu0 + sum(n)\n  ss &lt;- nu0 * s20\n  for (j in 1:m) {\n    ss &lt;- ss + sum((Y[[j]] - theta[j]) ^ 2)\n  }\n  sigma2 &lt;- 1 / rgamma(1, nun / 2, ss / 2)\n  \n  #sample a new value of mu\n  vmu &lt;- 1 / (m / tau2 + 1 / g20)\n  emu &lt;- vmu * (m * mean(theta) / tau2 + mu0 / g20)\n  mu &lt;- rnorm(1, emu, sqrt(vmu))\n  \n  # sample a new value of tau2\n  etam &lt;- eta0 + m\n  ss &lt;- eta0 * t20 + sum((theta - mu) ^ 2)\n  tau2 &lt;- 1 / rgamma(1, etam / 2, ss / 2)\n  \n  #store results\n  THETA[s, ] &lt;- theta\n  MST[s, ] &lt;- c(mu, sigma2, tau2)\n  \n  # predictive sampling\n  y51 = rnorm(1, mean = theta[51], sd = sqrt(sigma2))\n  y41 = rnorm(1, mean = theta[41], sd = sqrt(sigma2))\n  predictiveY = rbind(predictiveY, c(y51, y41))\n  \n}\n\nmcmc1 &lt;- list(THETA = THETA, MST = MST)"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#mcmc-diagnostics",
    "href": "notes/lec15-hierarchical-intro.html#mcmc-diagnostics",
    "title": "Hierarchical modeling",
    "section": "MCMC diagnostics",
    "text": "MCMC diagnostics\n\ntrace plots\n\nplotscode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolnames(MST) = c(\"mu\", \"sigma2\", \"tau2\")\nMST2 = MST %&gt;%\n  as.data.frame() %&gt;% \n  pivot_longer(cols = 1:3)\n\nMST2 %&gt;%\n  ggplot(aes(x = seq(1, nrow(MST2)), y = value)) +\n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ name, scales = \"free_y\") +\n  labs(y = \"mu\",\n       x = \"iteration\",\n       title = \"Traceplot of 5000 Gibbs samples\")\n\n\n\n\n\n\neffective sample size and autocorrelation\n\neffectiveSize(MST)\n\n      mu    sigma      tau \n3925.336 4461.112 2905.517 \n\npar(mfrow=c(1,3))\nacf(MST[,1])\nacf(MST[,2]) \nacf(MST[,3]) \n\n\n\n\n\n\n\n\n\n\nposterior means and standard error\n\n# MC error of mu, sigma2, tau2\nMCERR &lt;- apply(MST,2,sd)/sqrt( effectiveSize(MST) )\napply(MST,2,mean)\n\n      mu    sigma      tau \n48.12530 84.82892 24.79410 \n\nMCERR\n\n         mu       sigma         tau \n0.008528321 0.041664073 0.082344432 \n\n\nWe can do the exact same for the thetas, but the output will be 100 lines, so I suppress output below.\n\n# MC error of thetas\neffectiveSize(THETA) -&gt; esTHETA\nTMCERR &lt;- apply(THETA,2,sd)/sqrt( effectiveSize(THETA) )\nTMCERR"
  },
  {
    "objectID": "notes/lec15-hierarchical-intro.html#answers",
    "href": "notes/lec15-hierarchical-intro.html#answers",
    "title": "Hierarchical modeling",
    "section": "Answers",
    "text": "Answers\n\nHow are the schools ranked? How does the ordering compare to just ranking the schools by the sample means?\n\n\n# Ordering E[theta | data] and comparing to ybar\n\nposteriorMean = THETA %&gt;%\n  apply(2, mean)\n\norderedTable = mathScores %&gt;%\n  group_by(school) %&gt;%\n  summarize(ybar = mean(mathscore),\n            n = n()) %&gt;%\n  cbind(posteriorMean) %&gt;%\n  arrange(posteriorMean) %&gt;%\n  relocate(school, n, ybar, posteriorMean) %&gt;%\n  mutate_if(is.numeric, round, digits = 2)\n\nDT::datatable(\n  orderedTable,\n  fillContainer = FALSE, options = list(pageLength = 10)\n)\n\n\n\n\n\nHow many of the schools are ranked in the same position in the posterior ordering as the sample mean ordering?\n\noutputcode\n\n\n\n\n[1] 46\n\n\n\n\n\npostOrdering = posteriorMean %&gt;%\n  order()\n\nybarOrdering = mathScores %&gt;%\n  group_by(school) %&gt;%\n  summarize(ybar = mean(mathscore), \n            n = n()) %&gt;%\n  arrange(ybar) %&gt;%\n  pull(school)\n\nsum(postOrdering == ybarOrdering)\n\n\n\n\n\nDoes school 51 have a higher average score than school 41? Re-cast as a Bayesian question: what’s \\(p(\\theta_{51} &gt; \\theta_{41} | \\text{data})\\)?\n\n\nmean(THETA[,51] &gt; THETA[,41])\n\n[1] 0.9892\n\n\n\nWhat’s the probability a student randomly selected from school 51 performs better than a student selected randomly from school 41?\n\nBefore looking at the solution below, how would you answer this problem?\n\n\nSolution\nmean(predictiveY[,1] &gt; predictiveY[,2])\n\n# output:\n# [1] 0.685"
  },
  {
    "objectID": "notes/lec09-MCMC.html",
    "href": "notes/lec09-MCMC.html",
    "title": "MCMC Properties and Diagnostics",
    "section": "",
    "text": "View libraries used in these notes\nlibrary(tidyverse)"
  },
  {
    "objectID": "notes/lec09-MCMC.html#ergodic-theorem",
    "href": "notes/lec09-MCMC.html#ergodic-theorem",
    "title": "MCMC Properties and Diagnostics",
    "section": "Ergodic theorem",
    "text": "Ergodic theorem\nUnder what conditions does Metropolis-Hastings MCMC work?\nErgodic theorem: If \\(\\{\\theta^{(1)}, \\theta^{(2)}, \\ldots \\}\\) is an irreducible, aperiodic and recurrent Markov chain, then there is a unique probability distribution \\(\\pi\\) such that as \\(s \\rightarrow \\infty\\),\n\n\\(Pr(\\theta^{(s)} \\in \\mathcal{A}) \\rightarrow \\pi(\\mathcal{A})\\) for any set \\(\\mathcal{A}\\);\n\\(\\frac{1}{S} \\sum g(\\theta^{(s)}) \\rightarrow \\int g(x) \\pi(x) dx\\)."
  },
  {
    "objectID": "notes/lec09-MCMC.html#definitions",
    "href": "notes/lec09-MCMC.html#definitions",
    "title": "MCMC Properties and Diagnostics",
    "section": "Definitions",
    "text": "Definitions\n\nstationary distribution\n\\(\\pi\\) is called the stationary distribution of the Markov chain because if \\(\\theta^{(s)} \\sim \\pi\\) and \\(\\theta^{(s+1)}\\) is generated from the Markov chain starting at \\(\\theta^{(s)}\\), then \\(Pr(\\theta^{(s+1)} \\in \\mathcal{A}) = \\pi(\\mathcal{A})\\).\n\n\nirreducible\nA chain is reducible if the state-space can be divided into non-overlapping sets (due to some \\(J\\)). In practice, the proposal \\(J(\\theta^* | \\theta^{(s)})\\) needs to let us go from any value of \\(\\theta\\) to any other, eventually.\n\n\naperiodic\nWe want our Markov chain to be aperiodic. A value \\(\\theta\\) is said to be periodic with period \\(k&gt;1\\) if it can only be visited every \\(k\\)th iteration. A Markov chain without periodic states is aperiodic.\n\n\nrecurrent\nA value \\(\\theta\\) is recurrent if we are guaranteed to return to it eventually."
  },
  {
    "objectID": "notes/lec09-MCMC.html#mcmc-vocabulary",
    "href": "notes/lec09-MCMC.html#mcmc-vocabulary",
    "title": "MCMC Properties and Diagnostics",
    "section": "MCMC Vocabulary",
    "text": "MCMC Vocabulary\n\nautocorrelation: how correlated consecutive values in the Markov chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\] where \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. Practically, we use acf function in R. Example:\n\nacf(THETA1, plot = FALSE)\n\n\nAutocorrelations of series 'THETA1', by lag\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n1.000 0.913 0.845 0.786 0.735 0.691 0.650 0.615 0.584 0.554 0.528 0.502 0.479 \n   13    14    15    16    17    18    19    20    21    22    23    24    25 \n0.458 0.436 0.418 0.400 0.384 0.370 0.354 0.339 0.322 0.302 0.288 0.276 0.264 \n   26    27    28    29    30    31    32    33    34    35    36    37    38 \n0.252 0.242 0.232 0.220 0.208 0.198 0.190 0.181 0.171 0.162 0.155 0.145 0.135 \n   39    40 \n0.124 0.113 \n\n\nThe higher the autocorrelation, the more samples we need to obtain a given level of precision for our approximation. One way to state how precise our approximation is, is with effective sample size.\n\neffective sample size (ESS): intuitively this is the effective number of exact samples “contained” in the Markov chain (see Betancourt 2018). For further reading on ESS, see the stan manual. In practice we use coda::effectiveSize() function to compute. Example:\n\n\nlibrary(coda)\neffectiveSize(THETA1)\n\n    var1 \n302.4272 \n\n\nMore precisely, the effective sample size (ESS) is the value \\(S_{eff}\\) such that\n\\[\nVar_{MCMC}[\\bar{\\phi}] = \\frac{Var[\\phi]}{S_{eff}}.\n\\] In words, it’s the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. For comparison, recall \\(Var_{MC}[\\bar{\\phi}] = Var[\\phi]/S\\)\n\nStationarity is when samples taken in one part of the chain have a similar distribution to samples taken from other parts of the chain. Intuitively, we want the particle to move from our arbitrary starting point to regions of higher probability\\(^*\\), then we will say it has achieved stationarity.\n\nTraceplots are a great way to visually inspect whether a chain has converged, or achieved stationarity. In the traceplot from the previous lecture, we can see that samples from the beginning of the chain look very different than samples at the end for delta = 0.1.\n\\(^*\\) recall that probability is really a volume in high dimensions of parameter space, and so it is not enough for a pdf to evaluate to a high value, there must also be sufficient volume.\n\nMixing: how well the particle moves between sets of high probability. Some might refer to this as how well the particle sojourns across the “typical set” (regions of high probability)."
  },
  {
    "objectID": "slides/SIR-slides.html#install-packages",
    "href": "slides/SIR-slides.html#install-packages",
    "title": "Bayesian inverse problem practice",
    "section": "Install packages",
    "text": "Install packages\nWe will use the library deSolve “differential equation solve” to solve a system of differential equations in this lab. You can install the package using the code below.\n\ninstall.packages(\"deSolve\")\n\nand then load the package with the following code chunk.\n\nlibrary(deSolve)"
  },
  {
    "objectID": "slides/SIR-slides.html#data",
    "href": "slides/SIR-slides.html#data",
    "title": "Bayesian inverse problem practice",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "slides/SIR-slides.html#exercise",
    "href": "slides/SIR-slides.html#exercise",
    "title": "Bayesian inverse problem practice",
    "section": "Exercise",
    "text": "Exercise"
  },
  {
    "objectID": "slides/SIR-slides.html#solution",
    "href": "slides/SIR-slides.html#solution",
    "title": "Bayesian inverse problem practice",
    "section": "Solution",
    "text": "Solution\n\nsir_equations &lt;- function(time, variables, parameters) {\n  with(as.list(c(variables, parameters)), {\n    dS &lt;- -beta * I * S\n    dI &lt;-  beta * I * S - gamma * I\n    dR &lt;-  gamma * I\n    return(list(c(dS, dI, dR)))\n  })\n}\n\n\nparameters_values &lt;- c(\n  beta  = 0.004, # infectious contact rate (/person/day)\n  gamma = 0.5    # recovery rate (/day)\n)\n\n\ninitial_values &lt;- c(\n  S = 999,  # number of susceptibles at time = 0\n  I =   1,  # number of infectious at time = 0\n  R =   0   # number of recovered (and immune) at time = 0\n)\ntime_values &lt;- seq(0, 10) # days\nls()\n\n[1] \"initial_values\"    \"parameters_values\" \"sir_equations\"    \n[4] \"time_values\"      \n\n\n\nsir_values_1 &lt;- ode(\n  y = initial_values,\n  times = time_values,\n  func = sir_equations,\n  parms = parameters_values \n)\n\nsir_values_1\n\n   time           S         I          R\n1     0 999.0000000   1.00000   0.000000\n2     1 963.7055761  31.79830   4.496125\n3     2 461.5687749 441.91575  96.515480\n4     3  46.1563480 569.50418 384.339476\n5     4   7.0358807 373.49831 619.465807\n6     5   2.1489407 230.12934 767.721720\n7     6   1.0390927 140.41085 858.550058\n8     7   0.6674074  85.44479 913.887801\n9     8   0.5098627  51.94498 947.545162\n10    9   0.4328913  31.56515 968.001960\n11   10   0.3919173  19.17668 980.431400\n\n\n\nsir_1 &lt;- function(beta, gamma, S0, I0, R0, times) {\n  require(deSolve) # for the \"ode\" function\n  \n# the differential equations:\n  sir_equations &lt;- function(time, variables, parameters) {\n    with(as.list(c(variables, parameters)), {\n      dS &lt;- -beta * I * S\n      dI &lt;-  beta * I * S - gamma * I\n      dR &lt;-  gamma * I\n      return(list(c(dS, dI, dR)))\n    })\n  }\n  \n# the parameters values:\n  parameters_values &lt;- c(beta  = beta, gamma = gamma)\n\n# the initial values of variables:\n  initial_values &lt;- c(S = S0, I = I0, R = R0)\n  \n# solving\n  out &lt;- ode(initial_values, times, sir_equations, parameters_values)\n\n# returning the output:\n  as.data.frame(out)\n}\n\n\nsir_1(beta = 0.004, gamma = 0.5, S0 = 999, I0 = 1, R0 = 0, times = seq(0, 10))\n\n   time           S         I          R\n1     0 999.0000000   1.00000   0.000000\n2     1 963.7055761  31.79830   4.496125\n3     2 461.5687749 441.91575  96.515480\n4     3  46.1563480 569.50418 384.339476\n5     4   7.0358807 373.49831 619.465807\n6     5   2.1489407 230.12934 767.721720\n7     6   1.0390927 140.41085 858.550058\n8     7   0.6674074  85.44479 913.887801\n9     8   0.5098627  51.94498 947.545162\n10    9   0.4328913  31.56515 968.001960\n11   10   0.3919173  19.17668 980.431400\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-1-exponential-family",
    "href": "slides/lab-exp-families.html#ex-1-exponential-family",
    "title": "Exponential families & variable transformation",
    "section": "Ex 1: exponential family",
    "text": "Ex 1: exponential family\nLet \\(p(y|\\theta) = \\theta^{y}(1-\\theta)^{1-y}\\)\n\nIdentify the transform \\(\\phi = f(\\theta)\\) such that \\(p(y | \\phi)\\) can be written as \\(h(y) c(\\phi) e^{\\phi t(y)}\\). Identify the sufficient statistic \\(t(y)\\), as well as \\(c(\\phi)\\).\nWrite down the conjugate prior \\(p(\\phi|n_0, t_0)\\)."
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-2-variable-transform",
    "href": "slides/lab-exp-families.html#ex-2-variable-transform",
    "title": "Exponential families & variable transformation",
    "section": "Ex 2: variable transform",
    "text": "Ex 2: variable transform\nConfirm that \\(f(\\theta)\\) from the previous exercise is monotonic and invertible. Next, using the one-line formula: \\(p_\\theta(\\theta) = p_{\\phi}(f(\\theta))|\\frac{d\\phi}{d\\theta}|\\), show that the prior, \\(p(\\theta | n_0, t_0)\\) is a beta density.\nTo verify the above numerically, sample from \\(p(\\theta | n_0, t_0)\\) using the code below, for some \\(n_0, t_0\\) of your choosing.\ntheta = rbeta(n = 10000, shape1 = n_0 * t_0, shape2 = n_0*(1-t_0)\nNext, transform each sample of the object theta to phi using \\(f(\\theta)\\) as defined in exercise 1.\nFinally, plot a density plot of samples phi and, on the same plot, add \\(p(\\phi | n_0, t_0)\\) from exercise 1."
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-3-another-variable-transform",
    "href": "slides/lab-exp-families.html#ex-3-another-variable-transform",
    "title": "Exponential families & variable transformation",
    "section": "Ex 3: another variable transform",
    "text": "Ex 3: another variable transform\nLet \\(X \\sim \\text{Unif}(5, 10)\\) and let \\(Y = X^2\\)\nNotice that even though \\(X^2\\) is not a monotonic function everywhere, it is a monotonic function over the support of X.\nExercise: use the change of variables formula to derive \\(p(y)\\). Confirm via simulation, as in exercise 2."
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-1-solution",
    "href": "slides/lab-exp-families.html#ex-1-solution",
    "title": "Exponential families & variable transformation",
    "section": "Ex 1: solution",
    "text": "Ex 1: solution\na\n\\[\n\\phi = log(\\frac{\\theta}{1-\\theta})\n\\]\nTherefore,\n\\[\np(y|\\phi) = e^{\\phi y} \\left(\\frac{1}{1 + e^{\\phi}} \\right)\n\\]\nand\n\\[\n\\begin{aligned}\nt(y) &= y\\\\\nc(\\phi) &= \\left(\\frac{1}{1 + e^{\\phi}} \\right)\n\\end{aligned}\n\\]\nb\n\\[\np(\\phi | n_0, t_0) \\propto \\left({1 + e^{\\phi}} \\right)^{-n_0} e^{n_0 t_0 \\phi}\n\\]"
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-2-solution",
    "href": "slides/lab-exp-families.html#ex-2-solution",
    "title": "Exponential families & variable transformation",
    "section": "Ex 2: solution",
    "text": "Ex 2: solution\nMonotonic if \\(\\theta_1 \\geq \\theta_2\\) implies \\(f(\\theta_1) \\geq f(\\theta_2)\\) over the support \\(\\theta_1, \\theta_2 \\in [0,1]\\).\nLet \\(\\theta_1 &gt; \\theta_2\\), let’s check:\n\\[\n\\begin{aligned}\n\\log \\left(\\frac{\\theta_1}{1-\\theta_1}\\right) &&gt; \\log \\left(\\frac{\\theta_2}{1-\\theta_2}\\right)\\\\\n\\theta_1 (1-\\theta_2) &&gt; \\theta_2(1-\\theta_1)\\\\\n\\theta_1 &gt; \\theta_2\n\\end{aligned}\n\\]\nIt is monotonic!\nFurthermore, we found it was invertible in ex 1: \\(\\theta = e^{\\phi}/(1 + e^{\\phi})\\).\nOne-line formula: \\(p_\\theta(\\theta) = p_{\\phi}(f(\\theta))|\\frac{d\\phi}{d\\theta}|\\):\n\\[\n\\begin{aligned}\np(\\theta) &\\propto (1-\\theta)^{n_0} (\\theta/(1-\\theta))^{n_0 t_0} \\left|\\frac{d\\phi}{d\\theta} \\right|\\\\\n&= \\theta^{n_0 t_0 -1} (1-\\theta)^{n_0(1 -t_0) - 1}\n\\end{aligned}\n\\]\nSo \\(\\theta \\sim \\text{beta}(n_0 t_0, n_0(1-t_0))\\).\nRemember that \\(a\\) and \\(b\\) of a beta distribution must both be positive! This constrains what \\(n_0\\) and \\(t_0\\) can be."
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-2-solution-pt-2",
    "href": "slides/lab-exp-families.html#ex-2-solution-pt-2",
    "title": "Exponential families & variable transformation",
    "section": "Ex 2: solution (pt 2)",
    "text": "Ex 2: solution (pt 2)\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nn_0 = 5\nt_0 = .5\ntheta = rbeta(n = 100000, shape1 = n_0 * t_0, shape2 = n_0 * (1 - t_0))\nphi = log((theta / (1-theta)))\n\ndf = data.frame(phi)\n\nfphi = function(phi, n_0, t_0) {\n  ( (1 + exp(phi))^(-n_0) ) * exp(n_0 * t_0 * phi) / \n    beta(n_0 * t_0, n_0 * (1 - t_0))\n}\n\ndf %&gt;%\n  ggplot(aes(x = phi)) + \n  stat_function(fun = fphi, args = list(n_0 = n_0, t_0 = t_0)) +\n  geom_histogram(aes(x = phi, y = ..density..),\n                 fill = 'steelblue', alpha = 0.5)\n\n\n\n\nThe normalizing constant can be obtained by transforming from \\(p(\\theta)\\) (which is beta) back to \\(p(\\phi)\\)."
  },
  {
    "objectID": "slides/lab-exp-families.html#ex-3-solution",
    "href": "slides/lab-exp-families.html#ex-3-solution",
    "title": "Exponential families & variable transformation",
    "section": "Ex 3: solution",
    "text": "Ex 3: solution\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = runif(100000, 5, 10)\ny = x^2\n\ndf = data.frame(y)\n\nf = function(y) {\n  return(.1/sqrt(y))\n}\n\ndf %&gt;%\n  ggplot(aes(x = y)) + \n  stat_function(fun = f) +\n  geom_histogram(aes(x = y, y = ..density..),\n                 fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/lec03-Poisson-gamma-exp-families.html",
    "href": "notes/lec03-Poisson-gamma-exp-families.html",
    "title": "NBA Assists",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec03-Poisson-gamma-exp-families.html#data-boston-celtics",
    "href": "notes/lec03-Poisson-gamma-exp-families.html#data-boston-celtics",
    "title": "NBA Assists",
    "section": "Data: Boston Celtics",
    "text": "Data: Boston Celtics\nIn basketball, an “assist” is attributed to a player that passes the ball to a teammate in a way that directly leads to a basket. The data below was scraped from espn.com September 2024. Each row of the data set is an individual Boston Celtics player during a particular game of the 2023-2024 season. The AST records the number of assists made by the player in the particular game. MIN records the number of minutes each player played in a particular game. vs records the opposing team.\n\ndata samplecode\n\n\n\n\n# A tibble: 10 × 4\n   player                 AST   MIN vs                   \n   &lt;chr&gt;                &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                \n 1 Payton Pritchard PG      4  23.5 Golden State Warriors\n 2 Derrick White PG         4  33.5 Dallas Mavericks     \n 3 Jaylen Brown SG          4  34   Brooklyn Nets        \n 4 Luke Kornet C            2  21.3 Chicago Bulls        \n 5 Xavier Tillman F *       2  15   Dallas Mavericks     \n 6 Luke Kornet C            1  19   Dallas Mavericks     \n 7 Kristaps Porzingis C     1  23.7 Brooklyn Nets        \n 8 Kristaps Porzingis C     1  30   Chicago Bulls        \n 9 Oshae Brissett SF        0   4   Dallas Mavericks     \n10 Luke Kornet C            0  11   Golden State Warriors\n\n\n\n\n\nset.seed(360)\nyx = read_csv(\"../data/BostonCeltics_Assists_23-24_season.csv\")\n\nyx %&gt;%\n  slice_sample(n = 10) %&gt;%\n  arrange(desc(AST))\n\n\n\n\nQuestion: how many assists on average do we expect a Celtics player to make per minute played?"
  },
  {
    "objectID": "notes/lec03-Poisson-gamma-exp-families.html#bayesian-framework",
    "href": "notes/lec03-Poisson-gamma-exp-families.html#bayesian-framework",
    "title": "NBA Assists",
    "section": "Bayesian framework",
    "text": "Bayesian framework\n\nDefine a data generative model and write down the likelihood (often assuming exchangeability and invoking de Finetti’s theorem)\nChoose a prior distribution for all things unknown\nCompute or approximate the posterior\nMake inference\n\n\nData-generative model\nTo write down a data generative model, let’s assume players accumulate assists \\(y\\) at some per-minute rate, \\(\\theta\\). We will further assume that the expected number of assists by a player in a given game is then \\(\\theta x\\) where \\(x\\) is the number of minutes played.\nGiven \\(y\\) takes integer values \\(\\{0, 1, 2, \\ldots \\}\\), a Poisson distribution might make sense. If \\(Y | \\lambda\\) is Poisson\\((\\lambda)\\), then\n\\[\np(y |\\lambda) = \\frac{(\\lambda)^y e^{-\\lambda}}{y!}\n\\]\nHere, \\(\\lambda = \\theta x\\).\nAssuming this conditionally independent model for generating \\(y\\)s, we write the likelihood,\n\\[\np(y_1,\\ldots y_n | \\theta) = \\prod_{i = 1}^n \\frac{(\\theta x_i)^{y_i} e^{-\\theta x_i}}{y_i!}\n\\]\n\nExercise\n\n\nWhat assumptions are we making about assists in the data generative model above?\n\n\n\n\n\n\nPrior beliefs\n\nNotice the support: \\(\\theta &gt; 0\\)\nA gamma prior may be suitable\n\n\\[\n\\begin{aligned}\n\\theta &\\sim gamma(a, b)\\\\\np(\\theta | a, b) &= \\frac{b^{a}}{\\Gamma(a)} \\theta^{a - 1} e^{-b \\theta}\n\\end{aligned}\n\\] ### Compute the posterior\n\nExerciseSolution\n\n\nCompute the posterior.\n\n\n\\[\n\\begin{aligned}\n\\theta | y_1,\\ldots y_n &\\sim gamma(\\alpha, \\beta)\\\\\n\\alpha &= a + \\sum_{i=1}^n y_i\\\\\n\\beta &= b + \\sum_{i=1}^n x_i\n\\end{aligned}\n\\]\n\n\n\nHint: we have conjugacy. You can see this if you view the likelihood and the prior each as a function of \\(\\theta\\), the kernel of each has the same functional form.\nFollow-up:\n\nwhat is \\(E[\\theta | y_1,\\ldots, y_n]\\)? How does it compare to \\(E[\\theta]\\)?\nwhat is \\(Var[\\theta | y_1,\\ldots y_n]\\)?\n\n\nplot posteriorcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na = 9\nb = 3\nsumY = sum(yx$AST)\nsumX = sum(yx$MIN)\n\ndata.frame(x = c(0, 0.5)) %&gt;%\n  ggplot(aes(x = x)) + \n  stat_function(fun = dgamma, args = list(shape = sumY + a,\n                                          rate = sumX + b)) + \n  labs(x = TeX(\"$\\\\theta$\"), y = TeX(\"p($\\\\theta | y_1, \\\\ldots, y_n$)\")) +\n  theme_bw()\n\n\n\n\nGiven our prior of \\(a = 9, b = 3\\), \\(E[\\theta | y_1,\\ldots, y_n] =\\) 0.1194"
  },
  {
    "objectID": "notes/lec03-Poisson-gamma-exp-families.html#exponential-families",
    "href": "notes/lec03-Poisson-gamma-exp-families.html#exponential-families",
    "title": "NBA Assists",
    "section": "Exponential families",
    "text": "Exponential families\nDefinition: a sufficient statistic is a function of the data \\((y_1,\\ldots y_n\\)) that is sufficient to make inference about unknown parameters (\\(\\theta\\)).\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family.\n\n\n\n\n\n\nNote\n\n\n\n\\(t(y)\\) is referred to as the sufficient statistic.\n\n\nIf \\(p(y|\\theta)\\) belongs in the exponential family, then the conjugate prior is \\[\np(\\phi | n_0, t_0) = \\kappa(n_0, t_0)c(\\phi)^{n_0} e^{n_0 t_0 \\phi},\n\\] where \\(\\kappa(n_0, t_0)\\) is a normalizing constant.\n\n\n\n\n\n\nNotes about the prior\n\n\n\n\nthe conjugate prior is given over \\(\\phi\\) and we’d have to transform back if we care about \\(p(\\theta)\\).\n\\(n_0\\) is interpreted as the prior sample size and \\(t_0\\) is the prior guess.\n\n\n\nThe resulting posterior is\n\\[\np(\\phi | y_1,\\ldots y_n) \\propto p \\left(\\phi | n_0 + n, \\frac{n_0 t_0 + n \\sum t(y_i)/n}{n_0 + n}\\right)\n\\] In words, one can show that the kernel of the posterior of \\(\\phi\\) is proportional to the kernel of the prior of \\(\\phi\\) with specific parameters. Thereby, we have conjugacy.\n\nExample offline: Poisson density"
  },
  {
    "objectID": "notes/lec05-introMonteCarlo.html",
    "href": "notes/lec05-introMonteCarlo.html",
    "title": "Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec05-introMonteCarlo.html#monte-carlo-motivation",
    "href": "notes/lec05-introMonteCarlo.html#monte-carlo-motivation",
    "title": "Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2|\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?\nWhat about the probability a woman with a bachelor’s has more children than a woman without a bachelors? \\(p(\\tilde{y}_1  &lt; \\tilde{y}_2 | \\vec{y_1}, \\vec{y_2})\\)?"
  },
  {
    "objectID": "notes/lec05-introMonteCarlo.html#monte-carlo-integration",
    "href": "notes/lec05-introMonteCarlo.html#monte-carlo-integration",
    "title": "Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(\\theta\\), the sample mean \\(\\bar{\\theta}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\] then the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) p(\\theta | y)d\\theta \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)}).\n\\]\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) converges to \\(E~g(\\theta)|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/lec05-introMonteCarlo.html#examples",
    "href": "notes/lec05-introMonteCarlo.html#examples",
    "title": "Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %&gt;%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(|\\theta_1 - \\theta_2|\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = abs(theta1 - theta2))\n\ndf %&gt;%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$|\\\\theta_1 - \\\\theta_2|$\"),\n       y = TeX(\"$p(|\\\\theta_1 - \\\\theta_2 || {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n\n\n\n\n(3) \\(p(|\\theta_1 - \\theta_2|&gt; .5)\\)\n\nmean(df$diff &gt; .5)\n\n[1] 0.4108\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta  \\sim \\text{uniform}(0, 2)\\)\nLet \\(\\phi = \\log \\theta\\)\nVisualize \\(p(\\phi)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000, 0, 2)\n\n# define transform function\nf = function(x) {\n  return(0.5 *exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(phi = -7:0)\ndf2 = data.frame(phiSamples = log(theta))\n\n# make plots\ndf %&gt;%\n  ggplot(aes(x = phi)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = phiSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000, 0, 2)\nphi = log(theta)\nhist(phi)\n\n\n\n\n\n\n\n\n\n\n\n\nExerciseSolution\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat is \\(Pr(\\tilde{y}_1  &lt; \\tilde{y}_2 | \\vec{y_1}, \\vec{y_2})\\)?\n\n\n\n\n\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ny1tilde = rpois(N, theta1)\ny2tilde = rpois(N, theta2)\n\n# y1: no. children to parent w/ no bachelors\n# y2: no. children to parent w/ bachelors\nmean(y1tilde &lt; y2tilde)\n\n[1] 0.307"
  },
  {
    "objectID": "hw/hw2023_09.html",
    "href": "hw/hw2023_09.html",
    "title": "Homework 9",
    "section": "",
    "text": "To load the data for this exercise, run the code below.\n\nyX = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-train.csv\")\nyX.test = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-test.csv\")\n\nThe file azdiabetes-train.csv contains data on health-related variables of a population of 432 women. In this exercise we will be modeling the conditional distribution of glucose level (glu) as a linear combination of the other variables, excluding the variable diabetes.\n\nFit a regression model using the g-prior with \\(g = n\\), \\(\\nu_0 = 2\\) and \\(\\sigma_0^2 = 1\\). Obtain 95% posterior confidence intervals for all of the parameters. Note: you do not need a Gibbs sampler for this problem, see p 159 of Hoff.\nFit a MVN linear model using rstanarm with priors \\(\\beta_i \\sim N(0, 1)\\) and a flat prior on \\(\\sigma\\). Report the posterior mean and 95% confidence intervals for all parameters.\nPerform the model selection and averaging procedure described in section 9.3. See secton 9.3.1 for the model and pg 168 for sample code to sample \\(\\mathbf{z}\\). Obtain \\(Pr(\\beta_j \\neq 0 | y)\\), as well as posterior confidence intervals for all of the parameters. Compare to the results in part (a) and (b). Additionally, compare the average squared error of predictions using the data set azdiabetes-test.csv under all three fitted models."
  },
  {
    "objectID": "hw/hw2023_09.html#exercise-1",
    "href": "hw/hw2023_09.html#exercise-1",
    "title": "Homework 9",
    "section": "",
    "text": "To load the data for this exercise, run the code below.\n\nyX = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-train.csv\")\nyX.test = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-test.csv\")\n\nThe file azdiabetes-train.csv contains data on health-related variables of a population of 432 women. In this exercise we will be modeling the conditional distribution of glucose level (glu) as a linear combination of the other variables, excluding the variable diabetes.\n\nFit a regression model using the g-prior with \\(g = n\\), \\(\\nu_0 = 2\\) and \\(\\sigma_0^2 = 1\\). Obtain 95% posterior confidence intervals for all of the parameters. Note: you do not need a Gibbs sampler for this problem, see p 159 of Hoff.\nFit a MVN linear model using rstanarm with priors \\(\\beta_i \\sim N(0, 1)\\) and a flat prior on \\(\\sigma\\). Report the posterior mean and 95% confidence intervals for all parameters.\nPerform the model selection and averaging procedure described in section 9.3. See secton 9.3.1 for the model and pg 168 for sample code to sample \\(\\mathbf{z}\\). Obtain \\(Pr(\\beta_j \\neq 0 | y)\\), as well as posterior confidence intervals for all of the parameters. Compare to the results in part (a) and (b). Additionally, compare the average squared error of predictions using the data set azdiabetes-test.csv under all three fitted models."
  },
  {
    "objectID": "hw/hw2023_09.html#exercise-2",
    "href": "hw/hw2023_09.html#exercise-2",
    "title": "Homework 9",
    "section": "Exercise 2",
    "text": "Exercise 2\nExercise 10.2 from Hoff.\nTo load the data for this exercise, run the code below,\n\nyXsparrow = readr::read_csv(\"https://sta360-fa23.github.io/data/yXsparrow.csv\")\n\nInstead of 1000, please run your chain until you reach at least 100 effective sample size."
  },
  {
    "objectID": "hw/hw2023_09.html#exercise-3",
    "href": "hw/hw2023_09.html#exercise-3",
    "title": "Homework 9",
    "section": "Exercise 3",
    "text": "Exercise 3\nCode for this exercise is provided below,\n\n# load the data\ntrans.prob.mat = readRDS(url(\"https://sta360-fa23.github.io/data/trans-prob-mat.rds\"))\ncipher_text = readLines(\"https://sta360-fa23.github.io/data/ciphertext.txt\")\n\npl = function(decoded) {\n  logprob = 0\n  prevletter = \"SPACE\"\n  for (i in 1:nchar(decoded)) {\n    curletter = substring(decoded, i, i)\n    if(curletter == \" \") {\n      curletter = \"SPACE\"\n    }\n    logprob = logprob + log(trans.prob.mat[rownames(trans.prob.mat) == prevletter,\n                                             colnames(trans.prob.mat) == curletter])\n    prevletter = curletter\n  }\n  return(logprob)\n} \n\nIn this exercise we will re-create the cryptanalysis tool described here to decrypt a secret message. Read pages 1-3 of the article by Persi Diaconis linked above.\n\nLoad the object trans.prob.matrix using the code above and examine. Based on your reading of the article, how can you interpret the entries of this matrix? Is it symmetric or not? Why does this make sense? The function pl(), given above, computes the “plausibility” score for a given decoding. Explain in detail what the code comprising pl() does.\nFollow the pseudo-code outlined on page 2 of the article to write a MCMC algorithm and decrypt the secret message. Run your Markov chain for at least 1000 iterations and report the decoding with the highest plausibility score."
  },
  {
    "objectID": "slides/BayesianInverseProblem.html#e.-coli",
    "href": "slides/BayesianInverseProblem.html#e.-coli",
    "title": "Inverse problem",
    "section": "E. coli",
    "text": "E. coli\n\n\nCode\nlibrary(tidyverse)\n\n\nE. coli grows in a petri dish according to the logistic growth equation,\n\\[\n\\frac{dP}{dt} = rP( 1 - \\frac{P}{K})\n\\]\nwhere \\(P(t)\\) is the population size at time \\(t\\), \\(r\\) is the per capita growth rate, and \\(K\\) is the carrying capacity of the dish.\nThis equation can be solved analytically (which is what makes this a toy example),\n\\[\nP(t) = \\frac{K}{1 + Ae^{-rt}}\n\\] where \\(A = \\frac{K - P_0}{P_0}\\) and \\(P_0\\) is the initial population size at time 0.\nBut what if we could not solve solve the equation in closed form and, instead, could only simulate from the data generative model given a set of parameter values \\(K\\), \\(r\\) and \\(P(0)\\)."
  },
  {
    "objectID": "slides/BayesianInverseProblem.html#data",
    "href": "slides/BayesianInverseProblem.html#data",
    "title": "Inverse problem",
    "section": "Data",
    "text": "Data\nBacterial populations are measured in CFU (colony forming units). At time \\(t = 0\\), 1 colony forming unit was placed into a dish.\n\npopulationFunction = function(K, r, t) {\n  P0 = 1\n  A = (K - P0) / P0\n  round(K / (1 + (A * exp(-r * t))))\n}\n\nIn the past, CFU are counted manually in a small pipetted sample and then the CFU per unit volume are multiplied by the total volume in the dish to estimate the total population size of bacteria at a given time \\(t\\).\nA new machine has been created to replace this mundane task by automating the counting of CFUs in a sample. The machine counts the bacteria in the dish every fifteen minutes since the start of the experiment. Data are provided below.\n\ny = read_csv(\"https://sta602-sp25.github.io/data/E_coli.csv\")\nglimpse(y)\n\nRows: 24\nColumns: 2\n$ P    &lt;dbl&gt; 2, 3, 5, 8, 13, 22, 37, 64, 103, 186, 318, 542, 843, 1490, 2283, …\n$ time &lt;dbl&gt; 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 2…\n\n\nNote: time is in minutes."
  },
  {
    "objectID": "slides/BayesianInverseProblem.html#model",
    "href": "slides/BayesianInverseProblem.html#model",
    "title": "Inverse problem",
    "section": "Model",
    "text": "Model\nWe know \\(P_0 = 1\\). Let \\(\\theta = \\{r, K\\}\\)\nWe assume the machine has some normal measurement error that is proportional to the size of the population. Thus the data generative model is given by\n\\[\nP(t) |r,K \\sim N(f(\\theta, t),\\sigma^2 f(\\theta, t))\n\\] where \\(f(\\theta, t)\\) is computed by populationFunction on the previous slide."
  },
  {
    "objectID": "slides/BayesianInverseProblem.html#exercise",
    "href": "slides/BayesianInverseProblem.html#exercise",
    "title": "Inverse problem",
    "section": "Exercise",
    "text": "Exercise\nYour task is to determine the measurment error of the machine \\(\\sigma^2\\).\nIt is well known that E coli takes about 20 \\(\\pm 2.5\\) minutes in laboratory conditions to double in size. Given this, we’d expect \\(r\\) to be about \\(\\frac{\\log(2)}{20}\\).\nFurthermore, we know the carrying capacity of the petri dish is at least \\(10^8\\) CFU.\n\nIdentify each unknown.\nUse the information above to develop reasonable priors over each unknown.\nWrite pseudo-code of an MCMC sampler to make inference about the parameters.\n(optional) Implement your sampler."
  },
  {
    "objectID": "slides/BayesianInverseProblem.html#solution",
    "href": "slides/BayesianInverseProblem.html#solution",
    "title": "Inverse problem",
    "section": "Solution",
    "text": "Solution\nThe unknowns are \\(r, K, \\sigma^2\\).\nMaybe we think it takes somewhere between 15 minutes and 25 minutes for the population size to double under our lab conditions. Some plausible prior choices are\n\\[\n\\begin{aligned}\nr &\\sim \\text{Uniform}(\\log(2)/25, \\log(2)/15)\\\\\nK &\\propto 1 \\text{ if } K &gt; 10^8\\\\\\\n\\sigma^2 &\\sim \\text{inverse-gamma}(1, 1)\n\\end{aligned}\n\\]\nPseudocode:\ninitialize r, K, sigma^2 \nS = large number\nfor (i in 1:S) {\n - sample r* ~ cnorm(1, r_s, .01, a = log(2)/25, b = log(2)/15)\n - compute MH ratio: [posterior(r*)/posterior(r_s)] * [J(r_s | r*)/J(r* | r_s)]\n - accept/reject\n - sample K* ~ cnorm(1, K_s, 1E5, a = 1E8)\n - compute MH ratio like above and accept/reject\n - sample sigma^2* ~ cnorm(1, sigma^2_s, .1, a = 0)\n - compute MH ratio like above and accept/reject\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/lec14-estimators.html",
    "href": "notes/lec14-estimators.html",
    "title": "Estimators",
    "section": "",
    "text": "Definition\n\n\n\nA point estimator of an unknown parameter \\(\\theta\\) is a function that converts data into a single element of parameter space \\(\\Theta\\).\n\n\nExample: Let \\(Y_1, \\ldots, Y_n | \\theta, \\sigma^2 \\sim \\text{iid }~N(\\theta, \\sigma^2)\\). Further assume some prior \\(p(\\theta, \\sigma^2)\\). The following are each point estimators of \\(\\theta\\):\n\n\\(\\bar{y}\\)\n\\(y_1\\)\n\\(\\frac{y_1 + y_2}{2}\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is convention to write estimators the same way we write the parameter but with a “hat”. For example, \\(\\theta\\) is the parameter and \\(\\hat{\\theta}\\) is the estimator.\n\n\nSampling properties of a point estimator refer to the estimator’s behavior under hypothetical repeatable surveys or experiments.\nThree common sampling properties of estimators we will see again and again are:\n\nbias\nvariance\nmean squared error (MSE)\n\n\n\nBefore we discuss bias, variance and mean squared error of an estimator, it’s important to understand that an estimator is a statistic (function of the data) and therefore a random variable. Because of this, estimator’s have a sampling distribution.\n\nExercise 1\n\n\nWhat does the example below show? What is x?\n\n\n\n\nset.seed(360)\n\nx = vector()\nfor (i in 1:100) {\n  y = rnorm(10)\n  x = append(min(y), x)\n}\nhist(x, freq = FALSE)\nabline(v = mean(x), col= \"steelblue\", lwd = 4)\n\n\n\n\n\n\n\ncat(\"The variance of x is \", round(var(x), 3))\n\nThe variance of x is  0.291\n\n\n\nExercise 2\n\n\nImagine \\(\\hat{\\theta}_a\\) and \\(\\hat{\\theta}_b\\) are two different estimators of \\(\\theta\\). The true value of \\(\\theta\\) is \\(\\theta_0 = 0\\). The sampling distributions of the two estimators are given below. Which estimator do you prefer?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the rest of these notes, let \\(\\theta_0\\) be the true value of the population parameter \\(\\theta\\).\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\] where \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\nWhile it may seem desirable to have an estimator with zero bias, the estimator may still be far away from the true parameter value if the variance is too large. The mean squared error quantifies how close an estimator is to the true parameter value.\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]\n\n\n\nLet’s show this offline."
  },
  {
    "objectID": "notes/lec14-estimators.html#definitions",
    "href": "notes/lec14-estimators.html#definitions",
    "title": "Estimators",
    "section": "",
    "text": "Definition\n\n\n\nA point estimator of an unknown parameter \\(\\theta\\) is a function that converts data into a single element of parameter space \\(\\Theta\\).\n\n\nExample: Let \\(Y_1, \\ldots, Y_n | \\theta, \\sigma^2 \\sim \\text{iid }~N(\\theta, \\sigma^2)\\). Further assume some prior \\(p(\\theta, \\sigma^2)\\). The following are each point estimators of \\(\\theta\\):\n\n\\(\\bar{y}\\)\n\\(y_1\\)\n\\(\\frac{y_1 + y_2}{2}\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is convention to write estimators the same way we write the parameter but with a “hat”. For example, \\(\\theta\\) is the parameter and \\(\\hat{\\theta}\\) is the estimator.\n\n\nSampling properties of a point estimator refer to the estimator’s behavior under hypothetical repeatable surveys or experiments.\nThree common sampling properties of estimators we will see again and again are:\n\nbias\nvariance\nmean squared error (MSE)\n\n\n\nBefore we discuss bias, variance and mean squared error of an estimator, it’s important to understand that an estimator is a statistic (function of the data) and therefore a random variable. Because of this, estimator’s have a sampling distribution.\n\nExercise 1\n\n\nWhat does the example below show? What is x?\n\n\n\n\nset.seed(360)\n\nx = vector()\nfor (i in 1:100) {\n  y = rnorm(10)\n  x = append(min(y), x)\n}\nhist(x, freq = FALSE)\nabline(v = mean(x), col= \"steelblue\", lwd = 4)\n\n\n\n\n\n\n\ncat(\"The variance of x is \", round(var(x), 3))\n\nThe variance of x is  0.291\n\n\n\nExercise 2\n\n\nImagine \\(\\hat{\\theta}_a\\) and \\(\\hat{\\theta}_b\\) are two different estimators of \\(\\theta\\). The true value of \\(\\theta\\) is \\(\\theta_0 = 0\\). The sampling distributions of the two estimators are given below. Which estimator do you prefer?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the rest of these notes, let \\(\\theta_0\\) be the true value of the population parameter \\(\\theta\\).\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\] where \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\nWhile it may seem desirable to have an estimator with zero bias, the estimator may still be far away from the true parameter value if the variance is too large. The mean squared error quantifies how close an estimator is to the true parameter value.\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]\n\n\n\nLet’s show this offline."
  },
  {
    "objectID": "notes/lec14-estimators.html#practice",
    "href": "notes/lec14-estimators.html#practice",
    "title": "Estimators",
    "section": "Practice",
    "text": "Practice\nSuppose you wish to make inference about the average bill length of Chinstrap penguins.\nYou make the modeling assumption that \\(Y\\), the bill length of a penguin is normally distributed, i.e. \\(Y| \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2)\\) and you set up a conjugate prior as we’ve done before.\nOne can then show that the posterior mean estimator of \\(\\theta\\) is\n\\[\n\\hat{\\theta}_b = E[\\theta | y_1,\\ldots y_n] = \\frac{n}{\\kappa_0 + n} \\bar{y} + \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 = w\\bar{y} + (1-w) \\mu_0\n\\]\n\nExercise 3\n\n\nCompare \\(\\hat{\\theta}_b\\) to the estimator \\(\\hat{\\theta}_e = \\bar{y}\\). Compute the expected value of each estimator, which one is biased? Compute the variance of each estimator. Which has lower variance?\n\n\n\n\nLet’s compute the MSE and discuss when the Bayesian estimator \\(\\hat{\\theta}_b\\) has lower MSE than the sample mean offline."
  },
  {
    "objectID": "notes/lec14-estimators.html#extra-practice",
    "href": "notes/lec14-estimators.html#extra-practice",
    "title": "Estimators",
    "section": "Extra practice",
    "text": "Extra practice\n\n\n\n\n\n\nExercise 4plotcode\n\n\nSuppose you know Gentoo penguins are closely related to Chinstrap penguins. Previously, you’ve measured the bill length of three Gentoo penguins and found their mean bill length to be 46.2. Accordingly, you set \\(\\mu_0 = 46.2\\).\n\n\n\n\n\n\n\n\nFor illustrative purposes, we’ll pretend we know the true population mean and variance for Chinstrap penguin bill length\n\\[\n\\begin{aligned}\n\\theta_0 &= 48.5\\\\\n\\sigma^2 &= 3.3.\n\\end{aligned}\n\\]      \n\nCompute \\(MSE[\\hat{\\theta}_e|\\theta_0]\\) and \\(MSE[\\hat{\\theta_b}|\\theta_0]\\) and plot the ratio \\(MSE[\\hat{\\theta}_b]/MSE[\\hat{\\theta}_e|\\theta_0]\\) as a function of \\(n\\) for \\(\\kappa_0 = 0, 1, 2, 3\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# MSE of the sample mean = sigma^2 / n \nsigma2 = 3.3 \nMSE_empirical = function(n) {\n  sigma2 / n\n}\n\nMSE_bayesian = function(k0, n) {\n  w = n / (k0 + n)\n  (w^2 * sigma2 / n) + (((1-w) * (46.2 - 48.5))^2)\n}\n\nMSE_ratio = function(k0, n) {\n  MSE_bayesian(k0, n) / MSE_empirical(n)\n}\n\ndata.frame(x = 1:100) %&gt;%\n  ggplot(aes(x = x)) +\n  stat_function(aes(col = '0'), alpha = 0.5, fun = MSE_ratio,\n                args = list(k0 = 0)) +\n  stat_function(aes(col = '1'), alpha = 0.5, fun = MSE_ratio,\n                args = list(k0 = 1)) +\n  stat_function(aes(col = '2'), alpha = 0.5, fun = MSE_ratio,\n                args = list(k0 = 2)) +\n  stat_function(aes(col = '3'), alpha = 0.5, fun = MSE_ratio,\n                args = list(k0 = 3)) +\n  labs(x = \"n\", y = \"MSE ratio\", col = \"k0\") +\n  theme_bw()"
  },
  {
    "objectID": "slides/lab-mixtures.html#what-is-a-mixture-density",
    "href": "slides/lab-mixtures.html#what-is-a-mixture-density",
    "title": "Mixture densities",
    "section": "What is a mixture density?",
    "text": "What is a mixture density?\nA mixture density (sometimes called an “admixture” density) is a convex combination (i.e. weighted sum, with non-negative weights that sum to 1) of other density functions.\nIn other words…\n\\[\nf(x) = \\sum_{i=1}^nw_i p_i(x),\n\\]\nwhere \\(p_i(x)\\) is a pdf and \\(w_i &gt; 0\\) for all \\(i\\) and \\(\\sum w_i = 1\\). We say: \\(f(x)\\) is a (finite) mixture density.\nMixture densities are often used to model distinct sub-populations within a population. This allows us to create flexible prior distributions.\n\nExercise\nProve that \\(f(x)\\) is a proper density function, i.e. that \\(f(x) \\geq 0\\) everywhere and \\(\\int f(x) dx = 1\\)."
  },
  {
    "objectID": "slides/lab-mixtures.html#exercise-1",
    "href": "slides/lab-mixtures.html#exercise-1",
    "title": "Mixture densities",
    "section": "Exercise 1",
    "text": "Exercise 1\nCreate and plot a function \\(f(x)\\) that is a mixture of two densities and approximates the histogram below."
  },
  {
    "objectID": "slides/lab-mixtures.html#exercise-2",
    "href": "slides/lab-mixtures.html#exercise-2",
    "title": "Mixture densities",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose an experimental machine in a lab is either fine, or comes from a bad batch of machines that are to be recalled by the manufacturer. Scientists in the lab want to estimate the failure rate of their machine and decide whether or not to return it. They encode their prior uncertainty about the failure rate \\(\\theta\\) with the following density:\n\\[\np(\\theta) = \\frac{1}{4} \\frac{\\Gamma(10)}{\\Gamma(2)\\Gamma(8)}\\left[\n3 \\theta (1 - \\theta)^7 + \\theta^7(1- \\theta)\n\\right]\n\\]\n(a). Make a plot of this prior density and explain why it makes sense for the scientists. Based on the prior density, which do the scientists think is more likely - that their machine is fine, or bad?\n(b). The scientists run the machine \\(n\\) times. Let \\(y_i\\) be one if the machine fails on the \\(i\\)th run, and zero otherwise. Write out the posterior distribution of \\(\\theta\\) given \\(y_1, \\ldots, y_n\\) (up to a proportionality constant) and simplify as much as possible.\n(c). The posterior is a mixture (weighted average) of two distributions that you know. Identify these two distributions, including their parameters."
  },
  {
    "objectID": "slides/lab-mixtures.html#solution-1",
    "href": "slides/lab-mixtures.html#solution-1",
    "title": "Mixture densities",
    "section": "Solution 1",
    "text": "Solution 1\nThe plot looks like a mixture of normals. The first centered on 0 and the second on 10. More weight is given to the first density.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmixNormal = function(x) {\n  0.75 *dnorm(x, 0, 1) +\n  0.25 * dnorm(x, 10, 1)\n}\n\ndata.frame(x = -2:13) %&gt;%\nggplot(aes(x = x)) +\n  stat_function(fun = mixNormal) +\n  labs(y = \"f(x)\")"
  },
  {
    "objectID": "slides/lab-mixtures.html#solution-2",
    "href": "slides/lab-mixtures.html#solution-2",
    "title": "Mixture densities",
    "section": "Solution 2",
    "text": "Solution 2\nIn lab.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "hw/hw2023_08.html",
    "href": "hw/hw2023_08.html",
    "title": "Homework 8",
    "section": "",
    "text": "Weighted regression: Suppose \\(y_i \\sim N(\\beta x_i, \\sigma^2 / w_i)\\) independently for \\(i = 1,\\ldots n\\), where \\(x_1, \\ldots, x_n\\) and \\(w_1, \\ldots w_n\\) are known scalars, and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nFind the formula for the OLS estimator \\(\\hat{\\beta}_{OLS}\\) and compute its variance \\(V[\\hat{\\beta}_{OLS} | \\beta, \\sigma^2]\\).\nWrite out the sampling density \\(p(y_1, \\ldots, y_n | \\sigma^2, \\beta)\\) as a function of \\(\\beta\\) (i.e. the likelihood) and find the value of \\(\\beta\\) that maximizes this function (the MLE). Denote this maximizing value as \\(\\hat{\\beta}_{MLE}\\). Compute \\(V[\\hat{\\beta}_{MLE}  | \\beta, \\sigma^2]\\) and compare it to that of \\(\\hat{\\beta}_{OLS}\\).\nUnder the prior distribution \\(\\beta \\sim N(0, \\tau^2)\\), find \\(E[\\beta | y_1, \\ldots, y_n, \\sigma^2]\\). What does this estimator get close to as the prior precision goes to zero (\\(\\tau^2 \\rightarrow \\infty\\))?"
  },
  {
    "objectID": "hw/hw2023_08.html#exercise-1",
    "href": "hw/hw2023_08.html#exercise-1",
    "title": "Homework 8",
    "section": "",
    "text": "Weighted regression: Suppose \\(y_i \\sim N(\\beta x_i, \\sigma^2 / w_i)\\) independently for \\(i = 1,\\ldots n\\), where \\(x_1, \\ldots, x_n\\) and \\(w_1, \\ldots w_n\\) are known scalars, and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nFind the formula for the OLS estimator \\(\\hat{\\beta}_{OLS}\\) and compute its variance \\(V[\\hat{\\beta}_{OLS} | \\beta, \\sigma^2]\\).\nWrite out the sampling density \\(p(y_1, \\ldots, y_n | \\sigma^2, \\beta)\\) as a function of \\(\\beta\\) (i.e. the likelihood) and find the value of \\(\\beta\\) that maximizes this function (the MLE). Denote this maximizing value as \\(\\hat{\\beta}_{MLE}\\). Compute \\(V[\\hat{\\beta}_{MLE}  | \\beta, \\sigma^2]\\) and compare it to that of \\(\\hat{\\beta}_{OLS}\\).\nUnder the prior distribution \\(\\beta \\sim N(0, \\tau^2)\\), find \\(E[\\beta | y_1, \\ldots, y_n, \\sigma^2]\\). What does this estimator get close to as the prior precision goes to zero (\\(\\tau^2 \\rightarrow \\infty\\))?"
  },
  {
    "objectID": "hw/hw2023_08.html#exercise-2",
    "href": "hw/hw2023_08.html#exercise-2",
    "title": "Homework 8",
    "section": "Exercise 2",
    "text": "Exercise 2\nRidge regression theory: Let \\(y \\sim N_n(X \\beta, \\sigma^2 I)\\). Consider estimating \\(\\beta\\) with the prior distribution \\(\\beta | \\sigma^2 \\sim N_p(0, \\sigma^2 I / \\lambda)\\), where \\(\\lambda\\) is known and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nDerive the conditional distribution of \\(\\beta | y, \\sigma^2\\) and, in particular, show that \\(E[\\beta | y] = (X^TX + I \\lambda)^{-1} X^Ty\\). Denote this expectation \\(\\hat{\\beta}_\\lambda\\), which we can use as an estimator of \\(\\beta\\). What happens to \\(\\hat{\\beta}_\\lambda\\) as \\(\\lambda \\rightarrow 0\\)?\nConsider the special case that \\(X^TX\\) is a diagonal matrix with entries \\(x_1^T x_1, \\ldots, x_p^T x_p\\). Find the mathematical relationship between each element of \\(\\hat{\\beta}_{\\lambda}\\) and the corresponding element of the OLS estimator \\(\\hat{\\beta}_{OLS}\\). Explain in words the effect of \\(\\lambda\\)."
  },
  {
    "objectID": "hw/hw2023_08.html#exercise-3",
    "href": "hw/hw2023_08.html#exercise-3",
    "title": "Homework 8",
    "section": "Exercise 3",
    "text": "Exercise 3\nRidge regression application: The data set yX.diabetes.train contains data on diabetes progression (first column) and 64 predictor variables. These data can be loaded with with command\n\nyX&lt;-dget(url(\"https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.diabetes.train\"))\n\n\nFor each value of \\(\\lambda \\in \\{0, 1,  \\ldots, 99, 100 \\}\\) compute the estimator \\(\\hat{\\beta}_{\\lambda}\\) and plot this in some way (maybe using matplot).\nLoad the data set yX.diabetes.test using the code below\n\n\nyX.diabetes.test&lt;-dget(\n  url(\"https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.diabetes.test\"))\n\nUse yX.diabetes.test to evaluate the predictive performance of each estimate you obtained in part a. Specifically, compute the predictive error sum of squares \\(PSS(\\lambda) = ||y_{test} - X_{test} \\hat{\\beta}_{\\lambda}||^2\\) for each value of \\(\\lambda\\) (IMPORTANT: \\(\\hat{\\beta}_{\\lambda}\\) is obtained from the training data in part a, not the test data). Make a plot of PSS versus \\(\\lambda\\). How good is the unbiased OLS estimate for prediction, relative to the other estimates?\n\nIdentify the value of \\(\\lambda\\) that has the best predictive performance. For this best value of \\(\\lambda\\), report which x-variables have the largest effects."
  },
  {
    "objectID": "hw/hw2023_08.html#exercise-4",
    "href": "hw/hw2023_08.html#exercise-4",
    "title": "Homework 8",
    "section": "Exercise 4",
    "text": "Exercise 4\nFor this exercise, use the code below to load the data\n\nyX = readRDS(\n  url(\"http://www2.stat.duke.edu/~pdh10/Teaching/360/Materials/yXSS.rds\"))\n\nSource separation: The first column y of the dataset yXSS.rds is the vectorization of a spectroscopy image of a water sample taken from the Neuse River in North Carolina. You can view the image with the following code: y&lt;-yX[,1] ; image(matrix(y,151,43)). The water sample is of unknown origin, but it is assumed that it is a mix of water from 9 different categories, whose average spectroscopy images are given by the remaining 9 columns \\(X\\) of yX. You can view these images with the same code above, applied to each column of \\(X\\).\n\nFrom \\(y\\) and \\(X\\), infer the sources of the water sample using the linear model \\(E[y|X, \\beta] = X\\beta\\). Assuming the normal linear model and with priors \\(\\beta \\sim N_9(1/9, \\ldots 1/9), I_9)\\), \\(1/\\sigma^2 \\sim \\text{gamma}(1, 1)\\), use a Gibbs sampler to obtain a posterior distribution of \\(\\beta\\) and \\(\\sigma^2\\) given \\(y\\). Plot the posterior density of \\(\\sigma^2\\), and obtain posterior 95% confidence intervals for each element of \\(\\beta\\). Which of the nine categories are the main sources of the water sample?\nEvaluate the assumptions of the normal linear model using some residual plots, addressing the assumption that the entries of \\(y\\) have constant variance, are uncorrelated, and are normally distributed.\nFor this problem it doesn’t make sense for the coefficients of \\(\\beta\\) to be negative. Think of a modification to the prior distribution for \\(\\beta\\) that takes this fact into account, and describe how a Gibbs sampler could be constructed to sample from the corresponding posterior distribution."
  },
  {
    "objectID": "hw/hw05.html",
    "href": "hw/hw05.html",
    "title": "Homework 5",
    "section": "",
    "text": "You’ve been hired as a columnist to write for the statistics/mathematics section of an online magazine. Your editor knows you are enrolled in STA602 and has asked you to write about the Metropolis algorithm for the magazine. Specifically, your editor tells you that your article should answer the following:\n\nWhat is the Metropolis algorithm? What is the history of the algorithm?\nWhat can the Metropolis algorithm be used for?\nWhat is a proposal distribution?\nWhat’s the intuition behind why the algorithm works?\n\nAdditionally, the editor adds: your article needs to be strictly under 500 words (the shorter the better). Furthermore, your target audience has limited statistical background. For this reason, you should define all statistical terminology when you use it, in your own words."
  },
  {
    "objectID": "hw/hw05.html#exercise-1",
    "href": "hw/hw05.html#exercise-1",
    "title": "Homework 5",
    "section": "",
    "text": "You’ve been hired as a columnist to write for the statistics/mathematics section of an online magazine. Your editor knows you are enrolled in STA602 and has asked you to write about the Metropolis algorithm for the magazine. Specifically, your editor tells you that your article should answer the following:\n\nWhat is the Metropolis algorithm? What is the history of the algorithm?\nWhat can the Metropolis algorithm be used for?\nWhat is a proposal distribution?\nWhat’s the intuition behind why the algorithm works?\n\nAdditionally, the editor adds: your article needs to be strictly under 500 words (the shorter the better). Furthermore, your target audience has limited statistical background. For this reason, you should define all statistical terminology when you use it, in your own words."
  },
  {
    "objectID": "hw/hw05.html#exercise-2",
    "href": "hw/hw05.html#exercise-2",
    "title": "Homework 5",
    "section": "Exercise 2",
    "text": "Exercise 2\nYounger male sparrows may or may not nest during a mating season, perhaps depending on their physical characteristics. Researchers have recorded the nesting success of 43 young male sparrows of the same age, as well as their wingspan. Run the code below to load the data:\n\nyXsparrow = readr::read_csv(\"https://sta602-sp25.github.io/data/yXsparrow.csv\")\n\nLet \\(Y_i\\) be the binary indicator that sparrow \\(i\\) successfully nests, and let \\(x_i\\) denote their wingspan. Our model for \\(Y_i\\) is logit \\(Pr(Y_i = 1 | \\alpha, \\beta, x_i) = \\alpha + \\beta x_i\\), where the logit function is given by logit \\(\\theta = \\log \\left[\\frac{\\theta}{(1 - \\theta)} \\right]\\).\n\nWrite down the likelihood,\n\n\\[\n\\prod_{i=1}^n p(y_i | \\alpha, \\beta, x_i)\n\\] and simplify as much as possible.\n\nFormulate a prior probability distribution over \\(\\alpha\\) and \\(\\beta\\) by considering the range of \\(Pr(Y = 1 | \\alpha, \\beta, x)\\) as \\(x\\) ranges over 10 to 15, the approximate range of observed wingspans.\nImplement a Metropolis algorithm that approximates \\(p(\\alpha, \\beta | \\mathbf{y}, \\mathbf{x})\\). \\(\\mathbf{y} = y_1, \\ldots, y_n\\) and \\(\\mathbf{x} = x_1, \\ldots x_n\\). Adjust the proposal distribution to achieve a reasonable acceptance rate, and run the algorithm long enough so that the effective sample size is at least 100 for each parameter.\nReport trace plots for \\(\\alpha\\) and \\(\\beta\\). Additionally, compare the posterior densities of \\(\\alpha\\) and \\(\\beta\\) to their prior densities.\nUsing the output of the Metropolis algorithm, come up with a way to make a confidence band for the following function \\(f_{\\alpha, \\beta}(x)\\) of wingspan:\n\n\\[\nf_{\\alpha, \\beta}(x) = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\nwhere \\(\\alpha\\) and \\(\\beta\\) are the parameters in your data generative model. Make a plot of such a band."
  },
  {
    "objectID": "hw/hw05.html#exercise-3",
    "href": "hw/hw05.html#exercise-3",
    "title": "Homework 5",
    "section": "Exercise 3",
    "text": "Exercise 3\nCode for this exercise is provided below,\n\n# load the data\ntrans.prob.mat = readRDS(url(\"https://sta602-sp25.github.io/data/trans-prob-mat.rds\"))\ncipher_text = readLines(\"https://sta602-sp25.github.io/data/ciphertext.txt\")\n\npl = function(decoded) {\n  logprob = 0\n  prevletter = \"SPACE\"\n  for (i in 1:nchar(decoded)) {\n    curletter = substring(decoded, i, i)\n    if(curletter == \" \") {\n      curletter = \"SPACE\"\n    }\n    logprob = logprob + log(trans.prob.mat[rownames(trans.prob.mat) == prevletter,\n                                             colnames(trans.prob.mat) == curletter])\n    prevletter = curletter\n  }\n  return(logprob)\n} \n\nIn this exercise we will re-create the cryptanalysis tool described here to decrypt a secret message. Read pages 1-3 of the article by Persi Diaconis linked above.\n\nLoad the object trans.prob.matrix using the code above and examine. Based on your reading of the article, how can you interpret the entries of this matrix? Is it symmetric or not? Why does this make sense? The function pl(), given above, computes the “plausibility” score for a given decoding. Explain in detail what the code comprising pl() does.\nThe following code can help you get started:\n\n\n## alphabet with space\nalphabet = c(LETTERS, \" \")\n\n## decode: replace ciphertext with mapping\n\ndecode = function(mapping, coded) {\n  coded = toupper(coded)\n  decoded = coded\n  for (i in 1:nchar(coded)) {\n      substring(decoded, i, i) = alphabet[mapping == substring(coded, i, i)]\n  }\n  decoded\n}\n\nExplain, line-by-line what the function decode() above does. What are the arguments? What does the function return?\n\nFollow the pseudo-code outlined on page 2 of the article to write a MCMC algorithm and decrypt the secret message. Run your Markov chain for at least 1000 iterations and report the decoding with the highest plausibility score."
  },
  {
    "objectID": "slides/lab2.html#practice-exercise",
    "href": "slides/lab2.html#practice-exercise",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\nA cancer laboratory is estimating the rate of tumorigenesis in two strains of mice, \\(A\\) and \\(B\\). They have tumor count data for 10 mice in strain \\(A\\) and 13 mice in strain \\(B\\),\n\nyA = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyB = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\nAssume\n\\[\n\\begin{aligned}\nY_A &\\sim \\text{Poisson}(\\theta_A)\\\\\nY_B &\\sim \\text{Poisson}(\\theta_B).\n\\end{aligned}\n\\]\n\nExercise 1Exercise 2\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12, 1).\n\\end{aligned}\n\\]\n\nCompute \\(p(\\theta_B &lt; \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\) via Monte Carlo sampling.\n\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12\\cdot n_0, n_0).\n\\end{aligned}\n\\]\n\nFor a range of values of \\(n_0\\), obtain \\(p(\\theta_B &lt; \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\).\nDescribe how sensitive conclusions about the event \\(\\{ \\theta_B &lt; \\theta_A\\}\\) are to the prior distribution on \\(\\theta_B\\)."
  },
  {
    "objectID": "slides/lab2.html#practice-exercise-1",
    "href": "slides/lab2.html#practice-exercise-1",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\n\nLet \\(X \\sim \\text{Unif}(5, 10)\\)\nLet \\(Y = X^2\\)\n\nNotice that even though \\(X^2\\) is not a monotonic function everywhere, it is a monotonic function over the support of X.\nExercise: use the change of variables formula to derive \\(p(y)\\). Confirm with Monte Carlo simulation.\n\n\nShow solution\nlibrary(tidyverse)\n\nx = runif(100000, 5, 10)\ny = x^2\n\ndf = data.frame(y)\n\nf = function(y) {\n  return(.1/sqrt(y))\n}\n\ndf %&gt;%\n  ggplot(aes(x = y)) + \n  stat_function(fun = f) +\n  geom_histogram(aes(x = y, y = ..density..),\n                 fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "hw/hw08.html",
    "href": "hw/hw08.html",
    "title": "Homework 8",
    "section": "",
    "text": "10.1 from Hoff."
  },
  {
    "objectID": "hw/hw08.html#exercise-1",
    "href": "hw/hw08.html#exercise-1",
    "title": "Homework 8",
    "section": "",
    "text": "10.1 from Hoff."
  },
  {
    "objectID": "hw/hw08.html#exercise-2",
    "href": "hw/hw08.html#exercise-2",
    "title": "Homework 8",
    "section": "Exercise 2",
    "text": "Exercise 2\n8.1 from Hoff. Note there is a typo in this exercise. Every \\(\\theta_i\\) in the exercise prompt should be replaced by \\(\\theta_j\\)."
  },
  {
    "objectID": "hw/hw08.html#exercise-3",
    "href": "hw/hw08.html#exercise-3",
    "title": "Homework 8",
    "section": "Exercise 3",
    "text": "Exercise 3\n8.3 from Hoff: find the problem setup (definitions of each Greek letter) on page 132 and 133 of the book. Also see, e.g. the notes on hierarchical modeling.\nRun the code below to load the data.\n\nlibrary(readr)\nlibrary(glue)\n\nfor(i in 1:8) {\nassign(paste0(\"school\", i), \n       read_csv(glue(\"https://sta602-sp25.github.io/data/school{i}.csv\")))\n}"
  },
  {
    "objectID": "hw/hw2023_05.html",
    "href": "hw/hw2023_05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Risk calculation: Let \\(Y_1, \\ldots, Y_n | \\theta \\sim \\text{ i.i.d. Poission}(\\theta)\\).\n\nFor the case that \\(\\theta \\sim \\text{gamma}(a, b)\\), show that the posterior mean of \\(\\theta\\) given \\(Y_1, \\ldots, Y_n\\) can be written as \\(\\hat{\\theta}_w = w \\bar{y} + (1-w)\\mu\\) for values \\(w\\) and \\(\\mu\\) that depend on \\(n\\), \\(a\\) and \\(b\\).\nNow consider how good this estimator is for a specific value of \\(\\theta\\). Compute \\(E[\\hat{\\theta}_w|\\theta]\\), \\(V[\\hat{\\theta}_w|\\theta]\\), and \\(E[\\bar{y}|\\theta]\\) and \\(V[\\bar{y}|\\theta]\\).\nFind some nice conditions on \\(w\\) and \\(\\mu\\) so that \\(MSE[\\hat{\\theta}_w] &lt; MSE[\\bar{y}]\\)\n[Optional] Now suppose \\(n = 10\\) and \\(\\theta = 5\\). Pick a value of \\(w\\) and \\(\\mu\\) so that your condition in c. is met. Now verify the condition numerically with a Monte Carlo simulation, by simulating 1000 samples of size \\(n=10\\) from the Poisson(5) distribution, computing \\(\\bar{y}\\) and \\(\\hat{\\theta}_w\\) for each simulated sample, and then approximating the MSE of each estimator using the 1000 simulated values of each. Also make histograms or density plots of the simulated estimators, to confirm that one has low(er) variance but positive bias, and the other has zero bias but high(er) variance."
  },
  {
    "objectID": "hw/hw2023_05.html#exercise-1",
    "href": "hw/hw2023_05.html#exercise-1",
    "title": "Homework 5",
    "section": "",
    "text": "Risk calculation: Let \\(Y_1, \\ldots, Y_n | \\theta \\sim \\text{ i.i.d. Poission}(\\theta)\\).\n\nFor the case that \\(\\theta \\sim \\text{gamma}(a, b)\\), show that the posterior mean of \\(\\theta\\) given \\(Y_1, \\ldots, Y_n\\) can be written as \\(\\hat{\\theta}_w = w \\bar{y} + (1-w)\\mu\\) for values \\(w\\) and \\(\\mu\\) that depend on \\(n\\), \\(a\\) and \\(b\\).\nNow consider how good this estimator is for a specific value of \\(\\theta\\). Compute \\(E[\\hat{\\theta}_w|\\theta]\\), \\(V[\\hat{\\theta}_w|\\theta]\\), and \\(E[\\bar{y}|\\theta]\\) and \\(V[\\bar{y}|\\theta]\\).\nFind some nice conditions on \\(w\\) and \\(\\mu\\) so that \\(MSE[\\hat{\\theta}_w] &lt; MSE[\\bar{y}]\\)\n[Optional] Now suppose \\(n = 10\\) and \\(\\theta = 5\\). Pick a value of \\(w\\) and \\(\\mu\\) so that your condition in c. is met. Now verify the condition numerically with a Monte Carlo simulation, by simulating 1000 samples of size \\(n=10\\) from the Poisson(5) distribution, computing \\(\\bar{y}\\) and \\(\\hat{\\theta}_w\\) for each simulated sample, and then approximating the MSE of each estimator using the 1000 simulated values of each. Also make histograms or density plots of the simulated estimators, to confirm that one has low(er) variance but positive bias, and the other has zero bias but high(er) variance."
  },
  {
    "objectID": "hw/hw2023_05.html#exercise-2",
    "href": "hw/hw2023_05.html#exercise-2",
    "title": "Homework 5",
    "section": "Exercise 2",
    "text": "Exercise 2\n6.1 from Hoff. Let \\(\\theta\\) and \\(\\gamma\\) be independent. Use the code below to load the data.\n\nbach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/bach30.csv\")\n\nnobach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/nobach30.csv\")"
  },
  {
    "objectID": "hw/hw2023_05.html#exercise-3",
    "href": "hw/hw2023_05.html#exercise-3",
    "title": "Homework 5",
    "section": "Exercise 3",
    "text": "Exercise 3\n6.2 from Hoff. Note the typo: \\(1/\\sigma_j^2\\) is gamma, not \\(1/\\sigma_j\\). Use the code below to load the data.\n\nglucose = readr::read_csv(\"https://sta360-fa23.github.io/data/glucose.csv\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian statistical modeling and data analysis",
    "section": "",
    "text": "Schedule\n\n\n\n\n\nWeek\nDate\nTopic\nReading\nNotes\nAssignment\n\n\n\n\n1\nWed Jan 08\nlab: welcome\n\n💻\nhello R\n\n\n\nFri Jan 10\nintro, history, notation\nCh. 2\n\nhw 0\n\n\n2\nMon Jan 13\nlab: MLE\n\n💻\n\n\n\n\nWed Jan 15\nprobability, exchangeability\nCh. 2\n🗒 📝\nhw 1\n\n\n\nFri Jan 17\nbeta-binomial model\nCh. 3\n🗒 📝\n\n\n\n3\nMon Jan 20\nNO CLASS\n\n\n\n\n\n\nWed Jan 22\nPoisson-gamma model, exp families\nCh. 3\n🗒 📝\nhw 2\n\n\n\nFri Jan 24\nreliability (conf. intervals, hpd, Laplace approx.)\nCh. 3\n🗒 📝\n\n\n\n4\nMon Jan 27\nlab: exp. families and transformations\n\n💻\n\n\n\n\nWed Jan 29\nintro to Monte Carlo\n📖\n🗒 📝\nhw 3\n\n\n\nFri Jan 31\npredictive checks and MC error\nCh. 4\n🗒 📝\n\n\n\n5\nMon Feb 03\nlab: mixture densities\n\n💻\n\n\n\n\nWed Feb 05\nthe normal model\nCh. 5\n🗒📝\nhw 4\n\n\n\nFri Feb 07\nestimators\nCh. 5\n🗒📝\n\n\n\n6\nMon Feb 10\nlab: normal data & estimators\n\n💻\n\n\n\n\nWed Feb 12\npriors\n\n🗒📝\n\n\n\n\nFri Feb 14\nreview\n\n\n\n\n\n7\nMon Feb 17\nJeffreys prior; exam review\n\n💻\n\n\n\n\nWed Feb 19\nExam I\n\n\n\n\n\n\nFri Feb 21\nMetropolis algorithm\nCh. 10\n🗒\n\n\n\n8\nMon Feb 24\nlab: Metropolis algo.\n\n💻\n\n\n\n\nWed Feb 26\nMCMC diagnostics\nCh. 6, 10\n🗒📝\nhw 5\n\n\n\nFri Feb 28\nGibbs sampling\nCh. 6\n🗒\n\n\n\n9\nMon Mar 03\nlab: MCMC and conf. bands\n\n💻\n\n\n\n\nWed Mar 05\nmultivariate normal\nCh. 6\n🗒\nhw 6\n\n\n\nFri Mar 07\nBayesian regression\nCh. 7, background\n🗒📝\n\n\n\n10\nMon Mar 10\nNO CLASS\n\n\n\n\n\n\nWed Mar 12\nNO CLASS\n\n\n\n\n\n\nFri Mar 14\nNO CLASS\n\n\n\n\n\n11\nMon Mar 17\nlab: rstanarm\n\n💻\n\n\n\n\nWed Mar 19\nhierarchical modeling\nCh. 8\n🗒📝\nhw 7\n\n\n\nFri Mar 21\nmodel averaging\nCh. 9 sec. 3\n🗒\n\n\n\n12\nMon Mar 24\nlab: probit regression\n\n💻\n\n\n\n\nWed Mar 26\nmixed effects models\nCh. 11\n📝.R\n\n\n\n\nFri Mar 28\nreview\n\n\n\n\n\n13\nMon Mar 31\nlab: exam review\n\n\n\n\n\n\nWed Apr 02\nExam II\n\n\n\n\n\n\nFri Apr 04\nHamiltonian Monte Carlo\n📖\n🗒\n\n\n\n14\nMon Apr 07\nlab: inverse problem\n\n💻\nhw 8\n\n\n\nWed Apr 09\nBayesian inverse problems\n📖\n🗒\n\n\n\n\nFri Apr 11\nSpecial topic\n\n\n\n\n\n15\nMon Apr 14\nfinal review\n\n\n\n\n\n\nWed Apr 16\npractice for final"
  },
  {
    "objectID": "hw/hw04.html",
    "href": "hw/hw04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Let \\(\\theta\\) be the rate of mutation for a certain cluster of cancer cells. Biologists encode their prior uncertainty about \\(\\theta\\) with the following density:\n\\[\np(\\theta) = \\frac{4}{10}e^{-4\\theta} + \\frac{9}{10 \\Gamma(8)} \\theta^7 e^{-\\theta}\n\\] a. Make a plot of this prior density and explain what it means, in context, to the biologists.\n\nLet \\(Y_i\\) be the number of mutations produced in the \\(i\\)th cell, such that\n\n\\[\nY_i | \\theta \\sim \\text{iid }Poisson(\\theta)\n\\]\nWrite out the posterior distribution of \\(\\theta\\) given \\(y_1,\\ldots y_n\\) (up to a proportionality constant) and simplify as much as possible. Hint: Be careful when writing your proportionality statement!\n\nThe posterior is a mixture (weighted average) of two distributions that you know. Identify these two distributions, including their parameters.\nAssume you obtain mutation data from two cells, \\(y_1 = 3, y_2 = 1\\). Compute the posterior exactly (i.e. find the appropriate integration constant) and plot the posterior density.\nIn part (c) you identified the posterior as a mixture (weighted average) of two distributions. Given the data in part (d), compute the weights of each density in the mixture."
  },
  {
    "objectID": "hw/hw04.html#exercise-1",
    "href": "hw/hw04.html#exercise-1",
    "title": "Homework 4",
    "section": "",
    "text": "Let \\(\\theta\\) be the rate of mutation for a certain cluster of cancer cells. Biologists encode their prior uncertainty about \\(\\theta\\) with the following density:\n\\[\np(\\theta) = \\frac{4}{10}e^{-4\\theta} + \\frac{9}{10 \\Gamma(8)} \\theta^7 e^{-\\theta}\n\\] a. Make a plot of this prior density and explain what it means, in context, to the biologists.\n\nLet \\(Y_i\\) be the number of mutations produced in the \\(i\\)th cell, such that\n\n\\[\nY_i | \\theta \\sim \\text{iid }Poisson(\\theta)\n\\]\nWrite out the posterior distribution of \\(\\theta\\) given \\(y_1,\\ldots y_n\\) (up to a proportionality constant) and simplify as much as possible. Hint: Be careful when writing your proportionality statement!\n\nThe posterior is a mixture (weighted average) of two distributions that you know. Identify these two distributions, including their parameters.\nAssume you obtain mutation data from two cells, \\(y_1 = 3, y_2 = 1\\). Compute the posterior exactly (i.e. find the appropriate integration constant) and plot the posterior density.\nIn part (c) you identified the posterior as a mixture (weighted average) of two distributions. Given the data in part (d), compute the weights of each density in the mixture."
  },
  {
    "objectID": "hw/hw04.html#exercise-2",
    "href": "hw/hw04.html#exercise-2",
    "title": "Homework 4",
    "section": "Exercise 2",
    "text": "Exercise 2\nA group of scientists have mutation data,\n\ny = c(0,3,0,1,5,2,0,4,1,1)\n\nand are interested in assessing how well the Poisson model from exercise 1 fits their data. Using the data generative model and prior from exercise 1, generate posterior predictive datasets \\(y^{(1)}, y^{(2)}, \\ldots y^{(S)}\\), where each data set \\(y^{(s)}\\) is a vector of length 10 whose entries are sampled from the Poisson distribution with parameters \\(\\theta^{(s)}\\). Each \\(\\theta^{(s)}\\) itself is a sample from the posterior \\(p(\\theta | y_1, \\ldots y_{10})\\). For each \\(s\\), let \\(t(s)\\) be the sample average of the 10 values of \\(y^{(s)}\\) divided by the sample standard deviation of \\(y^{(s)}\\). Make a histogram of \\(t(s)\\) and compare to the observed value of this statistic. Based on this statistic, assess the fit of the Poisson model for these data."
  },
  {
    "objectID": "hw/hw04.html#exercise-3",
    "href": "hw/hw04.html#exercise-3",
    "title": "Homework 4",
    "section": "Exercise 3",
    "text": "Exercise 3\nChimowitz et al. (2011) https://doi.org/10.1056/NEJMoa1105335 investigate if stents are effective treatment to manage strokes in patients with atherosclerotic intracranial arterial stenosis. You can load the data using the code below. Data sourced from openintro package.\n\nstents = readr::read_csv(\"https://sta602-sp25.github.io/data/stent365.csv\")\n\nEach row of the data set is an individual patient. The group column indicates whether the patient was treated with a stent or not. The outcome column reports whether the patient had a stroke or not within a year.\n\nWrite down a data generative model for this data. Hint: you might write down two data generative models, one for patients in the treatment group and one for patients in the control group.\nWrite down your prior beliefs about unknown parameters in your model above using a conjugate prior. Choose parameters for the priors. Explain your choices.\nReport (using Monte Carlo sampling or otherwise) the posterior mean of the relative risk, i.e. the posterior mean of the probability of stroke in the treatment group versus in the control, (think \\(E~[\\frac{\\theta_t}{\\theta_c}~|~\\text{data}]\\)). Additionally, include a 95% posterior confidence interval for the relative risk.\nPlot the posterior of the relative risk from part c. Do you believe the treatment is effective?"
  },
  {
    "objectID": "slides/lab0-welcome.html#introductions",
    "href": "slides/lab0-welcome.html#introductions",
    "title": "Welcome to Lab",
    "section": "Introductions",
    "text": "Introductions\n\nMeet the TA!\nIntroduce yourself (icebreaker)\nFollow along these slides on the course website (under slides): sta602-sp25.github.io\nBookmark this! It’s the course website."
  },
  {
    "objectID": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "href": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "title": "Welcome to Lab",
    "section": "What to expect in labs",
    "text": "What to expect in labs\n\nDiscussion\nPractice problems\nAssistance on computing portion of homeworks"
  },
  {
    "objectID": "slides/lab0-welcome.html#tips",
    "href": "slides/lab0-welcome.html#tips",
    "title": "Welcome to Lab",
    "section": "Tips",
    "text": "Tips\n\nShow up.\nMake use of office hours. Before you need help!"
  },
  {
    "objectID": "slides/lab0-welcome.html#beginnings",
    "href": "slides/lab0-welcome.html#beginnings",
    "title": "Welcome to Lab",
    "section": "Beginnings",
    "text": "Beginnings\nWhile this is not a computing class, computers are the workhorse of Bayesian statistics and we will use R to both enhance understanding of fundamental course material as well as to implement models to learn about real data sets."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio",
    "href": "slides/lab0-welcome.html#set-up-rstudio",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 1 (easiest): RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick RStudio to log into the Docker container. You should now see the RStudio environment.\n\nIf you haven’t previously done so, you will need to reserve a container for RStudio first."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio-1",
    "href": "slides/lab0-welcome.html#set-up-rstudio-1",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 2: RStudio on your computer\n\nDownload R from http://www.r-project.org/.\nDownload RStudio, the popular IDE for R, from https://posit.co/downloads/.\n(optionally) download Quarto from https://quarto.org/docs/get-started/"
  },
  {
    "objectID": "slides/lab0-welcome.html#demo",
    "href": "slides/lab0-welcome.html#demo",
    "title": "Welcome to Lab",
    "section": "Demo",
    "text": "Demo\nNext, check your familarity with R/RStudio fundamentals here. You can also find a link to this from the course schedule under “Assignment”.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "old-quizzes/quiz06-old.html",
    "href": "old-quizzes/quiz06-old.html",
    "title": "Quiz 6 (2023)",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\n\\[\nY = X\\beta\n\\]\nWrite down \\(\\hat{\\beta}_{OLS}\\) as a function of \\(X\\) and \\(Y\\). Assume \\(X\\) is full rank.\n\n\nExercise 2\nTRUE or FALSE\n\\(\\hat{\\beta}_{OLS}\\) is biased.\n\n\nExercise 3\nTRUE or FALSE\n\\(y_i = \\beta_0 + \\beta_1 x_i^2\\) is a linear model.\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "hw/hw2023_04.html",
    "href": "hw/hw2023_04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Let\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, 1/\\gamma)\\\\\n\\theta | \\sigma^2 &\\sim N(\\mu_0, 1/\\gamma \\kappa_0)\\\\\n\\gamma &\\sim \\text{gamma}(a, b)\n\\end{aligned}\n\\] so \\(\\gamma\\) is the precision (inverse-variance) of the normal distribution.\n\nDerive and simplify the joint pdf \\(p(y_1, \\ldots y_n | \\theta, \\gamma)\\)\nDerive the posterior of the precision, \\(p(\\gamma| y_1, \\ldots y_n)\\).\nDerive the posterior of \\(\\theta\\), \\(p(\\theta | y_1, \\ldots y_n)\\)"
  },
  {
    "objectID": "hw/hw2023_04.html#exercise-1",
    "href": "hw/hw2023_04.html#exercise-1",
    "title": "Homework 4",
    "section": "",
    "text": "Let\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, 1/\\gamma)\\\\\n\\theta | \\sigma^2 &\\sim N(\\mu_0, 1/\\gamma \\kappa_0)\\\\\n\\gamma &\\sim \\text{gamma}(a, b)\n\\end{aligned}\n\\] so \\(\\gamma\\) is the precision (inverse-variance) of the normal distribution.\n\nDerive and simplify the joint pdf \\(p(y_1, \\ldots y_n | \\theta, \\gamma)\\)\nDerive the posterior of the precision, \\(p(\\gamma| y_1, \\ldots y_n)\\).\nDerive the posterior of \\(\\theta\\), \\(p(\\theta | y_1, \\ldots y_n)\\)"
  },
  {
    "objectID": "hw/hw2023_04.html#exercise-2",
    "href": "hw/hw2023_04.html#exercise-2",
    "title": "Homework 4",
    "section": "Exercise 2",
    "text": "Exercise 2\nExercise 5.1 from Hoff. You can read in the data from the three schools with the R code below. Hint: the problem specification is the same as exercise 1, except \\(a = \\nu_0/2\\) and \\(b = \\nu_0 \\sigma_0^2/2\\).\n\nlibrary(tidyverse)\nschool1 = read_csv(\"https://sta360-fa23.github.io/data/school1.csv\")\nschool2 = read_csv(\"https://sta360-fa23.github.io/data/school2.csv\")\nschool3 = read_csv(\"https://sta360-fa23.github.io/data/school3.csv\")"
  },
  {
    "objectID": "hw/hw2023_04.html#exercise-3",
    "href": "hw/hw2023_04.html#exercise-3",
    "title": "Homework 4",
    "section": "Exercise 3",
    "text": "Exercise 3\n3.12 from Hoff."
  },
  {
    "objectID": "hw/hw03.html",
    "href": "hw/hw03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Let \\(Y_1, \\ldots Y_n | \\theta\\) be an i.i.d. random sample from a population with pdf \\(p(y|\\theta)\\) where\n\\[\np(y|\\theta) = \\frac{2}{\\Gamma(a)} \\theta^{2a} y^{2a -1} e^{-\\theta^2 y^2}\n\\]\nand \\(y &gt; 0\\), \\(\\theta &gt; 0\\), \\(a &gt; 0\\).\nFor this density,\n\\[\n\\begin{aligned}\nE~Y|\\theta &= \\frac{\\Gamma(a + \\frac{1}{2})}{\\theta \\Gamma(a)}\\\\\nE~Y^2|\\theta &= \\frac{a}{\\theta^2}\n\\end{aligned}\n\\]\nCall this density \\(g^2\\) such that \\(Y_1, \\ldots Y_n | \\theta \\sim g^2(a, \\theta)\\).\n\nFind the joint pdf of \\(Y_1, \\ldots Y_n | \\theta\\) and simplify as much as possible.\nSuppose \\(a\\) is known but \\(\\theta\\) is unknown. Identify a simple conjugate class of priors for \\(\\theta\\). For any arbitrary member of the class, identify the posterior density \\(p(\\theta | y_1, \\ldots y_n)\\).\nObtain a formula for \\(E~ \\theta | Y_1, \\ldots Y_n\\) and \\(Var~\\theta | Y_1, \\ldots Y_n\\) when the prior is in the conjugate class."
  },
  {
    "objectID": "hw/hw03.html#exercise-1",
    "href": "hw/hw03.html#exercise-1",
    "title": "Homework 3",
    "section": "",
    "text": "Let \\(Y_1, \\ldots Y_n | \\theta\\) be an i.i.d. random sample from a population with pdf \\(p(y|\\theta)\\) where\n\\[\np(y|\\theta) = \\frac{2}{\\Gamma(a)} \\theta^{2a} y^{2a -1} e^{-\\theta^2 y^2}\n\\]\nand \\(y &gt; 0\\), \\(\\theta &gt; 0\\), \\(a &gt; 0\\).\nFor this density,\n\\[\n\\begin{aligned}\nE~Y|\\theta &= \\frac{\\Gamma(a + \\frac{1}{2})}{\\theta \\Gamma(a)}\\\\\nE~Y^2|\\theta &= \\frac{a}{\\theta^2}\n\\end{aligned}\n\\]\nCall this density \\(g^2\\) such that \\(Y_1, \\ldots Y_n | \\theta \\sim g^2(a, \\theta)\\).\n\nFind the joint pdf of \\(Y_1, \\ldots Y_n | \\theta\\) and simplify as much as possible.\nSuppose \\(a\\) is known but \\(\\theta\\) is unknown. Identify a simple conjugate class of priors for \\(\\theta\\). For any arbitrary member of the class, identify the posterior density \\(p(\\theta | y_1, \\ldots y_n)\\).\nObtain a formula for \\(E~ \\theta | Y_1, \\ldots Y_n\\) and \\(Var~\\theta | Y_1, \\ldots Y_n\\) when the prior is in the conjugate class."
  },
  {
    "objectID": "hw/hw03.html#exercise-2",
    "href": "hw/hw03.html#exercise-2",
    "title": "Homework 3",
    "section": "Exercise 2",
    "text": "Exercise 2\nHandwritten digit classification. Data originally sourced from U.S. postal envelopes.\nExercise inspired by Prof. Hua Zhou’s Biostat M280.\n\n\n\n\n\nIn this exercise, you will build a very simple Bayesian image classifier. Load the training and test data sets using the code below.\n\nyTrain = readr::read_csv(\n  \"https://sta602-sp25.github.io/data/hw-digits-train.csv\")\n\nyTest = readr::read_csv(\n  \"https://sta602-sp25.github.io/data/hw-digits-test.csv\"\n)\n\nThe training data set contains 3822 images like the ones displayed above. Each image is a 32 x 32 bitmap, i.e. 1024 pixels, where each pixel is either black (0) or white (1). The 1024 pixels are divided into 64 blocks of 4 x 4 pixels. Each digit in the data set is represented by a vector of these blocks \\(\\mathbf{x} = (x_1, \\ldots, x_{64})\\) where each element is a count of the white pixels in a block (a number between 0 and 16).\nThe 65th column of the data set (id) is the actual digit label.\n\nHow many of each digit are in the training data set? Create a histogram to show the distribution of block10 white pixels for each digit. What do you notice?\nAssume each digit (i.e. each id) has its own multinomial data generative model. You can read about the multinomial distribution using ?rmultinom in R.\n\n\nWrite down the joint density for images with id “j”, \\(\\prod_{k = 1}^{n_j} p(\\mathbf{x}_k^{(j)} | \\boldsymbol{\\pi}^{(j)})\\). Here \\(n_j\\) is the number of images of type \\(j\\) and \\(\\boldsymbol{\\pi}^{(j)} = \\{\\pi_1^{(j)}, \\ldots, \\pi_{64}^{(j)} \\}\\)\nHow many total unknown parameters are in the complete joint density of all images?\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the multinomial sampling model places positive density on \\(x_i &gt; 16\\), which is impossible in our data. This model is overly simple.\n\n\n\nThe Dirichlet distribution is the multivariate generalization of the beta distribution. You can read more about it here. Place a Dirichlet prior on the probability parameters for each of your multinomial models in part b. Let the concentration parameters be all identically 1.\n\n\nCompute the posterior mean \\(\\hat{\\boldsymbol{\\pi}}^{(j)}\\) for each \\(j\\) (or approximate it with Monte Carlo sampling). Hint: you may need to look up how to sample from a Dirichlet distribution in R. You may do this manually or find a package with built-in functions.\n\n\nFor each image \\(\\mathbf{x}\\) in your testing data set, compute your predicted id according to \\(\\text{argmax}_{j}~~p(\\mathbf{x}| \\boldsymbol{\\hat{\\pi}}^{(j)})p(j)\\), where \\(p(j)\\) is the proportion of digit \\(j\\) in the training set. Report the number of correct and incorrect classifications in your testing data set."
  },
  {
    "objectID": "hw/hw03.html#exercise-3",
    "href": "hw/hw03.html#exercise-3",
    "title": "Homework 3",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(Y|\\theta \\sim \\text{binary}(\\theta)\\) and we believe \\(\\theta \\sim \\text{Uniform}(0, 1)\\) describes our uninformed prior beliefs about \\(\\theta\\). However, we are really interested in the log-odds \\(\\gamma = f(\\theta) = \\log \\frac{\\theta}{1 - \\theta}\\).\n\nFind the prior distribution for \\(\\gamma\\) induced by our prior on \\(\\theta\\). Is the prior informative about \\(\\gamma\\)? Verify \\(p(\\gamma)\\) using Monte Carlo sampling (i.e. sampling from \\(p(\\theta)\\)) and then plotting the empirical density of the transformed samples along with the closed-form solution.\nIn general, is the mean of the transform the same as the transform of the mean? In other words, is \\(E f(\\theta) = f(E[\\theta])\\)? Why or why not? Hint: come up with another example.\nAssume some data come in and \\(\\sum y_i = 7\\) out of \\(n = 10\\) trials. Report the posterior mean and 95% posterior confidence interval for \\(\\gamma\\). Is the transform of the quantile the quantile of the transform? Why or why not?"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA602\nBayesian Statistical Modeling and Data Analysis",
    "section": "",
    "text": "Syllabus\n\nCourse description\nThis course introduces Bayesian modeling and inference, motivated by real world examples. Course topics include Bayes’ theorem, exchangeability, conjugate priors, Markov chain Monte Carlo (MCMC), Gibbs sampling, Metropolis-Hastings, hierarchical modeling, Bayesian regression and generalized linear models. We compare and contrast Bayesian methods to the frequentist paradigm. By the end of this course students should feel comfortable (1) writing Bayesian models and, when appropriate, (2) sampling from the posterior using MCMC to make inference.\n\n\nLogistics\n\nTeaching team & office hours\n\n\n\n\nContact\nOffice hours\nLocation\n\n\n\n\nDr. Alexander Fisher\naaf29@duke.edu\nWe/Th/Fr: 10:00am-11:00am\nOld Chem 211A/B\n\n\nChristine Shen\nyueming.shen@duke.edu\nMo: 9:30am-11:30am\nOld Chem 203B\n\n\nBenedetta Bruni\nbenedetta.bruni@duke.edu\nTh: 5:00pm-7:00pm\nOld Chem 203A\n\n\nJaehoan Kim\njaehoan.kim@duke.edu\nMo: 5:00pm-7:00pm\nOld Chem 203B\n\n\nHaochen Qin\nhaocheng.qin@duke.edu\nWe: 3:00pm-5:00pm\nZoom (link on Canvas)\n\n\n\n\n\nMeetings\n\n\n\nLecture\nWe/Fr 8:30am - 9:45am\nOld Chemistry 116\n\n\nLab 01\nMo 1:25pm - 2:40pm\nOld Chemistry 201\n\n\nLab 02\nMo 3:05pm - 4:20pm\nLSRC A156\n\n\nLab 03\nMo 3:05pm - 4:20pm\nBiological Sciences 154\n\n\n\nCourse website: sta602-sp25.github.io\n\n\n\n\n\n\n\n\n\nCourse material\n\nA First Course in Bayesian Statistical Methods. As a Duke student, an electronic version of the book is freely available to you on Springer link. Check the errata at the link above.\nChapter summaries. I compile major take-away points from each section. Review these to help prepare for exams.\nWe will use the statistical software package R on homework asignments in this course. R is freely available at http://www.r-project.org/. RStudio, the popular IDE for R, is freely available at https://posit.co/downloads/.\n\n\n\nSchedule of topics\nPart I: The Bayesian modeling toolkit\n\nReview of probability\nConjugate statistical models\nPosterior summaries and Monte Carlo sampling\nMarkov chain Monte Carlo (Metropolis-Hastings)\nSemi-conjugate models and Gibbs sampling\n\nPart II: Statistical model building and analysis\n\nLinear regression\nGeneralized linear models\nHierarchical models\n\n\n\nEvaluation\n\n\n\n\n\n\n\nAssignment\nDescription\n\n\n\n\nHomework (40%)\nIndividual take-home assignments, submitted to Gradescope.\n\n\nMidterms (30%)\nTwo in-class exams.\n\n\nFinal exam (25%)\nCumulative final during final’s week.\n\n\nQuizzes (5%)\nIn-class pop quizzes.\n\n\n\nA \\(&gt;= 93\\), A- \\(&lt; 93\\), B+ \\(&lt; 90\\), B \\(&lt; 87\\), B- \\(&lt; 83\\), C+ \\(&lt;80\\), C \\(&lt; 77\\), C- \\(&lt; 73\\), D+ \\(&lt; 70\\), D \\(&lt; 67\\), D- \\(&lt; 63\\), F \\(&lt; 60\\)\n\n\n\n\n\n\nA note on quizzes\n\n\n\nOn random class days, there will be a brief quiz on the previous lectures. If you score \\(&gt;60\\%\\) cumulatively on your final quiz grade, you will receive full participation credit. Your lowest two quizzes will also be dropped.\n\n\n\n\n\n\n\n\nA note on exams\n\n\n\nIf you miss either midterm 1 or midterm 2, and have an excused absence, your missing midterm grade will be replaced by your final exam grade. You must take at least 1 midterm and the final exam to pass the course.\n\n\n\n\n\n\n\n\nPolicies\nAcademic integrity\nBy enrolling in this course, you commit to upholding Duke’s community standard reproduced as follows:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\nAny violations of academic integrity will automatically result in a 0 for the assignment and will be reported to Duke Graduate School for further action. For the Exams and Quizzes, students are required to work alone. For the Homework assignments, students may work with a study group but each student must write up and submit their own answers.\nLate work\nLate homework may be submitted within 48 hours of the assignment deadline. Late homework submitted within 24 hours (even 1 minute late) will receive a 5% late penalty. Late work submitted between 24 to 48 hours of the deadline will receive a 10% late penalty. Work submitted after 48 hours will not be accepted. Exams cannot be turned in late and can only be excused under exceptional circumstances. The Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). For emergencies, email notification is needed at the first reasonable time.\nErrors in grading\nErrors in grading must be brought to the attention of the TA or instructor during office hours within 1 week of receiving the grade."
  },
  {
    "objectID": "slides/lab3-review.html#exercise",
    "href": "slides/lab3-review.html#exercise",
    "title": "Exam practice",
    "section": "Exercise",
    "text": "Exercise\nPhysicists studying a radioactive substance measure the times at which the substance emits a particle. They will record \\(n+1\\) emissions and set \\(Y_1\\) to be the time elapsed between the first and second emission, \\(Y_2\\) to be the time elapsed between the second and third emission and so on. They will model the data as \\(Y_1, \\ldots Y_n | \\theta \\sim \\text{exponential}(\\theta)\\). The pdf of the exponential(\\(\\theta\\)) distribution is\n\\[\np(y |\\theta) = \\theta e^{-\\theta y} \\ \\text{ for } \\ y&gt;0, \\ \\theta&gt;0.\n\\]\nFor this distribution, \\(E[Y|\\theta] = \\frac{1}{\\theta}\\).\n(a). Write out the corresponding joint density \\(p(y_1, \\ldots, y_n | \\theta)\\) and simplify as much as possible. Justify each step of your calculation.\n(b). Compute the maximum likelihood estimate \\(\\hat{\\theta}_{MLE}\\), i.e. the value \\(\\hat{\\theta}_{MLE}\\) that maximizes \\(p(y_1,\\ldots y_n | \\theta)\\). Hint: it’s easier to work with the log-likelihood.\n(c). Choose a prior \\(p(\\theta)\\) that is conjugate to the likelihood. Hint: look at kernels of densities on the distribution sheet. Write out the formula for \\(p(\\theta | y_1, \\ldots y_n)\\), up to a proportionality in \\(\\theta\\), and simplify as much as possible. From this, identify explicitly the posterior distribution of \\(\\theta\\) (i.e., write “the posterior is a blank distribution with parameter(s) blank)”.\n(d). Obtain the formula for \\(E[\\theta, y_1, \\ldots y_n]\\) as a function of \\(a, b, n\\) and \\(y_1, \\ldots y_n\\), and try to write this as a function of the estimator \\(\\hat{\\theta}\\) you found in part (b). What does \\(E[\\theta | y_1,\\ldots,y_n]\\) get close to as \\(n\\) increases?\n(e). Report a 95% posterior confidence interval for \\(\\theta\\).\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "slides/estimator-lab.html#exercise-1-estimators",
    "href": "slides/estimator-lab.html#exercise-1-estimators",
    "title": "Estimators",
    "section": "Exercise 1: estimators",
    "text": "Exercise 1: estimators\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\)."
  },
  {
    "objectID": "slides/estimator-lab.html#exercise-2-estimators",
    "href": "slides/estimator-lab.html#exercise-2-estimators",
    "title": "Estimators",
    "section": "Exercise 2: estimators",
    "text": "Exercise 2: estimators\n\\[\n\\begin{aligned}\nY_1, \\ldots, Y_n &\\sim \\text{ i.i.d. binary}(\\theta)\\\\\n\\theta &\\sim \\text{beta}(a, b)\n\\end{aligned}\n\\]\n\nCompute \\(\\hat{\\theta}_{MLE}\\)\nCompute \\(\\hat{\\theta}_{B} = E[\\theta | y_1,\\ldots y_n]\\).\nCompare \\(MSE(\\hat{\\theta}_{MLE})\\) to \\(MSE(\\hat{\\theta}_{B})\\)). Under what conditions is the MSE of \\(\\hat{\\theta}_B\\) smaller?"
  },
  {
    "objectID": "slides/estimator-lab.html#solution-1",
    "href": "slides/estimator-lab.html#solution-1",
    "title": "Estimators",
    "section": "Solution 1",
    "text": "Solution 1\nLet \\(\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\).\n\\[\n\\begin{aligned}\nBias(\\hat{\\sigma}^2 | \\sigma^2 = \\sigma_0^2) &= E[\\hat{\\sigma}^2|\\sigma_0^2] - \\sigma_0^2\\\\\n&=  - \\sigma_0^2 + \\frac{1}{n} \\sum_{i = 1}^n E[(Y_i -\\bar{Y})^2|\\sigma_0^2]\\\\\n&= - \\sigma_0^2 + \\frac{1}{n} \\sum_{i=1}^n \\left[\nE[Y_i^2 |\\sigma_0^2] - 2E[Y_i \\bar{Y}|\\sigma_0^2] + E[\\bar{Y}^2 | \\sigma_0^2]\n\\right]\n\\end{aligned}\n\\]\nRecall that for any random variable X, \\(Var(X) = E[X^2] - E[X]^2\\). Using this fact, we continue our proof above:\n\\[\n\\begin{aligned}\n&= -\\sigma_0^2 +(\\sigma_0^2  + \\theta^2)\n-2 \\frac{1}{n} \\sum_{i=1}^n \\left[  E~\\left(Y_i \\frac{1}{n}\\sum_j Y_j\\right) | \\sigma_0^2    \\right]\n+ \\left(\\frac{\\sigma_0^2}{n} + \\theta^2\\right)\\\\\n&= 2\\theta^2 + \\frac{\\sigma_0^2}{n} - \\frac{2}{n}\n\\left(n\\theta^2  - \\sigma_0^2\n\\right)\\\\\n&= \\frac{(n-1)\\sigma_0^2}{n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/estimator-lab.html#solution-2",
    "href": "slides/estimator-lab.html#solution-2",
    "title": "Estimators",
    "section": "Solution 2",
    "text": "Solution 2\n\\[\n\\begin{aligned}\n\\hat{\\theta}_{MLE} &= \\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i\\\\\n\\hat{\\theta}_B &= \\frac{n\\bar{y}+a}{n+a+b} =\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}_{MLE}|\\theta) &= \\frac{\\theta(1-\\theta)}{n}\\\\\nMSE(\\hat{\\theta}_B|\\theta) &= \\frac{n}{n + a + b}\\bar{Y} + \\frac{a + b}{n + a + b} \\frac{a}{a + b} =  w \\bar{Y} + (1-w)\\frac{a}{a+b}\\\\\n&= w^2Var(\\bar{Y} | \\theta) +  (1-w)^2 \\left(\\frac{a}{a+b} - \\theta\\right)^2\\\\\n&= {w^2} \\frac{\\theta(1-\\theta)}{n} + (1-w)^2  \\left(\\frac{a}{a+b} - \\theta\\right)^2\n\\end{aligned}\n\\] For the Bayesian estimator to have smaller MSE than the MLE, we need\n\\[\n\\begin{aligned}\n\\left(\\frac{a}{a+b} - \\theta\\right)^2 &\\leq \\frac{\\theta(1 - \\theta)}{n} \\frac{1 + w}{1 - w}\\\\\n&\\leq \\frac{\\theta(1 - \\theta) (2n + a + b)}{n^2}\n\\end{aligned}\n\\]\nIn words, if our prior guess \\(a / (a+b)\\) is “close enough” to \\(\\theta\\), where “close enough” is defined by the inequality above and is proportional to the variance of the estimator, then the MSE of the Bayesian estimator is smaller.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "readings/introMonteCarlo.html",
    "href": "readings/introMonteCarlo.html",
    "title": "Preparatory reading: Monte Carlo",
    "section": "",
    "text": "Chapter 4 of Hoff.\nOriginal JASA paper by Metropolis and Ulam (1949), also a pdf can be found on canvas under “files” –&gt; “additional readings”\nhistorical article from Los Alamos National Laboratory"
  },
  {
    "objectID": "notes/priors.html",
    "href": "notes/priors.html",
    "title": "Priors",
    "section": "",
    "text": "Definition\n\n\n\nA proper prior is a density function that:\n\ndoes not depend on data and\nintegrates to 1.\n\nIf a prior is not proper, we call the prior improper.\nIf a prior integrates to a positive finite value, it is an un-normalized density. This is different from being an improper prior. An un-normalized density can be normalized by being multiplied by a constant to integrate to 1.\n\n\n\n\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\] \\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff)."
  },
  {
    "objectID": "notes/priors.html#improper-priors",
    "href": "notes/priors.html#improper-priors",
    "title": "Priors",
    "section": "",
    "text": "Definition\n\n\n\nA proper prior is a density function that:\n\ndoes not depend on data and\nintegrates to 1.\n\nIf a prior is not proper, we call the prior improper.\nIf a prior integrates to a positive finite value, it is an un-normalized density. This is different from being an improper prior. An un-normalized density can be normalized by being multiplied by a constant to integrate to 1.\n\n\n\n\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\] \\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff)."
  },
  {
    "objectID": "notes/priors.html#unit-information-prior",
    "href": "notes/priors.html#unit-information-prior",
    "title": "Priors",
    "section": "Unit information prior",
    "text": "Unit information prior\nPriors are meant to describe our state of knowledge before examining data.\n\n\n\n\n\n\nDefinition\n\n\n\nA unit information prior is an improper, data-dependent prior that contains the same amount of information as would be contained in a single observation.\n\n\n\nExample:\n\\[\n\\begin{aligned}\nY | \\beta, \\sigma^2 &\\sim N_n(X \\beta, \\sigma^2 I_n)\\\\\n\\beta &\\sim N_p(\\beta_0, \\Sigma_0)\\\\\n1/\\sigma^2  &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2 /2)\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\beta_0 &= (X^TX)^{-1}X^Ty\\\\\n\\Sigma_0 &= \\left((X^TX)/n\\sigma^2\\right)^{-1}\\\\\n\\nu_0 &= 1\\\\\n\\sigma_0^2 &= \\text{SSR}(\\hat{\\beta}_{OLS})/ n\n\\end{aligned}\n\\]\nThis is using the MLE (or equivalently OLS estimator) as ‘unit information’. Notice \\(\\beta_0 = \\hat{\\beta}_{OLS}\\) and the precision \\(\\Sigma_0^{-1}\\) is just 1/n the precision of the MLE: \\(\\left(Var[\\hat{\\beta}_{OLS}]\\right)^{-1}\\).\nSimilarly, \\(\\nu_0 = 1\\) (implying unit information) and \\(\\sigma_0^2\\) is the MLE of \\(\\sigma^2\\).\n\n\nIn practice\nProcedurally, one can construct a unit information prior in the following way:\nLet \\(Y_1,\\ldots,Y_n \\sim \\text{iid } p(y|\\theta)\\). Let \\(l(\\theta | y_1,\\ldots,y_n) = \\sum_{i=1}^n \\log p(y_i|\\theta)\\).\n\nCompute the MLE, \\(\\hat{\\theta}_{MLE} = \\text{argmax}_{\\theta}~ l(\\theta|y_1,\\ldots,y_n)\\).\nCompute the negative of the curvature of the log-likelihood: \\(J(\\theta) = - \\frac{\\partial^2}{\\partial \\theta^2} l(\\theta | y_1,\\ldots, y_n)\\).\nLet the max of the prior be the MLE, and let the curvature of the prior be \\(J(\\theta) / n\\).\n\n\nExercise\n\n\n\nLet \\(Y_1,\\ldots,Y_n \\sim \\text{iid binary}(\\theta)\\). Find \\(\\hat{\\theta}_{MLE}\\).\nFind the unit information prior \\(p(\\theta)\\). Hint: find a density \\(p(\\theta)\\) such that \\(\\log p(\\theta) = l(\\theta | y_1,\\ldots,y_n)/n + c\\) where \\(c\\) is a constant that doesn’t depend on \\(\\theta\\)."
  },
  {
    "objectID": "notes/priors.html#improper-uniform-priors",
    "href": "notes/priors.html#improper-uniform-priors",
    "title": "Priors",
    "section": "Improper uniform priors",
    "text": "Improper uniform priors\nIn some cases we may wish to describe our ignorance a priori using a vague prior that plays a minimal role in the posterior distribution.\nA common trap is to imagine that a flat, or uniform prior is uninformative. However, we know that uniform priors are often informative. For example, you showed on a previous homework that a uniform prior on binary probability of success \\(\\theta\\) is informative on the log-odds \\(\\log \\left(\\frac{\\theta}{(1-\\theta)}\\right)\\).\nHowever, when a uniform prior is improper, it is informative because it states that most of the mass is infinitely far away from any bounded region.\n\nExample:\n\\[\n\\begin{aligned}\nY |\\theta &\\sim Poisson(\\theta)\\\\\np(\\theta) &\\propto 1 \\text{ for } \\theta \\in (0, \\infty)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/priors.html#jeffreys-prior",
    "href": "notes/priors.html#jeffreys-prior",
    "title": "Priors",
    "section": "Jeffreys prior",
    "text": "Jeffreys prior\n\n\n\n\n\n\nDefinition\n\n\n\nThe Jeffreys prior\n\\[\nJ(\\theta) \\propto \\sqrt{I(\\theta)}\n\\] where \\(I(\\theta) = -E[\\frac{\\partial^2}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta]\\) is the Fisher information.\n\n\nThe defining feature of Jeffreys prior is that is invariant under monotonic transformations. This principle of invariance is one approach to non-informative priors that works well for single parameter priors. Multiparameter extensions are often less useful.\n\nExample:\n\\[\n\\begin{aligned}\nY | \\theta &\\sim \\text{Poisson}(\\theta)\\\\\np(\\theta) &\\propto \\theta^{-1/2}\n\\end{aligned}\n\\]\n\nExerciseSolutionBonus\n\n\n\nProve that \\(p(\\theta) \\propto \\theta^{-1/2}\\) is the Jeffreys prior for the Poisson model above.\nAssume you observe \\(\\{y_1,\\ldots, y_n\\}\\). To what family of distributions does the posterior \\(p(\\theta|y_1,\\ldots,y_n)\\) belong? Note: you are assuming \\(Y_i \\sim \\text{iid Poisson}(\\theta)\\). What are the parameters?\n\n\n\n\\[\n\\begin{aligned}\nI(\\theta) = -E\\left[\\frac{\\partial^2}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta \\right]\n&=\n-E\\left[\\frac{\\partial^2}{\\partial\\theta^2} \\left(y \\log \\theta -\\theta - \\log y! \\right) | \\theta\\right]\\\\\n&= E\\left[ \\frac{y}{\\theta^2} | \\theta\\right]\\\\\n&= \\frac{1}{\\theta}\n\\end{aligned}\n\\] Therefore, \\(J(\\theta) \\propto \\theta^{-1/2}\\).\n\nPosterior is \\(\\text{gamma}(\\sum y_i + \\frac{1}{2}, n)\\)\n\n\n\nExamine the prior under re-parameterization.\nLet \\(\\phi = \\log \\theta\\). Then \\(\\log p(y | \\phi) = y \\phi - e^\\phi + \\log y!\\).\n\\[\n\\begin{aligned}\nI(\\phi) = -E\\left[\\frac{\\partial^2}{\\partial\\phi^2} \\log p(Y|\\phi) | \\phi \\right] &= -E\\left[ -e^\\phi |\\phi\\right]\\\\\n&= e^\\phi\n\\end{aligned}\n\\] Therefore, \\(J(\\phi) \\propto e^{\\phi/2}\\).\nSeparately, using the Jeffreys prior we obtained in \\(\\theta\\), one can use the change of variables formula: \\(p(\\phi) = p(\\theta) \\left|\\frac{d\\theta}{d\\phi}\\right|\\) to show that \\(J(\\phi) \\propto e^{\\phi/2}\\)."
  },
  {
    "objectID": "notes/lec01-probability.html",
    "href": "notes/lec01-probability.html",
    "title": "Probability",
    "section": "",
    "text": "This is foundational material. Most of it is background you will have learned in a previous probability course. While dry, we must soldier on to get to the exciting stuff."
  },
  {
    "objectID": "notes/lec01-probability.html#review-set-theory",
    "href": "notes/lec01-probability.html#review-set-theory",
    "title": "Probability",
    "section": "Review: set theory",
    "text": "Review: set theory\n\n\n\n\n\n\nDefinition\n\n\n\nset: a collection of elements, denoted by {}\nExamples\n\n\\(\\phi\\) = {} “the empty set”\nA = {1, 2, 3}\nB = {taken STA199, has not taken STA199}\nC = {1, 2, 3, 4, 5}\nD = {{1, 2, 3}, {4, 5}}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsubset: denoted by \\(\\subset\\), \\(A \\subset B\\) iff \\(a \\in A \\implies a \\in B\\)\nExamples\nUsing the previously examples of A, B and C above,\n\n\\(A \\subset C\\)\n\\(A \\not\\subset B\\)\n\n\n\nRecall:\n\n\\(\\cup\\) means “union”, “or”\n\\(\\cap\\) means “intersection”, “and”\n\n\n\n\n\n\n\nDefinition\n\n\n\npartition: {\\(H_1, H_2, ... H_n\\)} = \\(\\{H_i\\}_{i = 1}^n\\) is a partition of \\(\\mathcal{H}\\) if\n\nthe union of sets is \\(\\mathcal{H}\\) i.e. \\(\\cup_{i = 1}^n H_i = \\mathcal{H}\\)\nthe sets are disjoint i.e. \\(H_i \\cap H_j = \\phi\\) for all \\(i \\neq j\\)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsample space: \\(\\mathcal{H}\\), the set of all possible data sets (outcomes)\nevent: a set of one or more outcomes\nNote: p(\\(\\mathcal{H}\\)) = 1\nExamples\n\nRoll a six-sided die once. The sample space \\(\\mathcal{H} = \\{1, 2, 3, 4, 5, 6\\}\\).\nLet \\(A\\) be the event that the die lands on an even number. \\(A = \\{2, 4, 6 \\}\\)"
  },
  {
    "objectID": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "href": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "title": "Probability",
    "section": "Axioms of probability (in words)",
    "text": "Axioms of probability (in words)\nP1. Probabilities are between 0 and 1, importantly p(\\(\\neg\\)H|H) = 0 and p(H|H) = 1.\nP2. If two events A and B are disjoint, then p(A or B) = p(A) + p(B)\nP3. The joint probability of two events may be broken down stepwise: p(A,B) = p(A|B)p(B)\n–\nIt follows that\n\nfor any partition \\(\\{H_i\\}_{i = 1}^n\\), \\(\\sum_{i=1}^n p(H_i) = 1\\) (rule of total probability)\n\nnote: simplest partition \\(p(A) + p(\\neg A) = 1\\)\n\n\\(p(A) = \\sum_{i=1}^n p(A, H_i)\\) (rule of marginal probability)\n\nnote: P3 implies that equivalently, \\(p(A) = \\sum_{i=1}^n p(A | H_i) p(H_i)\\)\n\np(A|B) = p(A,B) / p(B) when p(B) \\(\\neq 0\\)\n\nnote: these statements can also be made where each term is additionally conditioned on another event C\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDerive Bayes’ rule:\n\\(p(H_i|X) = \\frac{p(X|H_i)p(H_i)}{\\sum_k p(X|H_k)p(H_k)}\\)\nusing the axioms of probability.\n\n\nBayes’ rule tells us how to update beliefs about \\(\\{H_i \\}_{i = 1}^n\\) given data \\(X\\)."
  },
  {
    "objectID": "notes/lec01-probability.html#independence",
    "href": "notes/lec01-probability.html#independence",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(p(F, G | H) = p(F | H) p(G | H)\\)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nShow conditional independence implies\n\\(p(F | H, G) = p(F | H)\\)\n\n\nThis means that if we know H, then G does not supply any additional information about F."
  },
  {
    "objectID": "notes/lec01-probability.html#random-variables",
    "href": "notes/lec01-probability.html#random-variables",
    "title": "Probability",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nDefinition\n\n\n\nIn Bayesian inference, a random variable is an unknown numerical quantity about which we make probability statements.\nThe support of a random variable is the set of values a random variable can take.\nExamples\n\nData. E.g. the amount of a wheat a field will yield later this year. Since this data has not yet been generated, the quantity is unknown.\nA population parameter. E.g. the true mean resting heart rate of Duke students. Note: this is a fixed (non-random) quantity, but it is also unknown. We use probability to describe our uncertainty in this quantity.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ndiscrete random variable: a random variable that takes countably many values. Y is discrete if its possible outcomes can be enumerated \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots \\}\\).\nNote: discrete does not mean finite. There may be infinitely many outcomes!\nExamples\n\nY = the number of children of a randomly sampled person\nY = the number of visible stars in the sky on a randomly sampled night of the year\n\nFor each \\(y \\in \\mathcal{Y}\\), let p(Y) = probability(Y = y). Then p is the probability mass function (pmf) of the random variable Y.\nExamples\n\nBinomial pmf: the probability of \\(y\\) successes in \\(n\\) trials, where each trial has an individual probability of success \\(\\theta\\). \\[p(y | \\theta) = {n \\choose y} \\theta ^y (1-\\theta)^{n-y} \\text{ for } y \\in \\{0, 1, \\ldots n \\}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots n\\}\\)\nsuccess probability \\(\\theta \\in [0, 1]\\)\ndbinom(y, n, theta) computes this pmf in R\n\nPoisson pmf: probability of \\(y\\) events occurring during a fixed interval at a mean rate \\(\\theta\\) \\[p(y | \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots \\}\\)\nrate \\(\\theta \\in \\mathbb{R}^+\\)\ndpois(y, theta) computes this pmf in R\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ncontinuous random variable: a random variable that takes uncountably many values.\nThe probability density function (pdf) of a continuous random variable, X is defined\n\\(pdf(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{p(x &lt; X &lt; x + \\Delta x)}{\\Delta x}\\)\nand the probability X is in some interval,\n\\(p(x_1 &lt; X &lt; x_2) = \\int_{x_1}^{x_2} pdf(x) dx\\)\nExamples\n\nNormal pdf \\[\np(x | \\mu, \\sigma) = (2\\pi \\sigma^2)^{-\\frac{1}{2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n\\]\nUniform pdf \\[p(x|a,b) =\n\\begin{cases}\n\\frac{1}{b - a} \\hspace{.6cm}\\text{ for } x \\in [a, b]\\\\\n0 \\hspace{1cm}\\text{ otherwise }\n\\end{cases}\\]\n\n\n\nNote: we will often abuse notation and use \\(p(x)\\) in place of \\(pmf(x)\\) and \\(pdf(x)\\) and prob(event), where only the context makes meaning clear.\nFor pmfs\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\leq 1\\\\\n\\sum_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nSimilarly, for pdfs,\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\ \\text{and} \\\\\n\\int_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nNote: For a continuous random variable Y, p(y) can be larger than 1 and p(y) is not p(Y = y), which equals 0.\n\n\n\n\n\n\nDefinition\n\n\n\nThe part of the density/mass function that depends on the variable is called the kernel.\nExample\n\nthe kernel of the normal pdf is \\(e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat’s the kernel of a gamma random variable X?\nRecall: the pdf of a gamma distribution:\n\\[\np(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#moments",
    "href": "notes/lec01-probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nFor a random variable X, the \\(n\\)th moment is defined as E(\\(X^n\\)).\nRecall, the expected value is defined for discrete random variable X,\n\\[\nE(X) = \\sum_{x \\in \\mathcal{X}} x p(x)\n\\]\nand for continuous random variable Y,\n\\[\nE(Y) = \\int_{-\\infty}^{\\infty} y p(y) dy\n\\]\nThe variance of a random variable, is also known as the second central moment and is defined\n\\[\nE(X - E(X))^2\n\\] or equivalently,\n\\[\nE(X^2) - E(X)^2\n\\]\nMore generally, the covariance between two random variables X and Y is defined\n\\[\nE[(X - E[X])(Y - E[Y])]\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#exchangeability",
    "href": "notes/lec01-probability.html#exchangeability",
    "title": "Probability",
    "section": "Exchangeability",
    "text": "Exchangeability\n\noffline notes"
  },
  {
    "objectID": "notes/extra-regression-readings.html",
    "href": "notes/extra-regression-readings.html",
    "title": "Optional readings on linear regression",
    "section": "",
    "text": "Find downloadable pdfs in Sakai.\nFor going beyond the ridge regression discussed in class, see this discussion of the Bayesian Lasso by Park and Casella (2008) that places Bayesian ridge within the broader class of exponential power priors.\nFor additional discussion of rstanarm, see continuous data in rstanarm. This is an introductory tutorial to using stan within the rstanarm package.\nFox-Ch12 - some pages from Ch12 of John Fox’s Applied Regression Analysis and GLMs (a favorite book of mine) on assessing the standard assumptions of linear regression, and specifically how residual plots help. This is very relevant to Ex4 of HW8, but again, the bare minimum you need for this exercise is a residual plot and a QQ plot + discussion."
  },
  {
    "objectID": "notes/additionalRegressionNotes.html",
    "href": "notes/additionalRegressionNotes.html",
    "title": "Additional regression notes",
    "section": "",
    "text": "Setup:\n\\[\ny_i = z_1 \\beta_1 x_{i, 1} + \\cdots + z_p \\beta_p x_{i, p} + \\epsilon_i\n\\]\n\n\\(y_i \\in \\mathbb{R}\\)\n\\(\\beta_i \\in \\mathbb{R}\\)\n\\(z_i \\in \\{0, 1\\}\\)\n\nThe \\(z_j\\)’s indicate which regression coefficients are non-zero.\n\n\n\n\n\n\nNote\n\n\n\nNotice that every set of values \\(\\mathbf{z} = \\{z_1, \\ldots z_p \\}\\) corresponds to a different model. So a prior \\(p(z)\\) may be thought of as a prior distribution over models.\n\n\nBayesian model selection proceeds by obtaining a posterior distribution for \\(\\mathbf{z}\\):\n\\[\np(\\mathbf{z}| \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})}{\\sum_\\mathbf{\\tilde{z}} p(\\mathbf{\\tilde{z}}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{\\tilde{z}})}\n\\]\nAlternatively, we may prefer to compare any two models with the posterior odds:\n\\[\n\\text{odds}(\\mathbf{z}_a, \\mathbf{z}_b | \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}_a | \\mathbf{y}, \\mathbf{X})}{p(\\mathbf{z}_b | \\mathbf{y}, \\mathbf{X})} = \\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)} \\times \\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\n\\] Notice that when examining the odds of one model vs another, we avoid computing the denominator of \\(p(\\mathbf{z}| \\mathbf{y}, \\mathbf{X})\\), and thereby exhaustively computing the probability of every model.\n\n\n\n\n\n\nDefinitions\n\n\n\n\n\\(\\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)}\\) is called the “prior odds”.\n\\(\\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\\) is called the “Bayes factor” i.e. how much the data favor model \\(\\mathbf{z}_a\\) over model \\(\\mathbf{z}_b\\).\n\n\n\nThis formulation above elicits a need to compute \\(p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})\\). To compute this in closed form, we will choose a few special priors (given a MVN data generative process).\n\\[\n\\begin{aligned}\n\\mathbf{y}| \\mathbf{X}, \\mathbf{z}, \\sigma^2 &\\sim MVN(X \\text{diag}(\\mathbf{z})\\beta, \\sigma^2 I)\\\\\n\\beta_z | \\mathbf{X}_z, \\sigma^2 &\\sim MVN(\\boldsymbol{0}, g\\sigma^2 [\\mathbf{X}_z^T \\mathbf{X}_z]^{-1})\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2 /2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/additionalRegressionNotes.html#model-selection",
    "href": "notes/additionalRegressionNotes.html#model-selection",
    "title": "Additional regression notes",
    "section": "",
    "text": "Setup:\n\\[\ny_i = z_1 \\beta_1 x_{i, 1} + \\cdots + z_p \\beta_p x_{i, p} + \\epsilon_i\n\\]\n\n\\(y_i \\in \\mathbb{R}\\)\n\\(\\beta_i \\in \\mathbb{R}\\)\n\\(z_i \\in \\{0, 1\\}\\)\n\nThe \\(z_j\\)’s indicate which regression coefficients are non-zero.\n\n\n\n\n\n\nNote\n\n\n\nNotice that every set of values \\(\\mathbf{z} = \\{z_1, \\ldots z_p \\}\\) corresponds to a different model. So a prior \\(p(z)\\) may be thought of as a prior distribution over models.\n\n\nBayesian model selection proceeds by obtaining a posterior distribution for \\(\\mathbf{z}\\):\n\\[\np(\\mathbf{z}| \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})}{\\sum_\\mathbf{\\tilde{z}} p(\\mathbf{\\tilde{z}}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{\\tilde{z}})}\n\\]\nAlternatively, we may prefer to compare any two models with the posterior odds:\n\\[\n\\text{odds}(\\mathbf{z}_a, \\mathbf{z}_b | \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}_a | \\mathbf{y}, \\mathbf{X})}{p(\\mathbf{z}_b | \\mathbf{y}, \\mathbf{X})} = \\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)} \\times \\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\n\\] Notice that when examining the odds of one model vs another, we avoid computing the denominator of \\(p(\\mathbf{z}| \\mathbf{y}, \\mathbf{X})\\), and thereby exhaustively computing the probability of every model.\n\n\n\n\n\n\nDefinitions\n\n\n\n\n\\(\\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)}\\) is called the “prior odds”.\n\\(\\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\\) is called the “Bayes factor” i.e. how much the data favor model \\(\\mathbf{z}_a\\) over model \\(\\mathbf{z}_b\\).\n\n\n\nThis formulation above elicits a need to compute \\(p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})\\). To compute this in closed form, we will choose a few special priors (given a MVN data generative process).\n\\[\n\\begin{aligned}\n\\mathbf{y}| \\mathbf{X}, \\mathbf{z}, \\sigma^2 &\\sim MVN(X \\text{diag}(\\mathbf{z})\\beta, \\sigma^2 I)\\\\\n\\beta_z | \\mathbf{X}_z, \\sigma^2 &\\sim MVN(\\boldsymbol{0}, g\\sigma^2 [\\mathbf{X}_z^T \\mathbf{X}_z]^{-1})\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2 /2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "hw/hw01.html",
    "href": "hw/hw01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Let \\(X_i \\in \\mathcal{X}\\) for all \\(i \\in \\{1, 2, \\ldots\\}\\) and suppose our belief model for \\(\\mathbf{X} = \\{ X_1, \\ldots X_n \\}\\) is exchangeable for all \\(n\\). Show, using de Finetti’s theorem, that for all \\(i \\neq j\\),\n\\[\nCov(X_i, X_j) \\geq 0 \\text{ and }\n\\]\n\\[\nCorr(X_i, X_j) \\geq 0.\n\\]"
  },
  {
    "objectID": "hw/hw01.html#exercise-1",
    "href": "hw/hw01.html#exercise-1",
    "title": "Homework 1",
    "section": "",
    "text": "Let \\(X_i \\in \\mathcal{X}\\) for all \\(i \\in \\{1, 2, \\ldots\\}\\) and suppose our belief model for \\(\\mathbf{X} = \\{ X_1, \\ldots X_n \\}\\) is exchangeable for all \\(n\\). Show, using de Finetti’s theorem, that for all \\(i \\neq j\\),\n\\[\nCov(X_i, X_j) \\geq 0 \\text{ and }\n\\]\n\\[\nCorr(X_i, X_j) \\geq 0.\n\\]"
  },
  {
    "objectID": "hw/hw01.html#exercise-2",
    "href": "hw/hw01.html#exercise-2",
    "title": "Homework 1",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet \\(X, Y, Z\\) be random variables with joint density (discrete or continuous)\n\\[\np(x, y, z) \\propto f(x,z) g(y, z) h(z).\n\\]\nShow that\n\n\\(p(x | y, z) \\propto f(x, z)\\), i.e. \\(p(x | y, z)\\) is a function of \\(x\\) and \\(z\\).\n\\(p(y | x, z) \\propto g(y, z)\\), i.e. \\(p(y | x, z)\\) is a function of \\(y\\) and \\(z\\).\n\\(X\\) and \\(Y\\) are conditionally independent given \\(Z\\)."
  },
  {
    "objectID": "hw/hw01.html#exercise-3",
    "href": "hw/hw01.html#exercise-3",
    "title": "Homework 1",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe number of particles \\(Y\\) emitted from a rock sample depends on the unknown amount \\(\\theta\\) of the sample that is radioactive. For each possible value of \\(\\theta\\),\n\\[\nPr(Y = y | \\theta) = \\theta^y e^{-\\theta} / y!\n\\] for each \\(y \\in \\{0, 1, 2, \\ldots \\}\\). Suppose it is known that the rock is one of three possible types \\(A\\), \\(B\\), or \\(C\\), each with a particular value of \\(\\theta\\), that is, \\(\\theta \\in \\{\\theta_A, \\theta_B, \\theta_C \\}\\) where \\(\\theta_A = 1.1\\), \\(\\theta_B = 3.2\\), and \\(\\theta_C = 4.5\\).\n\nMake a graph of \\(Pr(Y = y | \\theta)\\) as a function of \\(y\\) for each of the three possible values of \\(\\theta\\) (for some reasonable range of \\(y\\)-values.\nNow suppose that the rock is of type \\(A\\), \\(B\\), or \\(C\\) with probabilities \\(.4\\), \\(.3\\) and \\(.3\\) respectively. Compute the marginal probability of \\(Y\\), that is,\n\\(Pr(Y = y) = Pr(Y = y | \\theta_A) Pr(\\text{type} = A) + Pr(Y = y | \\theta_B) Pr(\\text{type} = B) + Pr(Y = y | \\theta_C) Pr(\\text{type} = C)\\)\nPlot this as a function of \\(y\\) and compare the graph to the three graphs from part a.\nSuppose it is observed that \\(Y = 4\\). Using the rules of conditional probability, compute the probabilities of each type conditional on \\(Y = 4\\), that is, compute \\(Pr(\\theta = \\theta_X | Y = 4)\\) for each \\(X \\in \\{A, B, C \\}\\). Compare these probabilities to the prior probabilities (.4, .3, .3)."
  },
  {
    "objectID": "hw/hw01.html#exercise-4",
    "href": "hw/hw01.html#exercise-4",
    "title": "Homework 1",
    "section": "Exercise 4",
    "text": "Exercise 4\nLet \\(Y_1, \\ldots Y_n\\) be binary random variables that are conditionally independent given a value of a parameter \\(\\theta\\), so that \\(Pr(Y_i = 1 | \\theta) = \\theta = 1 - Pr(Y_i = 0 | \\theta)\\).\n\nLet \\(y_1, \\ldots y_n\\) be a binary sequence so that \\(y_i \\in \\{0, 1 \\}\\), for each \\(i = 1, \\ldots, n\\). Using the rules of probability, derive a formula for \\(Pr(Y_1 = y_1, \\ldots, Y_n = y_n | \\theta)\\) as a function of \\(y_1, \\ldots y_n\\) and \\(\\theta\\). Simplify as much as possible.\nLet \\(X = \\sum_{i=1}^n Y_i\\), what is the probability \\(p(X = x | \\theta)\\) for any \\(x \\in \\{0, 1, \\ldots n\\}\\)? Explain (in 1-2 sentences) why \\(n \\choose x\\) is in the expression.\nCompute and compare, using the definition of expectation and variance: \\(E(Y_i|\\theta)\\), \\(Var(Y_i|\\theta)\\) to \\(E(X|\\theta)\\) and \\(Var(X|\\theta)\\).\nUsing calculus or otherwise, for a given value of \\(x\\), find “\\(\\theta_{MLE}\\)”, the value of \\(\\theta\\) that maximizes \\(Pr(X = x|\\theta)\\). This value is called the “maximum likelihood estimator” or MLE, of \\(\\theta\\)."
  },
  {
    "objectID": "hw/extra-credit.html",
    "href": "hw/extra-credit.html",
    "title": "Extra credit",
    "section": "",
    "text": "Because this is extra credit, the teaching team will not assist solving this problem during office hours. Additionally, extra credit may not be turned in late."
  },
  {
    "objectID": "hw/extra-credit.html#exercise",
    "href": "hw/extra-credit.html#exercise",
    "title": "Extra credit",
    "section": "Exercise",
    "text": "Exercise\n3.14 from Hoff.\nAdditionally, complete part (e): discuss the resulting posterior based on your findings from parts (a) through (d) in a couple of sentences."
  },
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "STA 360: Data sets",
    "section": "",
    "text": "ALPHA_SAMPLES.RData\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nBETA-model-avg.txt\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nBETA_SAMPLES.RData\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nBostonCeltics_Assists_23-24_season.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nBostonCeltics_PlayerStats_2023-2024_Games.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nE_coli.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nMarsWaterBetaHalf.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nMarsWaterH0.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nMarsWaterUniform.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nMartianLR.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nPima.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nSIGMA2-model-avg.txt\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nZ-model-avg.txt\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nazdiabetes-test.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nazdiabetes-train.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nazdiabetes.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nbach30.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nbanana_distribution.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nbass.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nbird-counts.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nbluecrab.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nciphertext.txt\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\ndivorce.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nglucose.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\ngss.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nhares-lynx.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nhw-digits-test.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nhw-digits-train.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nmathScores.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nnobach30.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\norangecrab.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool1.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool2.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool3.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool4.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool5.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool6.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool7.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nschool8.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nsimulatedXY.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nspam-train-fit.rds\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nspam.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nstent365.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\ntrans-prob-mat.RData\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\ntrans-prob-mat.rds\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nyX.diabetes.test\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nyX.diabetes.train\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nyXsparrow.csv\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\n\n\n\n\n\nyXspectroscopy.rds\n\n\n1/6/25, 11:08:15 AM\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chapterSummaries.html",
    "href": "chapterSummaries.html",
    "title": "Chapter summaries",
    "section": "",
    "text": "Axioms of probability\nFor all sets \\(F\\), \\(G\\) and \\(H\\),\n\n\\(0 = Pr(\\neg H | H) \\leq Pr(F | H) \\leq Pr(H | H) = 1\\)\n\\(Pr(F \\cup G | H) = Pr(F|H) + Pr(G|H) \\text{ if } F \\cap G = \\emptyset\\)\n\\(Pr(F \\cap G | H) = Pr(G | H) Pr(F | G \\cap H)\\)\n\nPartitions and probability\nSuppose \\(\\{ H_1, \\ldots, H_K\\}\\) is a partition of \\(\\mathcal{H}\\), \\(Pr(\\mathcal{H}) = 1\\) and \\(E\\) is some specific event. From the axioms of probability one may prove:\n\nRule of total probability:\n\n\\[\\begin{equation}\n\\sum_{k = 1}^K Pr(H_k) = 1\n\\end{equation}\\]\n\nRule of marginal probability:\n\n\\[\\begin{equation}\n\\begin{aligned}\nPr(E) &= \\sum_{k = 1}^K Pr(E \\cap H_k)\\\\ &= \\sum_{k = 1}^K Pr(E | H_k) Pr(H_k)\n\\end{aligned}\n\\end{equation}\\]\n\nBayes’ theorem:\n\n\\[\\begin{equation}\nPr(H_j | E) = \\frac{Pr(E|H_j) Pr(H_j)}{Pr(E)}\n\\end{equation}\\]\nNote it is often useful to replace the denominator, \\(Pr(E)\\), using the rule of marginal probability.\nIndependence\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(Pr(F \\cap G |H) = Pr(F|H) Pr(G|H)\\).\n\n\n\nLaw of total expectation \\(E(X) = E(E(X|Y))\\)\nLaw of total variance \\(Var(X) = E(Var(X|Y)) + Var(E(X|Y))\\)\n\n\n\n\n\n\n\nNote\n\n\n\nRemember we can always add conditioning statements e.g.\n\nLaw of total expectation \\(E(X|Z) = E(E(X|Y)|Z)\\)\nLaw of total variance \\(Var(X|Z) = E(Var(X|Y)|Z) + Var(E(X|Y)|Z)\\)"
  },
  {
    "objectID": "chapterSummaries.html#chapter-2",
    "href": "chapterSummaries.html#chapter-2",
    "title": "Chapter summaries",
    "section": "",
    "text": "Axioms of probability\nFor all sets \\(F\\), \\(G\\) and \\(H\\),\n\n\\(0 = Pr(\\neg H | H) \\leq Pr(F | H) \\leq Pr(H | H) = 1\\)\n\\(Pr(F \\cup G | H) = Pr(F|H) + Pr(G|H) \\text{ if } F \\cap G = \\emptyset\\)\n\\(Pr(F \\cap G | H) = Pr(G | H) Pr(F | G \\cap H)\\)\n\nPartitions and probability\nSuppose \\(\\{ H_1, \\ldots, H_K\\}\\) is a partition of \\(\\mathcal{H}\\), \\(Pr(\\mathcal{H}) = 1\\) and \\(E\\) is some specific event. From the axioms of probability one may prove:\n\nRule of total probability:\n\n\\[\\begin{equation}\n\\sum_{k = 1}^K Pr(H_k) = 1\n\\end{equation}\\]\n\nRule of marginal probability:\n\n\\[\\begin{equation}\n\\begin{aligned}\nPr(E) &= \\sum_{k = 1}^K Pr(E \\cap H_k)\\\\ &= \\sum_{k = 1}^K Pr(E | H_k) Pr(H_k)\n\\end{aligned}\n\\end{equation}\\]\n\nBayes’ theorem:\n\n\\[\\begin{equation}\nPr(H_j | E) = \\frac{Pr(E|H_j) Pr(H_j)}{Pr(E)}\n\\end{equation}\\]\nNote it is often useful to replace the denominator, \\(Pr(E)\\), using the rule of marginal probability.\nIndependence\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(Pr(F \\cap G |H) = Pr(F|H) Pr(G|H)\\).\n\n\n\nLaw of total expectation \\(E(X) = E(E(X|Y))\\)\nLaw of total variance \\(Var(X) = E(Var(X|Y)) + Var(E(X|Y))\\)\n\n\n\n\n\n\n\nNote\n\n\n\nRemember we can always add conditioning statements e.g.\n\nLaw of total expectation \\(E(X|Z) = E(E(X|Y)|Z)\\)\nLaw of total variance \\(Var(X|Z) = E(Var(X|Y)|Z) + Var(E(X|Y)|Z)\\)"
  },
  {
    "objectID": "chapterSummaries.html#chapter-3",
    "href": "chapterSummaries.html#chapter-3",
    "title": "Chapter summaries",
    "section": "Chapter 3",
    "text": "Chapter 3\n\nDefinitions and conjugacy\n\nBe able to define likelihood, prior, posterior, normalizing constant\n\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\n\nExamples of conjugate models: beta-binomial, gamma-Poisson.\n\n\n\nReliability\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) &lt; \\theta &lt; u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) &gt; p(\\theta_b | Y = y)\\)\n\n\n\n\n\nExponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi | n_0, t_0) \\propto c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\). Note: the conjugate prior is given over \\(\\phi\\) and we’d have to transform back if we care about \\(p(\\theta)\\)."
  },
  {
    "objectID": "chapterSummaries.html#chapter-4",
    "href": "chapterSummaries.html#chapter-4",
    "title": "Chapter summaries",
    "section": "Chapter 4",
    "text": "Chapter 4\n\nPredictive distributions\nThe posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta\n\\]\nwhen \\(Y | \\theta\\) conditionally iid.\nThe prior predictive distribution,\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta) p(\\theta)d\\theta.\n\\]\nNotice both the posterior and prior predictive distributions are represented as integrals. Integrals are expectations. This means we can use Monte Carlo integration to approximate.\nTo approximate the posterior predictive distribution:\n\nsample from the posterior of theta, \\(p(\\theta|y_1,\\ldots y_n)\\)\nsample from data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\nTo approximate the prior predictive distribution:\n\nsample from the prior of theta, \\(p(\\theta)\\)\nsample from the data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\n\n\nMonte Carlo error\nSince Monte Carlo approximation can be viewed as a sample mean approximating an expected value, CLT applies.\nMore specifically, if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\nand Monte Carlo estimates converge at a rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\n\n\nThe sampling view\nIf we have a posterior \\(p(\\theta | y_1, \\ldots y_n)\\) that we can sample from and we want some summary of the posterior… e.g. we want\n\n\\(p(\\theta &lt; a)\\)\nquantiles of the posterior , or\nthe posterior of some transform \\(f(\\theta)\\),\n\nthen we can simply sample from the posterior to obtain an empirical approximation of the posterior and then report the empirical quantity of interest. This is also called Monte Carlo approximation.\nThe procedure can be written:\n\nsample from the posterior \\(p(\\theta |y_1, \\ldots y_n)\\) some large number of times and then\ncompute the quantity of interest"
  },
  {
    "objectID": "chapterSummaries.html#chapter-5",
    "href": "chapterSummaries.html#chapter-5",
    "title": "Chapter summaries",
    "section": "Chapter 5",
    "text": "Chapter 5\n\nConjugate prior to the normal model\nIf\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\] then\n\\[\n\\begin{aligned}\n\\theta | \\sigma^2, y_1,\\ldots y_n &\\sim \\text{normal}\\\\\n\\sigma^2 | y_1,\\ldots y_n &\\sim \\text{gamma}\n\\end{aligned}\n\\]\nand since\n\\[\n\\begin{aligned}\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) &= p(\\theta |\\sigma^2, y_1,\\ldots y_n) p(\\sigma^2 | y_1,\\ldots y_n),\n\\end{aligned}\n\\] we can sample directly from the joint posterior by sampling from \\(p(\\sigma^2 | y_1,\\ldots y_n)\\) and then from \\(p(\\theta | \\sigma^2, y_1,\\ldots y_n)\\).\n\n\nEstimators\nBe able to define and compute the bias, variance and MSE of an estimator.\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\] where \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "chapterSummaries.html#chapter-6",
    "href": "chapterSummaries.html#chapter-6",
    "title": "Chapter summaries",
    "section": "Chapter 6",
    "text": "Chapter 6\n\nGibbs sampling procedure\nHow can we look at a joint posterior, e.g. \\(p(\\theta_1,\\ldots \\theta_p | y_1,\\ldots y_n)\\), if we have non-conjugate priors?\nWell if we do have the full conditionals, \\(p(\\theta_i | \\theta_{-i}, y_1,\\ldots y_n)\\) then we can sample from the joint posterior via Gibbs sampling. Note: \\(\\theta_{-i}\\) denotes \\(\\{\\theta\\} \\backslash \\theta_i\\), i.e. the set of all theta except \\(\\theta_i\\).\nGibbs sampling proceeds:\nPick a starting point \\(\\theta_2^{(0)}, \\ldots \\theta_p^{(0)}\\), then for s in 1:S,\n\nSample \\(\\theta_1^{(s)} \\sim p(\\theta_1 | \\theta_{2}^{(s-1)}, \\ldots, \\theta_{p}^{(s-1)}, y_1,\\ldots y_n)\\)\nSample \\(\\theta_2^{(s)} \\sim p(\\theta_2 | \\theta_{1}^{(s)}, \\theta_{3}^{(s-1)} \\ldots, \\theta_{p}^{(s-1)}, y_1,\\ldots y_n)\\)\n\n\\(\\vdots\\)\n\nSample \\(\\theta_p^{(s)} \\sim p(\\theta_2 | \\theta_{1}^{(s)}, \\ldots, \\theta_{p-1}^{(s)}, y_1,\\ldots y_n)\\)\n\nIt follows that we have a sequence of dependent samples from the joint posterior. The sequence \\(\\{\\theta^{(s)}\\}\\) is called a Markov chain.\n\\[\n\\frac{1}{S} \\sum_{s=1}^S g(\\theta^{(s)})  \\rightarrow E[g(\\theta)]\n\\] Gibbs sampling is a form of Markov chain Monte Carlo (MCMC).\n\n\nMCMC diagnostics\nEffective sample size (ESS), autocorrelation, and traceplots are diagnostic tools we use to assess how well our Markov chain approximates the posterior. You should be able to define these terms and interpret their output. See this lecture for details.\nSpecifically, ESS is the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. Typically, ESS is a criterion used to figure out how many samples to generate, i.e. how long to run your Markov chain."
  },
  {
    "objectID": "chapterSummaries.html#chapter-7",
    "href": "chapterSummaries.html#chapter-7",
    "title": "Chapter summaries",
    "section": "Chapter 7",
    "text": "Chapter 7\n\nDensity\nWe say a \\(p\\) dimensional vector \\(\\boldsymbol{Y}\\) has a multivariate normal distribution if its sampling density is given by\n\\[\np(\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{\n-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}- \\boldsymbol{\\theta})\n\\}\n\\]\nwhere\n\\[\n\\boldsymbol{y}=  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\\\\\n   \\vdots\\\\\n   y_p\n  \\end{array} } \\right]\n  ~~~\n   \\boldsymbol{\\theta}= \\left[ {\\begin{array}{cc}\n   \\theta_1 \\\\\n   \\theta_2\\\\\n   \\vdots\\\\\n   \\theta_p\n  \\end{array} } \\right]\n  ~~~\n  \\Sigma =\n  \\left[ {\\begin{array}{cc}\n   \\sigma_1^2 & \\sigma_{12}& \\ldots & \\sigma_{1p}\\\\\n   \\sigma_{12} & \\sigma_2^2 &\\ldots & \\sigma_{2p}\\\\\n   \\vdots & \\vdots & & \\vdots\\\\\n   \\sigma_{1p} & \\ldots & \\ldots & \\sigma_p^2\n  \\end{array} } \\right].\n\\]\n\nKey facts\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma &gt; 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] =  \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\n\n\nsemi-conjugate prior for \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN\n\\]\n\n\nsemiconjugate prior for \\(\\Sigma\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\Sigma &\\sim \\text{inverse-Wishart}(\\nu_0, S_0^{-1}),\n\\end{aligned}\n\\]\nthen\n\\[\n\\Sigma | \\boldsymbol{y}, \\boldsymbol{\\theta}\\sim \\text{inverse-Wishart}\n\\]\n\n\nWishart as sum of squares matrix\nFor a given \\(\\nu_0\\) and and a \\(p \\times p\\) covariance matrix \\(S_0\\), we can generate samples from a MVN by the following procedure:\n\nsample \\(\\boldsymbol{z}_1, \\ldots \\boldsymbol{z}_{\\nu_0} \\sim \\text{ i.i.d. } MVN(\\mathbf{0}, S_0)\\)\ncalculate \\(\\mathbf{Z}^T \\mathbf{Z} = \\sum_{i =1}^{\\nu_0} \\boldsymbol{z}_i \\boldsymbol{z}_i^T\\).\n\nIt follows that \\(\\mathbf{Z}^T \\mathbf{Z} &gt; 0\\) and symmetric. \\(E[\\mathbf{Z}^T \\mathbf{Z}] = \\nu_0 S_0\\)"
  },
  {
    "objectID": "chapterSummaries.html#chapter-8",
    "href": "chapterSummaries.html#chapter-8",
    "title": "Chapter summaries",
    "section": "Chapter 8",
    "text": "Chapter 8\nBe able to write a hierarchical model. Review and be able to explain all aspects of the example here."
  },
  {
    "objectID": "hw/hw00.html",
    "href": "hw/hw00.html",
    "title": "Homework 0",
    "section": "",
    "text": "This math assessment is meant to help both you and the instructor identify gaps in background knowledge both at the class and individual level."
  },
  {
    "objectID": "hw/hw00.html#exercise-1",
    "href": "hw/hw00.html#exercise-1",
    "title": "Homework 0",
    "section": "Exercise 1",
    "text": "Exercise 1\nSimplify\n\\[\n\\log(e^{a_1} e^{a_2} e^{a_3} \\cdots e^{a_n})\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-2",
    "href": "hw/hw00.html#exercise-2",
    "title": "Homework 0",
    "section": "Exercise 2",
    "text": "Exercise 2\nFind the derivative.\n\\[\n\\frac{d}{dx} \\left( \\frac{x}{\\log x} \\right)\n\\] ## Exercise 3\nWhat is the ordinary least squares estimator of \\(\\beta\\) (1-dimensional) in the linear regression \\(y = x \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-4",
    "href": "hw/hw00.html#exercise-4",
    "title": "Homework 0",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat is the ordinary least squares estimator of \\(\\beta\\) (p-dimensional) in the linear regression \\(y = X \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-5",
    "href": "hw/hw00.html#exercise-5",
    "title": "Homework 0",
    "section": "Exercise 5",
    "text": "Exercise 5\nIn linear regression with p-dimensional β, what is the interpretation of the estimate for the jth coefficient?"
  },
  {
    "objectID": "hw/hw00.html#exercise-6",
    "href": "hw/hw00.html#exercise-6",
    "title": "Homework 0",
    "section": "Exercise 6",
    "text": "Exercise 6\nCompute the integral,\n\\[\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-7",
    "href": "hw/hw00.html#exercise-7",
    "title": "Homework 0",
    "section": "Exercise 7",
    "text": "Exercise 7\n\\(X \\sim N(\\mu, \\sigma^2)\\) reads “X is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nLet\n\\[\n\\begin{aligned}\nX &\\sim N(0, 1),\\\\\nY &\\sim N(3, 2),\\\\\nZ &= X + Y\n\\end{aligned}\n\\] What is the distribution of \\(Z\\)? What is \\(\\mathbb{E}[Z]\\) and \\(Var(Z)\\)?"
  },
  {
    "objectID": "hw/hw00.html#exercise-8",
    "href": "hw/hw00.html#exercise-8",
    "title": "Homework 0",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn your own words, the “support” of random variable is…"
  },
  {
    "objectID": "hw/hw00.html#exercise-9",
    "href": "hw/hw00.html#exercise-9",
    "title": "Homework 0",
    "section": "Exercise 9",
    "text": "Exercise 9\nTRUE/FALSE: The product of two uniform[0, 1] random variables is uniform[0, 1]."
  },
  {
    "objectID": "hw/hw00.html#exercise-10",
    "href": "hw/hw00.html#exercise-10",
    "title": "Homework 0",
    "section": "Exercise 10",
    "text": "Exercise 10\n\\(X_1, \\ldots X_n\\) i.i.d. with pdf \\(p(x)\\). For all \\(i\\), \\(E(X_i) = \\mu\\) and \\(Var(X_i) = \\sigma^2 &lt; \\infty\\).\nCompare \\(\\text{Var}(\\frac{1}{n}\\sum X_i)\\) to \\(\\text{Var}(X_1)\\). Which is smaller?"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "Code\n\nRStudio containers\n\nResources\n\nCanvas website\n\nFind announcements and grades here.\nSolutions uploaded here under “Files” tab on the left hand side.\nRecorded zoom lectures uploaded here under “Pages” tab on the left hand side.\n\nGradescope\n\nTextbook\n\nA First Course in Bayesian Statistical Methods by Peter Hoff\nErrata to the textbook"
  },
  {
    "objectID": "notes/exam-notes.html",
    "href": "notes/exam-notes.html",
    "title": "Exam notes",
    "section": "",
    "text": "A random variable \\(X \\in \\mathbb{R}\\) has a \\(N(\\theta, \\sigma^2)\\) distribution if \\(\\sigma^2 &gt; 0\\) and\n\\(p(x | \\theta, \\sigma^2) = (2 \\pi \\sigma^2)^{-\\frac{1}{2}} e^{-\\frac{1}{2\\sigma^2}(x - \\theta)^2} \\ \\ \\ \\text{ for } -\\infty &lt; x &lt; \\infty.\\)\n\n\n\nA random vector \\(X \\in \\mathbb{R}^p\\) has a \\(MVN(\\theta, \\Sigma)\\) distribution if \\(\\Sigma &gt; 0\\) and\n\\(p(x| \\theta, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{ -\\frac{1}{2}(x - \\theta)^T \\Sigma^{-1} (x - \\theta) \\}\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has a gamma(a,b) distribution if \\(a &gt; 0, b &gt; 0\\) and\n\\(p(x |a,b) = \\frac{b^a}{\\Gamma(a)} x^{a - 1} e^{-bx} \\ \\ \\ \\text{ for } x &gt; 0.\\)\n\\(E[X | a, b] = a/b\\), \\(Var[X | a,b] = a / b^2\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if 1/X has a gamma(a,b) distribution. If \\(X\\) is inverse-gamma(a,b) then the density of X is\n\\(p(x|a,b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1} e^{-b/x} \\ \\ \\ \\text{ for } x &gt; 0.\\)\n\\(E[X|a,b] = \\frac{b}{a-1}\\) if \\(a&gt;=1\\), \\(\\infty\\) if \\(0&lt;a&lt;1\\)\n\\(Var[X|a,b] = \\frac{b^2}{(a-1)^2(a-2)}\\) if \\(a\\geq2\\), \\(\\infty\\) if \\(0&lt;a&lt;2\\)\n\n\n\nA random \\(p \\times p\\) matrix \\(\\Sigma\\) has an inverse-Wishart distribution if \\(p(\\Sigma | \\nu_0, S_0^{-1}) \\propto |\\Sigma|^{-(\\nu_0 + p + 1)/2} \\times \\exp \\{ -\\frac{1}{2}tr(S_0 \\Sigma^{-1})\\}\\).\n\nthe support is \\(\\Sigma &gt; 0\\) and \\(\\Sigma\\) symmetric \\(p \\times p\\) matrix. \\(\\nu_0 \\in \\mathbb{N}^+\\) and \\(\\nu_0 \\geq p\\). \\(S_0\\) is a \\(p \\times p\\) symmetric positive definite matrix.\n\\(E[\\Sigma^{-1}] = \\nu_0 S_0^{-1}\\) and \\(E[\\Sigma] = \\frac{1}{\\nu_0 - p - 1} S_0\\).\n\n\n\n\nA random variable \\(X \\in \\{0, 1, \\ldots, n\\}\\) has a binomial\\((n, \\theta)\\) distribution if \\(\\theta \\in [0, 1]\\) and\n\\(p(X = x| \\theta, n) = {n \\choose x} \\theta^x (1- \\theta)^{n-x} \\ \\ \\ \\text{ for } x\\in \\{0, 1, \\ldots, n \\}\\)\n\\(E[X|\\theta] = n\\theta\\), \\(Var[X|\\theta] = n\\theta(1-\\theta)\\)\n\n\n\nA random variable \\(X \\in [0, 1]\\) has a beta(a,b) distribution if \\(a &gt; 0, b &gt; 0\\) and\n\\(p(x|a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} x^{a-1} (1-x)^{b-1} \\ \\ \\ \\text{ for } 0 \\leq x \\leq 1.\\)\n\\(E[X|a,b] = \\frac{a}{a + b}\\), \\(Var[X|a,b] = \\frac{ab}{(a + b + 1)(a + b)^2}\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, 2, \\ldots \\}\\) has a Poisson(\\(\\theta\\)) distribution if \\(\\theta &gt; 0\\) and\n\\(p(X = x | \\theta) = \\theta^x \\frac{e^{-\\theta}}{x!} \\ \\ \\ \\text{ for } x \\in \\{0, 1, 2, \\ldots\\}\\)\n\\(E[X|\\theta] = \\theta\\), \\(Var[X|\\theta] = \\theta\\)\n\n\n\nA random variable \\(X \\in [0, \\infty)\\) has a exponential(\\(\\theta\\)) distribution if \\(\\theta &gt;0\\) and\n\\(p(x | \\theta) = \\theta e^{-\\theta x}\\)\n\\(E[X|\\theta] = \\frac{1}{\\theta}\\), \\(Var[X|\\theta] = \\frac{1}{\\theta^2}\\)"
  },
  {
    "objectID": "notes/exam-notes.html#useful-distributions",
    "href": "notes/exam-notes.html#useful-distributions",
    "title": "Exam notes",
    "section": "",
    "text": "A random variable \\(X \\in \\mathbb{R}\\) has a \\(N(\\theta, \\sigma^2)\\) distribution if \\(\\sigma^2 &gt; 0\\) and\n\\(p(x | \\theta, \\sigma^2) = (2 \\pi \\sigma^2)^{-\\frac{1}{2}} e^{-\\frac{1}{2\\sigma^2}(x - \\theta)^2} \\ \\ \\ \\text{ for } -\\infty &lt; x &lt; \\infty.\\)\n\n\n\nA random vector \\(X \\in \\mathbb{R}^p\\) has a \\(MVN(\\theta, \\Sigma)\\) distribution if \\(\\Sigma &gt; 0\\) and\n\\(p(x| \\theta, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{ -\\frac{1}{2}(x - \\theta)^T \\Sigma^{-1} (x - \\theta) \\}\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has a gamma(a,b) distribution if \\(a &gt; 0, b &gt; 0\\) and\n\\(p(x |a,b) = \\frac{b^a}{\\Gamma(a)} x^{a - 1} e^{-bx} \\ \\ \\ \\text{ for } x &gt; 0.\\)\n\\(E[X | a, b] = a/b\\), \\(Var[X | a,b] = a / b^2\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if 1/X has a gamma(a,b) distribution. If \\(X\\) is inverse-gamma(a,b) then the density of X is\n\\(p(x|a,b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1} e^{-b/x} \\ \\ \\ \\text{ for } x &gt; 0.\\)\n\\(E[X|a,b] = \\frac{b}{a-1}\\) if \\(a&gt;=1\\), \\(\\infty\\) if \\(0&lt;a&lt;1\\)\n\\(Var[X|a,b] = \\frac{b^2}{(a-1)^2(a-2)}\\) if \\(a\\geq2\\), \\(\\infty\\) if \\(0&lt;a&lt;2\\)\n\n\n\nA random \\(p \\times p\\) matrix \\(\\Sigma\\) has an inverse-Wishart distribution if \\(p(\\Sigma | \\nu_0, S_0^{-1}) \\propto |\\Sigma|^{-(\\nu_0 + p + 1)/2} \\times \\exp \\{ -\\frac{1}{2}tr(S_0 \\Sigma^{-1})\\}\\).\n\nthe support is \\(\\Sigma &gt; 0\\) and \\(\\Sigma\\) symmetric \\(p \\times p\\) matrix. \\(\\nu_0 \\in \\mathbb{N}^+\\) and \\(\\nu_0 \\geq p\\). \\(S_0\\) is a \\(p \\times p\\) symmetric positive definite matrix.\n\\(E[\\Sigma^{-1}] = \\nu_0 S_0^{-1}\\) and \\(E[\\Sigma] = \\frac{1}{\\nu_0 - p - 1} S_0\\).\n\n\n\n\nA random variable \\(X \\in \\{0, 1, \\ldots, n\\}\\) has a binomial\\((n, \\theta)\\) distribution if \\(\\theta \\in [0, 1]\\) and\n\\(p(X = x| \\theta, n) = {n \\choose x} \\theta^x (1- \\theta)^{n-x} \\ \\ \\ \\text{ for } x\\in \\{0, 1, \\ldots, n \\}\\)\n\\(E[X|\\theta] = n\\theta\\), \\(Var[X|\\theta] = n\\theta(1-\\theta)\\)\n\n\n\nA random variable \\(X \\in [0, 1]\\) has a beta(a,b) distribution if \\(a &gt; 0, b &gt; 0\\) and\n\\(p(x|a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} x^{a-1} (1-x)^{b-1} \\ \\ \\ \\text{ for } 0 \\leq x \\leq 1.\\)\n\\(E[X|a,b] = \\frac{a}{a + b}\\), \\(Var[X|a,b] = \\frac{ab}{(a + b + 1)(a + b)^2}\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, 2, \\ldots \\}\\) has a Poisson(\\(\\theta\\)) distribution if \\(\\theta &gt; 0\\) and\n\\(p(X = x | \\theta) = \\theta^x \\frac{e^{-\\theta}}{x!} \\ \\ \\ \\text{ for } x \\in \\{0, 1, 2, \\ldots\\}\\)\n\\(E[X|\\theta] = \\theta\\), \\(Var[X|\\theta] = \\theta\\)\n\n\n\nA random variable \\(X \\in [0, \\infty)\\) has a exponential(\\(\\theta\\)) distribution if \\(\\theta &gt;0\\) and\n\\(p(x | \\theta) = \\theta e^{-\\theta x}\\)\n\\(E[X|\\theta] = \\frac{1}{\\theta}\\), \\(Var[X|\\theta] = \\frac{1}{\\theta^2}\\)"
  },
  {
    "objectID": "notes/lec00-hmc.html",
    "href": "notes/lec00-hmc.html",
    "title": "Hamiltonian Monte Carlo",
    "section": "",
    "text": "Often we are interested in some summary (usually an integral) of the target distribution. To evaluate the quantity of interest, we need samples from the typical set."
  },
  {
    "objectID": "notes/practiceFinal.html",
    "href": "notes/practiceFinal.html",
    "title": "Practice for final exam",
    "section": "",
    "text": "Find the practice exam on Canvas under “Files” &gt; “Exams” &gt; final-exam-fall2023.pdf\nYou can work on the practice exam with others in class.\nThe final exam will cover all content through November 21st. In other words, Hamiltonian Monte Carlo and Bayesian model averaging are the only two lecture topics that cannot be on the final exam."
  },
  {
    "objectID": "quizzes.html",
    "href": "quizzes.html",
    "title": "STA 360: Quizzes",
    "section": "",
    "text": "Quiz 7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonus quiz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readings/readHMC.html",
    "href": "readings/readHMC.html",
    "title": "Preparatory reading: HMC",
    "section": "",
    "text": "Michael Betancourt’s conceptual intro\nRadford Neal’s comprehensive book chapter"
  },
  {
    "objectID": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "href": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "title": "Full conditionals",
    "section": "Full conditionals are proportional to the joint",
    "text": "Full conditionals are proportional to the joint\nSuppose \\(X, Y, Z, \\theta, \\phi\\) are random variables,\n\\[\n\\begin{aligned}\np(x| y, z, \\theta, \\phi) &=\n\\frac{p(x, y, z, \\theta, \\phi)}{\\int p(x,y,z,\\theta, \\phi) dx}\\\\\n&\\propto_x p(x| y, z, \\theta, \\phi)\n\\end{aligned}\n\\]\nSimilarly, each full conditional is proportional to the joint distribution.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "slides/lab7-exam2-prep.html#exercise-1",
    "href": "slides/lab7-exam2-prep.html#exercise-1",
    "title": "Practice",
    "section": "Exercise 1",
    "text": "Exercise 1\n\\[\n\\begin{aligned}\nY_1, \\ldots, Y_n &\\sim \\text{ i.i.d. binary}(\\theta)\\\\\n\\theta &\\sim \\text{beta}(a, b)\n\\end{aligned}\n\\]\n\nCompute \\(\\hat{\\theta}_{MLE}\\)\nCompute \\(\\hat{\\theta}_{B} = E[\\theta | y_1,\\ldots y_n]\\).\nCompare \\(MSE(\\hat{\\theta}_{MLE})\\) to \\(MSE(\\hat{\\theta}_{B})\\)). Under what conditions is the MSE of \\(\\hat{\\theta}_B\\) smaller?"
  },
  {
    "objectID": "slides/lab7-exam2-prep.html#exercise-2",
    "href": "slides/lab7-exam2-prep.html#exercise-2",
    "title": "Practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nConsider a single observation \\((y_1, y_2)\\) drawn from a bivariate normal distribution with mean \\((\\theta_1, \\theta_2)\\) and fixed, known \\(2 \\times 2\\) covariance matrix \\(\\Sigma = \\left[ {\\begin{array}{cc}\n   1 & .5 \\\\\n   .5 & 1\n  \\end{array} } \\right]\\). Consider a uniform prior on \\(\\theta = (\\theta_1, \\theta_2)\\) : \\(p(\\theta_1, \\theta_2) \\propto 1\\).\n(a.) Derive the joint posterior for \\(\\theta_1, \\theta_2 | y_1, y_2, \\Sigma\\). Describe a direct sampler for this distribution.\n(b.) Write down full conditionals \\(p(\\theta_1 | \\theta_2, y_1, y_2, \\Sigma)\\) and \\(p(\\theta_2 | \\theta_1, y_1, y_2, \\Sigma)\\). Write pseudo-code to describe a Gibbs sampling procedure. Hint: you can use the result from HW6 Ex 3.\n(c.) Will the direct sampler from part (a) or the Gibbs sampler in part (b) have higher ESS? Why?\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "hw/hw02.html",
    "href": "hw/hw02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Important\n\n\n\nTurn in your code used to generate any results and/or plots"
  },
  {
    "objectID": "hw/hw02.html#exercise-1",
    "href": "hw/hw02.html#exercise-1",
    "title": "Homework 2",
    "section": "Exercise 1",
    "text": "Exercise 1\nCompute the following integrals using the kernel trick discussed in class.\n\n\\(\\int_{0}^{\\infty} \\sigma^{x-1} e^{-b \\sigma} d\\sigma\\)\n\\(\\int_{0}^1 \\alpha \\theta^{\\alpha} (1 - \\theta)^{\\beta - 1} d\\theta\\)\n\\(\\int_{-\\infty}^\\infty x e^{-(x-3)^2} dx\\)"
  },
  {
    "objectID": "hw/hw02.html#exercise-2",
    "href": "hw/hw02.html#exercise-2",
    "title": "Homework 2",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet \\(Y_1, Y_2 | \\theta\\) be i.i.d. binary(\\(\\theta\\)), so that \\(p(y_1, y_2 | \\theta) = \\theta ^{y_1 + y_2} (1- \\theta) ^{2 - y_1 - y_2}\\) and let \\(\\theta \\sim \\text{beta}(\\eta, \\eta)\\)\n\nCompute \\(E~Y_i\\) and \\(Var~Y_i\\) (the mean and variance of \\(Y_i\\) unconditional on \\(\\theta\\)) as a function of \\(\\eta\\)\nCompute \\(E~Y_1 Y_2\\), which is the same as \\(p(Y_1 = 1, Y_2 = 1)\\) unconditional on \\(\\theta\\). Hint: \\(Y_1\\) and \\(Y_2\\) are conditionally i.i.d., see law of total expectation.\nUsing the terms you have calculated above, make a graph of the correlation between \\(Y_1\\) and \\(Y_2\\) as a function of \\(\\eta\\).\nInterpreting \\(\\eta\\) as how confident you are that \\(\\theta\\) is near \\(\\frac{1}{2}\\), and interpreting \\(Cor(Y_1, Y_2)\\) as how much information \\(Y_1\\) and \\(Y_2\\) provide about each other, explain in words why the correlation changes as a function of \\(\\eta\\)."
  },
  {
    "objectID": "hw/hw02.html#exercise-3",
    "href": "hw/hw02.html#exercise-3",
    "title": "Homework 2",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(n\\) individuals volunteer to count birds in a forest. Let \\(Y_i\\) be the number of birds counted by individual \\(i\\), and let \\(x_i\\) be the number of hours spent in the forest by volunteer \\(i\\). We will model the data \\(Y_1, \\ldots Y_n\\) as being independent given \\(\\theta\\), but not identically distributed. Specifically, our model is that \\(Y_i | \\theta \\sim \\text{Pois}(\\theta x_i)\\), independently for \\(i = 1, \\ldots n\\).\n\nCompute \\(E~Y_i | \\theta\\) and explain what \\(\\theta\\) represents.\nWrite out a formula for the joint pdf \\(p(y_1, \\ldots y_n |\\theta)\\) and simplify as much as possible. Find the MLE, that is, the value of \\(\\theta\\) that maximizes \\(p(y_1, \\ldots y_n | \\theta)\\). Explain why it makes sense.\nLet \\(\\theta \\sim \\text{gamma}(a, b)\\). Write down the posterior \\(p(\\theta | y_1,\\ldots y_n)\\) and find a formula for the posterior mode of \\(\\theta\\). Compare to the MLE."
  },
  {
    "objectID": "hw/hw02.html#exercise-4",
    "href": "hw/hw02.html#exercise-4",
    "title": "Homework 2",
    "section": "Exercise 4",
    "text": "Exercise 4\nData from the study described in exercise 3 can be downloaded from the course website using the code provided below.\n\nreadr::read_csv(\"https://sta602-sp25.github.io/data/bird-counts.csv\")\n\nIn this problem, we will examine the posterior distribution of \\(\\theta\\) given these data, under a prior distribution for \\(\\theta\\) having density of the form \\(p(\\theta) = c \\theta^{a-1} e^{-b\\theta}\\), where \\(c\\) is a constant that depends on \\(a\\) and \\(b\\) but not \\(\\theta\\). For this problem, we will set \\(a = 2\\) and \\(b = 1/5\\).\n\nMake a plot of \\(p(\\theta)\\) for \\(\\theta \\in (0, 50)\\) as follows: Compute \\(\\theta^{a -1} e^{-b\\theta}\\) on an evenly-spaced grid of 1000 \\(\\theta\\)-values from 0 to 50. Put the results of the computation into a vector of length 1000, then divide the vector by its sum. This vector is a discrete pdf that approximates the continuous density \\(p(\\theta)\\).\nCompute the prior expectation \\(E \\theta\\) using this discrete approximation.\nThe posterior density of \\(\\theta\\) may be expressed as \\(p(\\theta | y_1, \\ldots y_n) = \\tilde{c} p(\\theta) p(y_1, \\ldots y_n | \\theta)\\), where \\(\\tilde{c}\\) does not depend on \\(\\theta\\). As in part (a), make a discrete approximation to \\(p(\\theta | y)\\), and plot the results along with \\(p(\\theta)\\) and discuss the change from prior to posterior density. Also compare the prior and posterior expectations.\n\nHint: \\(p(\\theta | y_1,\\ldots y_n)\\) is the kernel of a well-known density. You can use a built in R function to help you create a discrete approximation to \\(p(\\theta | y_1,\\ldots y_n)\\)."
  },
  {
    "objectID": "hw/hw06.html",
    "href": "hw/hw06.html",
    "title": "Homework 6",
    "section": "",
    "text": "6.2 from Hoff. Note the typo: \\(1/\\sigma_j^2\\) is gamma, not \\(1/\\sigma_j\\). Use the code below to load the data.\n\nglucose = readr::read_csv(\"https://sta602-sp25.github.io/data/glucose.csv\")"
  },
  {
    "objectID": "hw/hw06.html#exercise-1",
    "href": "hw/hw06.html#exercise-1",
    "title": "Homework 6",
    "section": "",
    "text": "6.2 from Hoff. Note the typo: \\(1/\\sigma_j^2\\) is gamma, not \\(1/\\sigma_j\\). Use the code below to load the data.\n\nglucose = readr::read_csv(\"https://sta602-sp25.github.io/data/glucose.csv\")"
  },
  {
    "objectID": "hw/hw06.html#exercise-2",
    "href": "hw/hw06.html#exercise-2",
    "title": "Homework 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nRecall that if \\(W \\sim \\text{Wishart}_p(m, S)\\) then \\(W = \\sum_{i=1}^m z_i z_i^T\\) where \\(z_1, \\ldots, z_m \\sim \\text{i.i.d. } N_p(0, S)\\)\n\nShow that \\(E[W] = mS\\).\nShow that \\(W\\) is positive definite if \\(m \\geq p\\)."
  },
  {
    "objectID": "hw/hw06.html#exercise-3",
    "href": "hw/hw06.html#exercise-3",
    "title": "Homework 6",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(Y\\) is a random normal vector \\(Y \\sim N_p(\\theta, \\Sigma)\\). Let \\(Y_A\\) be the first \\(p_1\\) elements of \\(Y\\) and \\(Y_B\\) be the last \\(p_2 = p - p_1\\) elements, so that \\(Y = (Y_A, Y_B)\\). Similarly, write \\(\\theta = (\\theta_A, \\theta_B)\\). Finally, let\n\\[\n\\Sigma^{-} \\equiv \\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right]\n\\] and note that \\(\\Psi_{AB} = \\Psi_{BA}^T\\). Find the conditional distribution of \\(Y_B\\) given \\(Y_A\\) in terms of \\(\\theta_A\\), \\(\\theta_B\\) and components of \\(\\Psi\\). Try to interpret how \\(E[Y_B|Y_A]\\) differs from \\(E[Y_B]\\) and how \\(V[Y_B|Y_A]\\) differs from \\(V[Y_B]\\).\n\nIdentities for exercise 3\nSome of the following identities will be helpful for interpretation.\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "old-quizzes/quiz05-old.html",
    "href": "old-quizzes/quiz05-old.html",
    "title": "Quiz 5 (2023)",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nWhat is the purpose of Gibbs sampling?\n\n\nExercise 2\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(\\mathbf{x}^T \\Sigma \\mathbf{x}\\)?\n\n\nExercise 3\nLet \\(\\mathbf{y} =  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\n  \\end{array} } \\right]\\), \\(\\boldsymbol{\\theta} =  \\left[ {\\begin{array}{cc}\n   4 \\\\\n   8\n  \\end{array} } \\right]\\), \\(\\Sigma =  \\left[ {\\begin{array}{cc}\n   1 & .2 \\\\\n   .2 & 1.3\\\\\n  \\end{array} } \\right]\\).\nIf \\(\\mathbf{y} | \\boldsymbol{\\theta}, \\Sigma \\sim MVN(\\boldsymbol{\\theta}, \\Sigma)\\), then \\(y_1 \\sim N(a, b)\\). What is \\(a\\) and \\(b\\)?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "old-quizzes/quiz07-old.html",
    "href": "old-quizzes/quiz07-old.html",
    "title": "Quiz 7 (2023)",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nTRUE or FALSE: The Metropolis-Hastings algorithm is a generalization of both the Metropolis algorithm and the Gibbs sampler.\n\n\nExercise 2\nTRUE or FALSE: the Metropolis-Hastings algorithm requires symmetric proposal \\(J(\\theta^* | \\theta^{(s)})\\).\n\n\nExercise 3\nTRUE or FALSE: for any valid proposal distribution J, \\(J(\\theta^* | \\theta^{(1)}, \\ldots, \\theta^{(s)}) = J(\\theta^* | \\theta^{(s)})\\).\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#exercise",
    "href": "slides/lab9-MH-MCMC.html#exercise",
    "title": "MCMC Practice",
    "section": "Exercise",
    "text": "Exercise\nSuppose the target distribution we wish to sample from is given by probability mass function\n\\[\n\\pi(\\theta) = \\theta / w \\text{ for } \\theta \\in \\{1, 2, \\ldots 6\\}\n\\]\nin words, we wish to roll a die with probability \\(1/w\\) of landing on face 1, \\(2/w\\) of landing on face 2, etc.\n\nWrite a Metropolis algorithm to approximate the target distribution using a proposal \\(J(\\theta = j | \\theta^{(s)} = i) = 1/6\\) for all \\(j\\), i.e. propose a new state \\(j\\) uniformly. Run your Markov chain for \\(S=10000\\) states.\nThe Metropolis algorithm requires a symmetric proposal \\(J\\). Explain why this proposal is symmetric.\nPlot a histogram of the Markov chain samples. Does the plot match your intuition?\nCompare the estimated probabilities of each outcome to the truth (compute \\(w\\))."
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#metropolis-hastings-algorithm",
    "href": "slides/lab9-MH-MCMC.html#metropolis-hastings-algorithm",
    "title": "MCMC Practice",
    "section": "Metropolis-Hastings algorithm",
    "text": "Metropolis-Hastings algorithm\nLet \\(\\pi(\\theta)\\) be the target distribution. The Metropolis-Hastings algorithm proceeds:\n\nsample \\(\\theta^{*} \\sim J(\\theta | \\theta^{(s)})\\);\ncompute the acceptance ratio\n\n\\[\nr = \\frac{\\pi(\\theta^*)}{\\pi(\\theta^{(s)})} \\times\n\\frac{J(\\theta^{(s)}| \\theta^*)}{\nJ(\\theta^{*}| \\theta^{(s)})\n}\n\\]\n\nset \\(\\theta^{(s+1)}\\) to \\(\\theta^*\\) with probability \\(\\min(1, r)\\), otherwise set \\(\\theta^{(s+1)}\\) to \\(\\theta^{(s)}\\).\n\nImportant: We correct for asymmetry; the proposal distribution \\(J\\) need not be symmetric!"
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#exercise-1",
    "href": "slides/lab9-MH-MCMC.html#exercise-1",
    "title": "MCMC Practice",
    "section": "Exercise",
    "text": "Exercise\nMetropolis-Hastings lets us work with non-symmetric proposals. Re-write the algorithm of the previous exercise using the non-symmetric proposal \\(J(\\theta = j  | \\theta^{(s)} = i)\\) such that\n\\[\n\\theta  = \\begin{cases}\n1 & \\text{ with prob } & 0.05\\\\\n2 & \\text{ with prob } & 0.15\\\\\n3 & \\text{ with prob } & 0.2\\\\\n4 & \\text{ with prob } & 0.15\\\\\n5 & \\text{ with prob } & 0.15\\\\\n6 & \\text{ with prob } & 0.3\\\\\n\\end{cases}\n\\]\n\ncompare your results to that those of the previous exercise. In particular, compare the ESS of \\(\\theta\\) in each chain. Which do you prefer? How might you explain this difference in ESS?\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "hw/hw2023_06.html",
    "href": "hw/hw2023_06.html",
    "title": "Homework 6",
    "section": "",
    "text": "6.3 from Hoff. You can simulate from a constrained normal distribution with mean mean and standard deviation sd, constrained to lie in the interval \\((a,b)\\) using the following function:\n\nrcnorm&lt;-function(n, mean=0, sd=1, a=-Inf, b=Inf){\n  u = runif(n, pnorm((a - mean) / sd), pnorm((b - mean) / sd))\n  mean + (sd * qnorm(u))\n}\n\nNote that you can use this function to simulate a vector of constrained normal random variables, each with a potentially different mean, standard deviation, and constraints.\nTo load the data for this exercise, run the code below\n\ndivorce = readr::read_csv(\"https://sta360-fa23.github.io/data/divorce.csv\")"
  },
  {
    "objectID": "hw/hw2023_06.html#exercise-1",
    "href": "hw/hw2023_06.html#exercise-1",
    "title": "Homework 6",
    "section": "",
    "text": "6.3 from Hoff. You can simulate from a constrained normal distribution with mean mean and standard deviation sd, constrained to lie in the interval \\((a,b)\\) using the following function:\n\nrcnorm&lt;-function(n, mean=0, sd=1, a=-Inf, b=Inf){\n  u = runif(n, pnorm((a - mean) / sd), pnorm((b - mean) / sd))\n  mean + (sd * qnorm(u))\n}\n\nNote that you can use this function to simulate a vector of constrained normal random variables, each with a potentially different mean, standard deviation, and constraints.\nTo load the data for this exercise, run the code below\n\ndivorce = readr::read_csv(\"https://sta360-fa23.github.io/data/divorce.csv\")"
  },
  {
    "objectID": "hw/hw2023_06.html#exercise-2",
    "href": "hw/hw2023_06.html#exercise-2",
    "title": "Homework 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nShow that if \\(W \\sim \\text{Wishart}(m, S)\\) then \\(E[W] = mS\\)."
  },
  {
    "objectID": "hw/hw2023_06.html#exercise-3",
    "href": "hw/hw2023_06.html#exercise-3",
    "title": "Homework 6",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(Y\\) is a random normal vector \\(Y \\sim N_p(\\theta, \\Sigma)\\). Let \\(Y_A\\) be the first \\(p_1\\) elements of \\(Y\\) and \\(Y_B\\) be the last \\(p_2 = p - p_1\\) elements, so that \\(Y = (Y_A, Y_B)\\). Similarly, write \\(\\theta = (\\theta_A, \\theta_B)\\). Finally, let\n\\[\n\\Sigma^{-} \\equiv \\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right]\n\\] and note that \\(\\Psi_{AB} = \\Psi_{BA}^T\\). Find the conditional distribution of \\(Y_B\\) given \\(Y_A\\) in terms of \\(\\theta_A\\), \\(\\theta_B\\) and components of \\(\\Psi\\). Try to interpret how \\(E[Y_B|Y_A]\\) differs from \\(E[Y_B]\\) and how \\(V[Y_B|Y_A]\\) differs from \\(V[Y_B]\\).\n\nIdentities for exercise 3\nSome of the following identities will be helpful for interpretation.\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "hw/hw09.html",
    "href": "hw/hw09.html",
    "title": "Homework 9",
    "section": "",
    "text": "load-libraries\nlibrary(tidyverse)"
  },
  {
    "objectID": "hw/hw09.html#exercise-1",
    "href": "hw/hw09.html#exercise-1",
    "title": "Homework 9",
    "section": "Exercise 1",
    "text": "Exercise 1\n3.12 from Hoff."
  },
  {
    "objectID": "hw/hw09.html#exercise-2",
    "href": "hw/hw09.html#exercise-2",
    "title": "Homework 9",
    "section": "Exercise 2",
    "text": "Exercise 2\n8.1 from Hoff. Note there is a typo in this exercise. Every \\(\\theta_i\\) in the exercise prompt should be replaced by \\(\\theta_j\\)."
  },
  {
    "objectID": "hw/hw09.html#exercise-3",
    "href": "hw/hw09.html#exercise-3",
    "title": "Homework 9",
    "section": "Exercise 3",
    "text": "Exercise 3\n8.3 from Hoff: find the problem setup (definitions of each Greek letter) on page 132 and 133 of the book. Also see, e.g. the notes on hierarchical modeling.\nRun the code below to load the data.\n\nlibrary(readr)\nlibrary(glue)\n\nfor(i in 1:8) {\nassign(paste0(\"school\", i), \n       read_csv(glue(\"https://sta360-fa24.github.io/data/school{i}.csv\")))\n}"
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#exercise-1",
    "href": "slides/lab6-mcmc-d-practice.html#exercise-1",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet \\(p(\\theta_1, \\theta_2 | \\mathbf{y})\\) be our target distribution, i.e. the distribution we are interested in sampling.\nWe construct a Gibbs sampler and look at the trace plots of \\(\\theta_1\\) and \\(\\theta_2\\), produced below. Chat with your neighbor, describe what you observe. Has the chain reached stationarity for each parameter? How well is the sampler mixing? Do you think the parameters are correlated or uncorrelated? Why or why not?"
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#exercise-2",
    "href": "slides/lab6-mcmc-d-practice.html#exercise-2",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nBased on the first 1000 iterations of your Gibbs sampler shown on the previous slide, which of the following joint densities is the most plausible for \\(\\theta_1, \\theta_2 | \\mathbf{y}\\)? Why? Hint: it may help to think about where your sampler starts and imagine a particle moving through space according to conditional updates."
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#solution-1",
    "href": "slides/lab6-mcmc-d-practice.html#solution-1",
    "title": "MCMC diagnostics practice",
    "section": "Solution 1",
    "text": "Solution 1\n\nThe chain has not reached stationarity for either parameter. Different parts of the chain do not look the same.\nSampler appears to be mixing poorly (at least when run for only 1000 iterations) since we jump from one mode to another only once.\nThe parameters look correlated since jumps happen at the same (or nearly the same) iteration."
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#solution-2",
    "href": "slides/lab6-mcmc-d-practice.html#solution-2",
    "title": "MCMC diagnostics practice",
    "section": "Solution 2",
    "text": "Solution 2\nWe start around (10, 45) and up sampling around (50, 53). This rules out (A) and perhaps also (B). Notice the axes.\nPlot (C) looks like uncorrelated parameters.\nThe only plot with islands of high posterior density at these regions is plot (D), which shows an additional mode that we haven’t sampled at all.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/dynamicalSystems2.html",
    "href": "notes/dynamicalSystems2.html",
    "title": "Parameter Estimation in Dynamical Systems",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "notes/dynamicalSystems2.html#example-hares-lynx-population-dynamics",
    "href": "notes/dynamicalSystems2.html#example-hares-lynx-population-dynamics",
    "title": "Parameter Estimation in Dynamical Systems",
    "section": "Example: Hares-Lynx population dynamics",
    "text": "Example: Hares-Lynx population dynamics\nA Canadian business, Hudson’s Bay company is North America’s longest continually operating company (founded in 1670). During the 19th and 20th century, the company bought animal pelts of both snowshoe hares and lynx from trappers. Lynx are the most predominant natural predator of snowshoe hares. The counts of pelts provide an approximation to the population size of each animal. Data sourced from here.\n\nhares_lynx = read_csv(\"../data/hares-lynx.csv\")\nglimpse(hares_lynx)\n\nRows: 21\nColumns: 3\n$ year  &lt;dbl&gt; 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910…\n$ hares &lt;dbl&gt; 30.0, 47.2, 70.2, 77.4, 36.3, 20.6, 18.1, 21.4, 22.0, 25.4, 27.1…\n$ lynx  &lt;dbl&gt; 4.0, 6.1, 9.8, 35.2, 59.4, 41.7, 19.0, 13.0, 8.3, 9.1, 7.4, 8.0,…\n\n\n\nyear is the year of record\nhares is the number of hare pelts (thousands)\nlynx is the number of lynx pelts (thousands)\n\n\nDynamical System\nThe following system is an example known as “Lotka-Volterra” dynamics which describe an interactive model of the population of predator and prey.\n\n\n\n\n\n\n\n\\(H(t)\\)\nNumber of hares at time t\n\n\n\\(H(0) = H_0\\)\nNumber of hares at time 0\n\n\n\\(L(t)\\)\nNumber of lynx at time t\n\n\n\\(L(0) = L_0\\)\nNumber of lynx at time 0\n\n\n\\(a_1\\)\nPer capita birth rate of hares\n\n\n\\(b_1\\)\nPer capita death rate of lynx\n\n\n\\(a_2\\)\nRate at which lynx eat hares\n\n\n\\(b_2\\)\nRate at which prey affects predator growth\n\n\n\nSome assumptions:\n\nThe prey population finds ample food at all times.\nThe food supply of the predator population depends entirely on the size of the prey population.\nThe rate of change of population is proportional to its size.\nDuring the process, the environment does not change in favor of one species, and genetic adaptation is inconsequential.\nPredators have limitless appetite.\nBoth populations can be described by a single variable. This amounts to assuming that the populations do not have a spatial or age distribution that contributes to the dynamics.\n\n\\[\n\\begin{aligned}\n\\frac{dH(t)}{dt} &= a_1 H(t) - a_2 H(t)L(t)\\\\\n\\frac{dL(t)}{dt} &= - b_1 L(t) + b_2 H(t)L(t)\n\\end{aligned}\n\\]\n\n\nStatistical model\nOne more assumption: we will assume multivariate normal noise in our observations \\(H(t), L(t)\\).\n\\[\n  \\begin{align}\n   \\begin{bmatrix}\n           H(t) \\\\\n           L(t)\n         \\end{bmatrix}\n         &\\sim\n         MVN \\left(\n         \\begin{bmatrix}\n           \\tilde{H}(t) \\\\\n           \\tilde{L}(t)\n         \\end{bmatrix},\n         \\Sigma\n          \\right)\n  \\end{align}\n\\]\nwhere \\(\\tilde{H}(t), \\tilde{L}(t)\\) is the solution of the system of differential equations and is a function of \\(H(0), L(0), a_1, a_2, b_1, b_2\\) as well as \\(t\\).\n\\(\\Sigma\\) is a \\(2 \\times 2\\) matrix\nWe place priors on the unknowns\n\\[\n\\begin{aligned}\na_1 &\\sim N()\\\\\na_2 &\\sim \\text{log-normal}\\\\\nb_1 &\\sim N()\\\\\nb_2 &\\sim \\text{gamma}()\n\\end{aligned}\n\\]\n\n\nParameter estimation"
  },
  {
    "objectID": "slides/lab4.html#exercise",
    "href": "slides/lab4.html#exercise",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nA data scientist at a small subscriber-based tech company models the number of new subscribers in a day as \\(Y|\\theta \\sim \\text{Poisson}(\\theta)\\) with prior \\(\\theta \\sim \\text{gamma}(a,b)\\). A priori, the data scientist believes that there are on average 20 signups per day and 90% of the time there are between approximately 3 and 50 signups on a given day.\na\nFind suitable \\(a\\) and \\(b\\) that satisfy the data scientist’s prior beliefs.\nVerify how well your prior aligns with this belief using Monte Carlo sampling to generate the prior predictive distribution, \\(p(\\tilde{y}) = \\int p(\\tilde{y}, \\theta)d\\theta\\).\nb\nAfter one month the data scientist observes the following daily subscriber counts:\n\ny = c(10, 21, 19, 16, 20, 18, 35, 16, 23, 26, 20, 21, 23, 19, 18, 20, 23, 18, 21, 16, 15, 15, 20, 22, 19, 25)\n\nThe data scientist is fundamentally interested in the variance of subscriber counts per day. Is the Poisson model appropriate for this data?\nReport \\(p(\\tilde{S}^2 &gt; s^2_{obs} | y_1,\\ldots y_n)\\) where \\(\\tilde{S}^2\\) is the posterior predictive sample variance and \\(s^2_{obs}\\) is the observed sample variance (\\(s^2_{obs} = 21.3\\)). To generate samples under the posterior predictive distribution, use the prior from part (a)."
  },
  {
    "objectID": "slides/lab4.html#exercise-1",
    "href": "slides/lab4.html#exercise-1",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "hw/hw07.html",
    "href": "hw/hw07.html",
    "title": "Homework 7",
    "section": "",
    "text": "Ridge regression theory: Let \\(y \\sim N_n(X \\beta, \\sigma^2 I)\\). Consider estimating \\(\\beta\\) with the prior distribution \\(\\beta | \\sigma^2 \\sim N_p(0, \\sigma^2 I / \\lambda)\\), where \\(\\lambda\\) is known and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nDerive the conditional distribution of \\(\\beta | y, \\sigma^2\\) and, in particular, show that \\(E[\\beta | y] = (X^TX + I \\lambda)^{-1} X^Ty\\). Denote this expectation \\(\\hat{\\beta}_\\lambda\\), which we can use as an estimator of \\(\\beta\\). What happens to \\(\\hat{\\beta}_\\lambda\\) as \\(\\lambda \\rightarrow 0\\)?\nConsider the special case that \\(X^TX\\) is a diagonal matrix with entries \\(x_1^T x_1, \\ldots, x_p^T x_p\\). Write down the mathematical expression for an individual entry of the estimator, i.e. \\(\\hat{\\beta}_{\\lambda~i}\\) (where \\(i\\) is the \\(i\\)th entry of the vector). Further write down the mathematical expression for individual entries of the OLS estimator \\(\\hat{\\beta}_{OLS~i}\\). Compare the two and explain, in words, the effect of \\(\\lambda\\)."
  },
  {
    "objectID": "hw/hw07.html#exercise-1",
    "href": "hw/hw07.html#exercise-1",
    "title": "Homework 7",
    "section": "",
    "text": "Ridge regression theory: Let \\(y \\sim N_n(X \\beta, \\sigma^2 I)\\). Consider estimating \\(\\beta\\) with the prior distribution \\(\\beta | \\sigma^2 \\sim N_p(0, \\sigma^2 I / \\lambda)\\), where \\(\\lambda\\) is known and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nDerive the conditional distribution of \\(\\beta | y, \\sigma^2\\) and, in particular, show that \\(E[\\beta | y] = (X^TX + I \\lambda)^{-1} X^Ty\\). Denote this expectation \\(\\hat{\\beta}_\\lambda\\), which we can use as an estimator of \\(\\beta\\). What happens to \\(\\hat{\\beta}_\\lambda\\) as \\(\\lambda \\rightarrow 0\\)?\nConsider the special case that \\(X^TX\\) is a diagonal matrix with entries \\(x_1^T x_1, \\ldots, x_p^T x_p\\). Write down the mathematical expression for an individual entry of the estimator, i.e. \\(\\hat{\\beta}_{\\lambda~i}\\) (where \\(i\\) is the \\(i\\)th entry of the vector). Further write down the mathematical expression for individual entries of the OLS estimator \\(\\hat{\\beta}_{OLS~i}\\). Compare the two and explain, in words, the effect of \\(\\lambda\\)."
  },
  {
    "objectID": "hw/hw07.html#exercise-2",
    "href": "hw/hw07.html#exercise-2",
    "title": "Homework 7",
    "section": "Exercise 2",
    "text": "Exercise 2\nRidge regression application: The data set yX.diabetes.train contains data on diabetes progression (first column) and 64 predictor variables. These data can be loaded with with command\n\nyX&lt;-dget(url(\"https://sta602-sp25.github.io/data/yX.diabetes.train\"))\n\n\nFor each value of \\(\\lambda \\in \\{0, 1,  \\ldots, 99, 100 \\}\\) compute the estimator \\(\\hat{\\beta}_{\\lambda}\\) based on exercise 1 above. Visualize each \\(\\hat{\\beta}\\) as a function of \\(\\lambda\\) (maybe using matplot). Describe any trend(s) you notice in the plots.\nLoad the data set yX.diabetes.test using the code below\n\n\nyX.diabetes.test&lt;-dget(\n  url(\"https://sta602-sp25.github.io/data/yX.diabetes.test\"))\n\nUse yX.diabetes.test to evaluate the predictive performance of each estimate you obtained in part a. Specifically, compute the predictive error sum of squares \\(PSS(\\lambda) = ||y_{test} - X_{test} \\hat{\\beta}_{\\lambda}||^2\\) for each value of \\(\\lambda\\) (IMPORTANT: \\(\\hat{\\beta}_{\\lambda}\\) is obtained from the training data in part a, not the test data). Make a plot of PSS versus \\(\\lambda\\). How good is the unbiased OLS estimate for prediction, relative to the other estimates?\n\nIdentify the value of \\(\\lambda\\) that has the best predictive performance. For this best value of \\(\\lambda\\), report which x-variables have the largest effects."
  },
  {
    "objectID": "hw/hw07.html#exercise-3",
    "href": "hw/hw07.html#exercise-3",
    "title": "Homework 7",
    "section": "Exercise 3",
    "text": "Exercise 3\nFor this exercise, use the code below to load the data\n\nyX = readRDS(\n  url(\"https://sta602-sp25.github.io/data/yXspectroscopy.rds\"))\n\nSource separation: The first column y of the dataset yXSS.rds is the vectorization of a spectroscopy image of a water sample taken from the Neuse River in North Carolina. You can view the image with the following code: y&lt;-yX[,1] ; image(matrix(y,151,43)). The water sample is of unknown origin, but it is assumed that it is a mix of water from 9 different categories, whose average spectroscopy images are given by the remaining 9 columns \\(X\\) of yX. You can view these images with the same code above, applied to each column of \\(X\\).\n\nFrom \\(y\\) and \\(X\\), infer the sources of the water sample using the linear model \\(E[y|X, \\beta] = X\\beta\\). Assuming the normal linear model and with priors \\(\\beta \\sim N_9(1/9, \\ldots 1/9), I_9)\\), \\(1/\\sigma^2 \\sim \\text{gamma}(1, 1)\\), use a Gibbs sampler to obtain a posterior distribution of \\(\\beta\\) and \\(\\sigma^2\\) given \\(y\\). Plot the posterior density of \\(\\sigma^2\\), and obtain posterior 95% confidence intervals for each element of \\(\\beta\\). Which of the nine categories are the main sources of the water sample?\nEvaluate the assumptions of the normal linear model using some residual plots, addressing the assumption that the entries of \\(y\\) have constant variance, are uncorrelated, and are normally distributed. Hint: plots residuals vs yhat and a QQ plot.\nFor this problem it doesn’t make sense for the coefficients of \\(\\beta\\) to be negative. Think of a modification to the prior distribution for \\(\\beta\\) that takes this fact into account, and describe how you could sample \\(\\beta\\) under this updated model (you don’t have to implement it)."
  },
  {
    "objectID": "notes/dynamicalSystems.html",
    "href": "notes/dynamicalSystems.html",
    "title": "Parameter Estimation in Dynamical Systems",
    "section": "",
    "text": "library(tidyverse)\nToy example: logistic growth of a population.\n\\[\n\\frac{dN}{dt} = rN ( 1 - \\frac{N}{K})\n\\]\nwhere \\(N(t)\\) is the number of individuals at time \\(t\\), \\(r\\) is the per capita growth rate, and \\(K\\) is the carrying capacity.\nThis toy example can be solved analytically,\n\\[\nN(t) = N_0 f(t)\n\\]\nLet true parameter values \\(r = 1\\), \\(N_0 = 10\\), \\(K = 50\\).\n# https://en.wikipedia.org/wiki/Population_growth\ngrowth = function(K, r, N0, t) {\n  A = (K - N0) / N0\n  round(K / (1 + (A * exp(-r * t))))\n}\n\ntVector = seq(0, 5, 0.05)\n\nY = growth(K = 50, r = 1, N0 = 10, t = tVector)\n\nset.seed(360)\ndf = data.frame(t = tVector, Y) %&gt;%\n  slice_sample(n = 15) %&gt;%\n  arrange(t)\n\nglimpse(df)\n\nRows: 15\nColumns: 2\n$ t &lt;dbl&gt; 0.30, 0.65, 0.70, 1.00, 1.10, 2.15, 2.35, 2.50, 2.85, 3.30, 3.55, 4.…\n$ Y &lt;dbl&gt; 13, 16, 17, 20, 21, 34, 36, 38, 41, 44, 45, 47, 48, 48, 48\n# start at some arbitrary starting point\nr0 = 2\nK = 100\nN0 = 5\n\ngrowth(K = K, r = r0, N0 = N0, t = df$t)\n\n [1]   9  16  18  28  32  80  85  89  94  97  98 100 100 100 100"
  },
  {
    "objectID": "notes/dynamicalSystems.html#model",
    "href": "notes/dynamicalSystems.html#model",
    "title": "Parameter Estimation in Dynamical Systems",
    "section": "Model",
    "text": "Model\nAssumption: iid N(0, 1) noise.\nData generative model:\n\\[\nY(t)| N_0, r_0, K \\sim Normal(N_0 f(t, N_0, K, r_0), 1)\n\\]\nHorrible priors:\n\\[\n\\begin{aligned}\nN_0 &\\sim Unif(1,50)\\\\\nK &\\sim Unif(40, 1000)\\\\\nr_0 &\\sim Unif(0, 100)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/dynamicalSystems.html#inference",
    "href": "notes/dynamicalSystems.html#inference",
    "title": "Parameter Estimation in Dynamical Systems",
    "section": "Inference",
    "text": "Inference\n\nset.seed(360)\n# starting points\nK_s =  75 #runif(1, 40, 1000)\nK = NULL\nN0_s = 25 #runif(1, 1, 50)\nN0 = NULL\nr0_s = 10\nr0 = NULL\nS = 100000 # number of iterations\n\ndelta = 1 # proposal variance\naccept = 0 # keep track of acceptance rate\n\ngetLogPosterior = function(K, r, N0) {\n  mu = growth(K = K, r = r, N0 = N0, t = df$t)\n  if (N0 &lt; 0) {\n    return(-Inf)\n  }\n  if(K &lt; 0) {\n    return(-Inf)\n  }\n  if(r &lt; 0) {\n    return(-Inf)\n  }\n  else {\n  return(sum(dnorm(df$Y, mu, sd = rep(1, nrow(df)), log = TRUE)))\n  }\n  # todo: should add indicator whether or not within uniform ranges !\n}\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ## propose K\n  K_proposal = rnorm(1, mean = K_s, sd = delta)\n  log.r = getLogPosterior(K = K_proposal, r = r0_s, N0 = N0_s) -\n    getLogPosterior(K = K_s, r = r0_s, N0 = N0_s)\n  \n   if(log(runif(1)) &lt; log.r)  {\n    K_s = K_proposal\n    accept = accept + 1 \n   }\n  if(s %% 10 == 0) {\n  K = c(K, K_s)\n  }\n  \n  # propose N0\n\n  N0_proposal = rnorm(1, N0_s, 1)\n\n  log.r = getLogPosterior(K = K_s, r = r0_s, N0 = N0_proposal) -\n    getLogPosterior(K = K_s, r = r0_s, N0 = N0_s)\n\n   if(log(runif(1)) &lt; log.r)  {\n    N0_s = N0_proposal\n    accept = accept + 1\n   }\n  if(s %% 10 == 0) {\n  N0 = c(N0, N0_s)\n  }\n\n\n  ## propose r\n\n  r0_proposal = rnorm(1, r0_s, .5)\n\n  log.r = getLogPosterior(K = K_s, r = r0_proposal, N0 = N0_s) -\n    getLogPosterior(K = K_s, r = r0_s, N0 = N0_s)\n\n   if(log(runif(1)) &lt; log.r)  {\n    r0_s = r0_proposal\n    accept = accept + 1\n   }\n  if(s %% 10 == 0) {\n  r0 = c(r0, r0_s)\n  }\n}\n\naccept\n\n[1] 69129\n\n\n\nPOST = data.frame(r0 = r0,\n                K = K,\n                N0 = N0)\n\nnumBurn = 0.5*nrow(POST) \nPOST = POST[-c(1:numBurn),]\nPOST %&gt;%\n  ggplot(aes(x = 1:nrow(POST), y = r0)) + \n  geom_line() +\n  theme_bw() +\n  labs(x = \"iteration\")"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html",
    "href": "notes/lec11-missing-data-mvn.html",
    "title": "Inference under MVN with missing data",
    "section": "",
    "text": "This example is from Hoff ch. 7.\nLoad libraries and data.\n\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(monomvn)\nlibrary(coda)\nY = read_csv(\"https://sta360-fa23.github.io/data/Pima.csv\") %&gt;%\n  as.matrix() \ncolnames(Y) = NULL\n\nThis data set contains\n\nglu blood plasma glucose concentration\nbp diastolic blood pressure\nskin skin fold thickness\nbmi body mass index\n\nfor 200 women of Pima Indian heritage living near Phoenix, Arizona (Smith et al, 1988). Some observations are missing.\n\n\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]&lt;-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA &lt;- SIGMA &lt;- Y.MISS &lt;- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar &lt;- apply(Y.full, 2 , mean)\n  Ln &lt;- solve(solve(L0) + n * solve(Sigma))\n  mun &lt;- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta &lt;- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn &lt;- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma &lt;- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b &lt;- (O[i, ] == 0)\n    a &lt;- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa &lt;- solve(Sigma[a, a])\n    beta.j &lt;- Sigma[b, a] %*% iSa\n    s2.j   &lt;- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j &lt;- theta[b] + beta.j %*% (as.matrix(Y.full[i, a]) - theta[a])\n    Y.full[i, b] &lt;- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA&lt;-rbind(THETA,theta) ; SIGMA&lt;-rbind(SIGMA,c(Sigma))\n  Y.MISS&lt;-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html#example-precision-medicine",
    "href": "notes/lec11-missing-data-mvn.html#example-precision-medicine",
    "title": "Inference under MVN with missing data",
    "section": "",
    "text": "This example is from Hoff ch. 7.\nLoad libraries and data.\n\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(monomvn)\nlibrary(coda)\nY = read_csv(\"https://sta360-fa23.github.io/data/Pima.csv\") %&gt;%\n  as.matrix() \ncolnames(Y) = NULL\n\nThis data set contains\n\nglu blood plasma glucose concentration\nbp diastolic blood pressure\nskin skin fold thickness\nbmi body mass index\n\nfor 200 women of Pima Indian heritage living near Phoenix, Arizona (Smith et al, 1988). Some observations are missing.\n\n\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]&lt;-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA &lt;- SIGMA &lt;- Y.MISS &lt;- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar &lt;- apply(Y.full, 2 , mean)\n  Ln &lt;- solve(solve(L0) + n * solve(Sigma))\n  mun &lt;- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta &lt;- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn &lt;- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma &lt;- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b &lt;- (O[i, ] == 0)\n    a &lt;- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa &lt;- solve(Sigma[a, a])\n    beta.j &lt;- Sigma[b, a] %*% iSa\n    s2.j   &lt;- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j &lt;- theta[b] + beta.j %*% (as.matrix(Y.full[i, a]) - theta[a])\n    Y.full[i, b] &lt;- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA&lt;-rbind(THETA,theta) ; SIGMA&lt;-rbind(SIGMA,c(Sigma))\n  Y.MISS&lt;-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/old-gibbs.html",
    "href": "notes/old-gibbs.html",
    "title": "Gibbs sampling",
    "section": "",
    "text": "Definition\n\n\n\nA semiconjugate or conditionally conjugate prior is a prior that is conjugate to the full conditional posterior.\n\n\nNote: the idea of a semiconjugate prior only makes sense when making inferences about two or more parameters.\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta & \\sim N(\\mu_0, \\tau_0^2)\\\\\n\\frac{1}{\\sigma^2} &\\sim gamma(\\nu_0/2, \\nu_0\\sigma_0^2/2)\n\\end{aligned}\n\\]\nIn this case, \\(\\tau_0^2\\) is not a function of \\(\\sigma^2\\) and thus \\(p(\\theta, \\sigma^2) = p(\\theta) p(\\sigma^2)\\).\nEach prior is “semiconjugate” since \\(p(\\theta| \\sigma^2, y_1,\\ldots y_n)\\) is normal and \\(p(\\frac{1}{\\sigma^2} | \\theta, y_1,\\ldots y_n)\\) is gamma but \\(p(\\theta, \\sigma^2)\\) is not conjugate to \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA proper prior is a density function that does not depend on data and integrates to 1. If a prior integrates to a positive finite value, it is an unnormalized density that can be renormalized by being multiplied by a constant to integrate to 1. If a prior is not proper, we call the prior improper.\n\n\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\] \\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff).\n\n\n\nPriors are meant to describe our state of knowledge before examining data. In some cases we may wish to describe our ignorance a priori using a vague prior that plays a minimal role in the posterior distribution.\nA common trap is to imagine that a flat, or uniform prior is uninformative. Previously, on homework 3 you showed a uniform prior on binary probability of success \\(\\theta\\) is informative on the log-odds. Additionally, an improper flat prior may carry a lot of information, since most of the mass is infinitely far away.\n\n\n\n\n\n\nDefinition\n\n\n\nThe Jeffreys prior\n\\[\nJ(\\theta) \\propto \\sqrt{I(\\theta)}\n\\] where \\(I(\\theta) = -E[\\frac{\\partial}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta]\\).\n\n\nThe defining feature of Jeffreys prior is that it will yield an equivalent result if applied to a transformed parameter. This principle of invariance is one approach to non-informative priors that works well for single parameter priors. Multiparameter extensions are often less useful."
  },
  {
    "objectID": "notes/old-gibbs.html#non-conjugate-priors",
    "href": "notes/old-gibbs.html#non-conjugate-priors",
    "title": "Gibbs sampling",
    "section": "",
    "text": "Definition\n\n\n\nA semiconjugate or conditionally conjugate prior is a prior that is conjugate to the full conditional posterior.\n\n\nNote: the idea of a semiconjugate prior only makes sense when making inferences about two or more parameters.\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta & \\sim N(\\mu_0, \\tau_0^2)\\\\\n\\frac{1}{\\sigma^2} &\\sim gamma(\\nu_0/2, \\nu_0\\sigma_0^2/2)\n\\end{aligned}\n\\]\nIn this case, \\(\\tau_0^2\\) is not a function of \\(\\sigma^2\\) and thus \\(p(\\theta, \\sigma^2) = p(\\theta) p(\\sigma^2)\\).\nEach prior is “semiconjugate” since \\(p(\\theta| \\sigma^2, y_1,\\ldots y_n)\\) is normal and \\(p(\\frac{1}{\\sigma^2} | \\theta, y_1,\\ldots y_n)\\) is gamma but \\(p(\\theta, \\sigma^2)\\) is not conjugate to \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA proper prior is a density function that does not depend on data and integrates to 1. If a prior integrates to a positive finite value, it is an unnormalized density that can be renormalized by being multiplied by a constant to integrate to 1. If a prior is not proper, we call the prior improper.\n\n\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\] \\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff).\n\n\n\nPriors are meant to describe our state of knowledge before examining data. In some cases we may wish to describe our ignorance a priori using a vague prior that plays a minimal role in the posterior distribution.\nA common trap is to imagine that a flat, or uniform prior is uninformative. Previously, on homework 3 you showed a uniform prior on binary probability of success \\(\\theta\\) is informative on the log-odds. Additionally, an improper flat prior may carry a lot of information, since most of the mass is infinitely far away.\n\n\n\n\n\n\nDefinition\n\n\n\nThe Jeffreys prior\n\\[\nJ(\\theta) \\propto \\sqrt{I(\\theta)}\n\\] where \\(I(\\theta) = -E[\\frac{\\partial}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta]\\).\n\n\nThe defining feature of Jeffreys prior is that it will yield an equivalent result if applied to a transformed parameter. This principle of invariance is one approach to non-informative priors that works well for single parameter priors. Multiparameter extensions are often less useful."
  },
  {
    "objectID": "notes/old-gibbs.html#gibbs-sampler",
    "href": "notes/old-gibbs.html#gibbs-sampler",
    "title": "Gibbs sampling",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\nWhat if we have a non-conjugate prior? How can we can we look at \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\)?\nIn general, suppose we don’t know\n\\[\np(\\theta, \\sigma^2 | y_1,\\ldots y_n)\n\\] but we do know the full conditional posteriors\n\\[\n\\begin{aligned}\np(\\theta | \\sigma^2, y_1, \\ldots y_n)\\\\\np(\\sigma^2 | \\theta, y_1,\\ldots y_n)\n\\end{aligned}\n\\] we can generate sample \\(\\theta^{(s)}, \\sigma^{2(s)}\\) from the joint posterior by the following algorithm:\n\nsample \\(\\theta^{(s+1)}\\) from \\(p(\\theta | \\sigma^{2(s)}, y_1,\\ldots y_n)\\)\nsample \\(\\sigma^{2(s+1)}\\) from \\(p(\\sigma^2|\\theta^{(s+1)}, y_1,\\ldots, y_n)\\)\nlet \\(\\phi^{(s+1)} = \\{ \\theta^{(s+1)}, \\sigma^{2(s+1)} \\}\\)\n\niterate steps 1-3 \\(S\\) times.\nThis algorithm is called the Gibbs sampler,\n\nit creates a dependent set of values \\(\\phi^{(1)} \\ldots \\phi^{(S)}\\),\nthe sequence is called a Markov chain,\nthe samples let us approximate the posterior i.e. the histogram of \\((\\phi^{(1)},\\ldots \\phi^{(S)})\\) is a Markov chain Monte Carlo approximation to \\(p(\\phi | y_1,\\ldots y_n)\\).\n\nExample: in the semiconjugate normal model described above, the resulting posteriors are:\n\\[\n\\theta | \\sigma^2, y_1,\\ldots y_n \\sim N(\\mu_n, \\tau_n^2),\n\\] where \\(\\mu_n = \\frac{\\mu_0/\\tau_0^2 + n\\bar{y} /\\sigma^2}{1/{\\tau_0^2} + n/\\sigma^2}\\) and \\(\\tau_n^2 = \\left( \\frac{1}{\\tau_0^2 }+ \\frac{n}{\\sigma^2} \\right)^{-1}\\) and\n\\[\n\\sigma^2 | \\theta, y_1, \\ldots y_n \\sim invgamma(\\nu_n/2, \\nu_n \\sigma^2_n / 2)\n\\]\nwhere \\(\\nu_n = \\nu_0 + n\\), \\(\\sigma_n^2 = \\frac{1}{\\nu_n} [\\nu_0 \\sigma_0^2 + n s^2_n(\\theta)]\\) and \\(s^2_n(\\theta) = \\frac{1}{n}\\sum (y_i - \\theta)^2\\).\n\n##########################\n# example from Hoff ch6 #\n##########################\n\n# data\ny = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\nmean.y = mean(y) ; var.y = var(y) ; n = length(y)\n\n# priors\nmu0 = 0\nt20 = 100\nnu0 = 1\ns20 = 2\n\n# starting point\nS = 1000\nPHI = matrix(nrow = S, ncol = 2)\nphi = c(mean.y, var(y))\nPHI[1, ] = phi\n\n# Gibbs sampling\nset.seed(360)\nfor(s in 2:S) { \n\n## generate theta from sigma2\nmun = (mu0 / t20 + n * mean.y * phi[2]) / (1 / t20 + n * phi[2])\nt2n = 1 / (1 / t20 + n * phi[2])\nphi[1] = rnorm(1, mun, sqrt(t2n))\n\n## generate 1/sigma2 from theta\nnun = nu0 + n\ns2n = (nu0 * s20 + (n - 1) * var.y + n * (mean.y - phi[1])^2 ) / nun\nphi[2] = rgamma(1, nun/2, nun * s2n / 2)\n\n## update chain\nPHI[s,] = phi\n}\n\nNote: in this code we use the identity \\(n s_n^2(\\theta) = (n-1)s^2 + n (\\bar{y} - \\theta)^2\\).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\n# plotting the joint posterior\ndf = as.data.frame(PHI)\nnames(df) = c(\"theta\", \"prec\")\ndf %&gt;%\n  ggplot(aes(x = theta, y = prec)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$1/\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, 1/\\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nSince the sequence \\(\\{\\phi^{(s)} \\}\\) depends on \\(\\phi^{(0)}, \\ldots \\phi^{(s-1)}\\) only through \\(\\phi^{(s-1)}\\) we say the sequence is memoryless. This is called the Markov property, and so the sequence is a Markov chain.\n“What happens next depends only on the state of affairs now”\n\n\nUnder some conditions,\n\\[\np(\\phi^{(s)} \\in A) \\rightarrow \\int_A p(\\phi) d\\phi \\ \\ \\text{ as } s \\rightarrow \\infty\n\\]\ni.e. the sampling distribution of \\(\\phi^{(s)}\\) approaches the target distribution as \\(s \\rightarrow \\infty\\) regardless of \\(\\phi^{(0)}\\).\nFurthermore,\n\\[\n\\frac{1}{S} \\sum_{s=1}^S g(\\phi^{(s)})  \\rightarrow E[g(\\phi)]\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nBig take-away: if we can sample from the full conditional posteriors, we can construct a Markov chain with samples from the joint posterior! We can then use Monte Carlo approximation to use the samples to summarize aspects of the posterior."
  },
  {
    "objectID": "hw/hw2023_07.html",
    "href": "hw/hw2023_07.html",
    "title": "Homework 7",
    "section": "",
    "text": "7.3 from Hoff.\nRun the code below to load the data.\n\nlibrary(readr)\nbluecrab = read_csv(\"https://sta360-fa23.github.io/data/bluecrab.csv\")\norangecrab = read_csv(\"https://sta360-fa23.github.io/data/orangecrab.csv\")"
  },
  {
    "objectID": "hw/hw2023_07.html#exercise-1",
    "href": "hw/hw2023_07.html#exercise-1",
    "title": "Homework 7",
    "section": "",
    "text": "7.3 from Hoff.\nRun the code below to load the data.\n\nlibrary(readr)\nbluecrab = read_csv(\"https://sta360-fa23.github.io/data/bluecrab.csv\")\norangecrab = read_csv(\"https://sta360-fa23.github.io/data/orangecrab.csv\")"
  },
  {
    "objectID": "hw/hw2023_07.html#exercise-2",
    "href": "hw/hw2023_07.html#exercise-2",
    "title": "Homework 7",
    "section": "Exercise 2",
    "text": "Exercise 2\n8.1 from Hoff. Note there is a typo in this exercise. Every \\(\\theta_i\\) in the exercise prompt should be replaced by \\(\\theta_j\\)."
  },
  {
    "objectID": "hw/hw2023_07.html#exercise-3",
    "href": "hw/hw2023_07.html#exercise-3",
    "title": "Homework 7",
    "section": "Exercise 3",
    "text": "Exercise 3\n8.3 from Hoff\nRun the code below to load the data.\n\nlibrary(readr)\nlibrary(glue)\n\nfor(i in 1:8) {\nassign(paste0(\"school\", i), \n       read_csv(glue(\"https://sta360-fa23.github.io/data/school{i}.csv\")))\n}"
  },
  {
    "objectID": "notes/lec07-normalModel.html",
    "href": "notes/lec07-normalModel.html",
    "title": "The normal model",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec07-normalModel.html#background",
    "href": "notes/lec07-normalModel.html#background",
    "title": "The normal model",
    "section": "Background",
    "text": "Background\n\nDefinition and vocabulary\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2  \\sim N(\\theta, \\sigma^2).\n\\] The density \\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (y-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance \\((\\frac{1}{\\sigma^2})\\) has a special name, precision. Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %&gt;%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/lec07-normalModel.html#bayesian-inference",
    "href": "notes/lec07-normalModel.html#bayesian-inference",
    "title": "The normal model",
    "section": "Bayesian inference",
    "text": "Bayesian inference\nIn general, we wish to make inference about \\(\\theta\\) and \\(\\sigma^2\\) after observing some data \\(y_1, \\ldots y_n\\) and thus are interested in the posterior \\(p(\\theta, \\sigma^2 | y_1, \\ldots y_n)\\). This is the standard task we have seen thus far, and requires us to specify a joint prior \\(p(\\theta, \\sigma^2)\\). Below, we will work to find a class of conjugate priors over \\(\\theta\\) and \\(\\sigma^2\\).\nWe can break up the joint posterior into two pieces from the axioms of probability:\n\\[\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\n\\] This suggests that we calculate the joint posterior by:\n\nfirst finding the full conditional of \\(\\theta\\): \\(p(\\theta| \\sigma^2, \\vec{y})\\)\nand then finding the marginal posterior of \\(\\sigma^2\\): \\(p(\\sigma^2 | \\vec{y})\\),\n\nwhere \\(\\vec{y} = \\{y_1, \\ldots y_n\\}\\).\n\nThe full conditional of \\(\\theta\\)\nBy Bayes’ theorem,\n\\[\np(\\theta| \\sigma^2, \\vec{y}) \\propto \\underbrace{p(\\vec{y} |\\theta, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\theta|\\sigma^2)}_{\\text{prior}}.\n\\] To arrive at the full conditional posterior of \\(\\theta\\), we must first specify a prior on \\(\\theta\\).\nConsidering we have a normal likelihood, what is a conjugate class of densities for \\(\\theta\\)?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\\(\\theta | \\sigma^2 \\sim N(\\mu_0, \\tau_0^2)\\) for some \\(\\mu_0 \\in \\mathbb{R}\\) and \\(\\tau_0^2 \\in \\mathbb{R}^+\\) is conjugate.\n\n\n\nWith the conjugate prior, our full conditional posterior \\(\\{ \\theta| \\sigma^2, \\vec{y} \\} \\sim N(\\mu_n, \\tau_n^2)\\) where\n\\[\n\\begin{aligned}\n\\mu_n &=\n\\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\n\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n}\n\\\\\n\\\\\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\end{aligned}\n\\]\n\nLet’s sketch out ‘completing the square’ to derive the parameters offline.\n\n\n\nIntuitive posterior parameters\nIf we consider the posterior precision, \\(\\frac{1}{\\tau_n^2}\\), we can re-arrange the terms above to illuminate how posterior information = prior information + data information;.\n\\[\n\\frac{1}{\\tau_n^2}= \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\\] In words, posterior precision is equivalent to prior precision plus sampling precision. If we name each precision term, \\(\\lambda_0 = \\frac{1}{\\tau_0}\\) and \\(\\lambda = \\frac{1}{\\sigma}\\) then\n\\[\n\\mu_n = \\frac{\\lambda_0^2}{\\lambda_0^2 + n\\lambda^2} \\mu_0 +\n\\frac{n\\lambda^2}{\\lambda_0^2 + n\\lambda^2} \\bar{y}\n\\]\ni.e. the posterior mean is the weighted average of prior and sample mean, where the weights are the relative contribution of each precision!\nWe can re-define \\(\\lambda_0^2 = \\kappa_0 \\lambda^2\\) (or equivalently \\(\\tau_0^2 = \\frac{\\sigma^2}{\\kappa_0}\\)) and obtain\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y},\\\\\n\\frac{1}{\\tau_n^2} &= \\frac{\\kappa_0 + n}{\\sigma^2}\n\\end{aligned}\n\\]\nwhere we can interpret \\(\\kappa_0\\) as the prior sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that \\(\\tau_n^2\\) is the posterior variance of the full conditional posterior of \\(\\theta\\). This is distinct from \\(\\sigma_n^2\\), defined below.\n\n\n\n\nPrior on \\(\\sigma^2\\)\nRemember, we want \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\). We have the first component of the right hand side, what about the second component?\nNotice that\n\\[\np(\\sigma^2 | \\vec{y}) \\propto p(\\sigma^2)\\int p(\\vec{y} | \\theta, \\sigma^2) p(\\theta|\\sigma^2) d\\theta\n\\]\nBut how do we choose \\(p(\\sigma^2)\\) to be conjugate? We can proceed in multiple ways: one is noting that the integral is really a convolution of normals, (thereby a sum of normals) and is therefore a normal density.\nUpon inspection, we can see a suitable choice is \\(\\frac{1}{\\sigma^2} \\sim \\text{gamma}(a, b)\\).\n\n\nThe inverse-gamma\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if \\(\\frac{1}{X}\\) has a gamma(a,b) distribution.\nIf X has an inverse-gamma distribution, the density of X is\n\\[\np(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1}e^{-b/x} \\ \\text{for } \\ x &gt; 0\n\\] and \\[\n\\begin{aligned}\nEX &= \\frac{b}{(a-1)} \\text{ if } a \\geq 1; \\ \\infty \\text{ if } 0&lt;a&lt;1,\\\\\nVar(X) &= \\frac{b^2}{(a-1)^2(a-2)} \\ \\text{if } a \\geq 2; \\ \\infty \\text{ if } 0 &lt; a &lt; 2,\\\\\nMode(X) &= \\frac{b}{a +1}.\n\\end{aligned}\n\\]\n\n\nThe marginal posterior of \\(\\sigma^2\\)\nTaken all together, if we let our sampling model and prior distributions be such that \\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\] then the posterior\n\\[\n\\frac{1}{\\sigma^2} | \\vec{y} \\sim \\text{gamma}(\\frac{\\nu_n}{2}, \\frac{\\nu_n \\sigma^2_n}{2}),\n\\] where \\[\n\\begin{aligned}\n\\nu_n &= \\nu_0 + n,\\\\\n\\sigma^2_n &= \\frac{1}{\\nu_n} \\left[\n\\nu_0 \\sigma^2_0 +(n-1)s^2 + \\frac{\\kappa_0 n}{\\kappa_0 + n}(\\bar{y} - \\mu_0)^2\n\\right],\n\\end{aligned}\n\\]\nand \\(s^2\\) is the sample variance, \\(\\frac{1}{n-1} \\sum_i (y_i - \\bar{y})^2\\)."
  },
  {
    "objectID": "notes/lec07-normalModel.html#sampling-from-the-joint-posterior",
    "href": "notes/lec07-normalModel.html#sampling-from-the-joint-posterior",
    "title": "The normal model",
    "section": "Sampling from the joint posterior",
    "text": "Sampling from the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can sample from the joint posterior by first sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\).\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %&gt;%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec02-estimation.html",
    "href": "notes/lec02-estimation.html",
    "title": "Is this a fair coin?",
    "section": "",
    "text": "We observe 10 flips from the same coin above, where 0 is “tails” and 1 is “heads”. In summary, we see Y = 1 heads in 10 coin flips. Is this a fair coin?\nTo articulate this mathematically, let \\(\\theta \\in [0, 1]\\) be the bias-weighting (the chance of heads) of the coin. Fundamentally, we want \\(p(\\theta | y)\\), which we can expand via Bayes’ rule,\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{\\int_{\\theta \\in \\Theta} p(y|\\theta) p(\\theta) d\\theta}\n\\]\nLikelihood: the data generative process. The joint probability (or density) of the data given the parameters of the model. Most often thought of as a function of the parameter. Note: not a density of the parameter.\nPrior: Our a priori (beforehand) beliefs about the true population characteristics.\nPosterior: Our a posteriori (afterwards) beliefs about the true population characteristics after having observed the data set \\(y\\).\nNormalizing constant: A number that enables a pmf or pdf to integrate to 1."
  },
  {
    "objectID": "notes/lec02-estimation.html#uniform-prior",
    "href": "notes/lec02-estimation.html#uniform-prior",
    "title": "Is this a fair coin?",
    "section": "Uniform prior",
    "text": "Uniform prior\nLet \\(y\\) be the number of heads in \\(n\\) coin flips.\n\\[\np(\\theta | y) \\propto \\theta^{y}(1-\\theta)^{n-y}\n\\]\nThis is the kernel of a ___ density, where \\(\\alpha = y + 1\\) and \\(\\beta = n - y + 1\\), hence\n\\[\np(\\theta | y) = \\frac{\\Gamma(n + 2)}{\\Gamma(y + 1)\\Gamma(n-y+1)} \\theta^{y}(1-\\theta)^{n-y}\n\\]\nand the posterior mean is \\(\\frac{y + 1}{n + 2}\\) and the posterior variance is \\(\\frac{(y+1)(n - y + 1)}{(n + 2)^2 (n + 1)}\\).\nLet’s examine how the posterior evolves with each successive coin flip.\n\nplotscode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = c(0, 1, 2, 3, 4, 10, 100, 1000, 5000)\n\nfor (i in seq_along(N)) {\nn = N[i]\nif(n == 0) {\n  y = 0\n}\nelse {\n  y = sum(flips[1:n])\n}\n\nx = 0:1 # range\ndf = data.frame(x)\nassign(paste0(\"p\", i),\n  df %&gt;%\n  ggplot(aes(x = x)) +\n  stat_function(fun=dbeta, \n                args = list(shape1 = y + 1, shape2 = n - y + 1)) +\n  labs(y = TeX(\"$p(\\\\theta | y)$\"), x = TeX(\"$\\\\theta$\"),\n       title = glue(\"n = {n}\")) +\n  theme_bw()\n)\n}\n\n(p1 + p2 + p3) / \n  (p4 + p5 + p6) / \n  (p7 + p8 + p9) +\n  plot_annotation(title = \"Figure 1\")"
  },
  {
    "objectID": "notes/lec02-estimation.html#conjugacy",
    "href": "notes/lec02-estimation.html#conjugacy",
    "title": "Is this a fair coin?",
    "section": "Conjugacy",
    "text": "Conjugacy\nIf \\(\\theta \\sim\\) Uniform(0, 1) then \\(p(\\theta)\\) = 1 for all \\(\\theta \\in [0, 1]\\).\nSimilarly, if \\(\\theta \\sim\\) beta(1, 1), then \\(p(\\theta) = 1\\).\nClaim:\nIf\n\\[\n\\begin{aligned}\n\\theta &\\sim \\text{beta}(a, b)\\\\\nY | \\theta &\\sim \\text{binomial}(n, \\theta)\n\\end{aligned}\n\\] then\n\\[\np(\\theta | Y) = \\text{beta}(y + a, n - y + b)\n\\]\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\nWhile conjugate priors make calculation easy, they may not accurately reflect our prior beliefs.\n\nExercise\n\n\nProve the claim above."
  },
  {
    "objectID": "notes/lec02-estimation.html#other-priors",
    "href": "notes/lec02-estimation.html#other-priors",
    "title": "Is this a fair coin?",
    "section": "Other priors",
    "text": "Other priors\nIncidentally, people are often satisfied with the choice of likelihood but are worried about the choice of prior.\nLet’s examine the effect of another couple of priors.\nGiven the coin’s dubious origin, we might believe a priori that the coin is biased. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(.5, .5)\n\\]\nOr alternatively, we might be strongly believe a priori that the coin is fair. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(20, 20)\n\\]\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\nHow would you update the code of the previous example to show posterior inference under the prior \\(\\theta \\sim\\) beta(2,3)?"
  },
  {
    "objectID": "notes/lec02-estimation.html#prior-data",
    "href": "notes/lec02-estimation.html#prior-data",
    "title": "Is this a fair coin?",
    "section": "Prior data",
    "text": "Prior data\nIn the example above, the parameters, a and b, of the conjugate prior are often thought of as prior data.\n\na: “prior number of 1s”\nb: “prior number of 0s”\na + b: “prior sample size”\n\n\nExercise\n\n\nWe saw above that when a = 20 and b = 20, we needed more data to move the posterior.\nShow that the posterior mean, \\(E(\\theta | y) = \\frac{a + y}{a + b + n}\\) converges to the sample average as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "notes/lec12-regression-intro.html",
    "href": "notes/lec12-regression-intro.html",
    "title": "Intro to regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "notes/lec12-regression-intro.html#background-review",
    "href": "notes/lec12-regression-intro.html#background-review",
    "title": "Intro to regression",
    "section": "Background review",
    "text": "Background review\n\nLinear modeling and linear regression\n\n\n\n\n\n\nLinear regression is but a special case of modeling the conditional expectation of one variable \\(Y\\) given other variables \\(X\\) where \\(E[Y|X] = X \\beta\\). This is what we will focus on today.\nA generalized linear model states \\(E[Y|X] = g(X\\beta)\\), for some invertible “link” function \\(g\\).\nLeast squares regression (otherwise termed “ordinary least squares” or “OLS”) refers to a particular method of estimating \\(\\beta\\): minimize the sum of squared residuals.\n\n\n\nNotation\n\n\\(\\mathbf{y} = \\{y_1, \\ldots y_n\\}\\) is an \\(n \\times 1\\) vector outcomes. Also called the “response” or “dependent variable”. \\(y_i\\) is an individual observed outcome.\n\\(\\mathbf{x}_i\\) is a \\(p \\times 1\\) vector of predictors also called “regressors”, “independent variables”, “covariates”, or “features”.\n\\(X\\) is a \\(n \\times p\\) matrix of all covariates. This is often referred to as “the data matrix”.\n\\(\\beta\\) is a \\(p \\times 1\\) vector of constants. These are referred to as parameters. These are fixed, but unknown numbers. Being Bayesian, we will describe our uncertainty about this population parameter vector using probability statements.\n\n\n\nCommon convention\nThe linear model\n\\[\nE[Y | X\\beta] = X \\beta\n\\] often has the hidden convention that the first column of \\(X\\) is all 1s and \\(\\beta_1\\) is understood to be the intercept term. E.g.\n\\[\nE [ Y | X ]  =\n  \\begin{bmatrix}\n    1 & x_{12} & \\ldots & x_{1p} \\\\\n    1 & x_{22} & \\ldots & x_{2p} \\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    1 & x_{n2} & \\ldots & x_{np}\n  \\end{bmatrix}\n    \\begin{bmatrix}\n    \\beta_1\\\\\n    \\beta_2\\\\\n    \\vdots\\\\\n    \\beta_p\n  \\end{bmatrix}\n\\]\n\n\nIllustration of a linear model\n\nExample\nImagine we’ve collected 3 measurements on a number of penguins:\n\nbody mass (g)\nbill length (mm)\nflipper length (mm)\n\nThe first five entries of our data set are given below:\n\n\n# A tibble: 5 × 3\n  body_mass_g bill_length_mm flipper_length_mm\n        &lt;int&gt;          &lt;dbl&gt;             &lt;int&gt;\n1        3750           39.1               181\n2        3800           39.5               186\n3        3250           40.3               195\n4        3450           36.7               193\n5        3650           39.3               190\n\n\nIn all, our data set contains the measurements of 342 penguins. Because we’ve collected three measurements, each individual penguin can be represented as a point in three dimensional space:\n\n\n\n\n\n\n\n\n\nNow, imagine it’s hard to measure a penguin’s bodymass because it’s difficult to get them onto a scale. We wish to develop a linear model that uses bill length and flipper length to predict body mass,\n\\[\nE[Y|X] = X \\beta,\n\\]\nwhere\n\n\\(Y\\) is the body mass of the penguins and\n\\(X\\) contains covariates bill length and flipper length.\n\nWhat does our linear model look like?\n\n\n\n\n\n\n\n\n\nIn general, for \\(D\\) measurements, a linear model is a \\(D-1\\) dimensional hyperplane!\n\n\n\nTraditional way to find the hyperplane\nTo “fit” a linear regression model means to estimate \\(\\beta\\). One way to do this is to minimize some objective function. A really common function to minimize is the sum of square residuals SSR.\nA residual is defined as the distance our mean is from the true value:\n\\[\n\\begin{aligned}\nr_i &= y_i - E[y_i | \\mathbf{x}\\beta]\\\\\n&= y_i - \\beta^T\\mathbf{x}_i\n\\end{aligned}\n\\] Thus the sum of square residuals is:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n r_i^2 &= \\sum_{i=1}^n (y_i - \\beta^T \\mathbf{x}_i)^2\\\\\n&= (\\mathbf{y} -X\\beta)^T(\\mathbf{y} -X\\beta)\\\\\n&= \\mathbf{y}^T \\mathbf{y} - 2\\beta^T X^T\\mathbf{y} + \\beta^TX^TX\\beta)\n\\end{aligned}\n\\]\nThe ordinary least squares (OLS) estimate is\n\\[\n\\hat{\\beta}_{OLS} = (X^TX)^{-1}X^T \\mathbf{y}\n\\] - See the matrix cookbook by Petersen and Petersen for all your matrix algebra needs.\n\nExercise 1Exercise 2\n\n\nWhat other objective functions could we optimize?\n\n\nShow that \\(\\hat{\\beta}_{OLS}\\) is un-biased. In other words, show that \\(E[\\hat{\\beta}_{OLS} | \\beta] = \\beta\\).\n\n\n\n\n\nNormal linear regression model\nSo far, we had not made any distributional assumptions, we only made an assumption about the expectation. Now for the normal linear regression model,\n\\[\nY = X \\beta + \\epsilon\n\\]\nand \\(\\epsilon \\sim N(0, \\sigma^2 I)\\) where \\(I\\) is a \\(n \\times n\\) identity matrix. This is a way of saying \\(\\epsilon_i \\sim_{iid} N(0, \\sigma^2)\\).\nTherefore,\n\\[\n\\mathbf{y} | X, \\beta, \\sigma^2 \\sim MVN(X\\beta, \\sigma^2 I)\n\\]\n\nExercise 3\n\n\nShow that \\(Var(\\hat{\\beta}_{OLS} | \\beta, \\sigma^2) = \\sigma^2(X^TX)^{-1}\\) under the normal model above.\n\n\n\n\n\n\n\n\n\nHint\n\n\n\nLet \\(z\\) be a random vector. \\(Var[Az] = A Var(z) A^T\\).\n\n\n\nExercise 4\n\n\nWhat is \\(\\hat{\\beta}_{MLE}\\)?\n\n\n\n\n\nAssumptions\nA brief reminder about the flexibility and limitations of classical linear regression.\n\nLimitations so far:\n\nthe mean may not be a good summary of the conditional relationship, e.g. if \\(p(y|x)\\) is skewed, multimodal, or has heavy tails.\nerror may not be iid. In other words, the conditional variance of \\(Y\\) may change with the \\(\\mathbf{x}\\)s.\n\n\n\nFlexibility\nIs this an example of linear regression?\n\\[\ny_i = \\beta_1 + \\beta_2x_1 + \\beta_3 x_1^2 + \\beta_4 \\log x_1 + \\beta_5 x_2 + \\beta_6 x_1 x_2 + \\epsilon_i\n\\] What’s linear about linear regression? The parameters!\nThis is powerful, because nonlinear relationships between \\(X\\) and \\(\\mathbf{y}\\) can often be corrected by a power transformation of \\(X\\), \\(\\mathbf{y}\\) or of both variables."
  },
  {
    "objectID": "notes/lec12-regression-intro.html#bayesian-regression",
    "href": "notes/lec12-regression-intro.html#bayesian-regression",
    "title": "Intro to regression",
    "section": "Bayesian regression",
    "text": "Bayesian regression\nLet’s assume the normal sampling model (i.e. normal data generative process, aka normal likelihood),\n\\[\n\\mathbf{y} | X, \\beta, \\sigma^2 \\sim MVN(X\\beta, \\sigma^2I).\n\\] To make inference about our model parameters, we will construct a posterior distribution,\n\\[\np(\\beta, \\sigma^2 | \\mathbf{y}, X) \\propto \\underbrace{ p(\\mathbf{y}|X, \\beta, \\sigma^2)}_{likelihood} \\underbrace{p(\\beta, \\sigma^2)}_{prior}\n\\]\n\nsemi-conjugate prior specification\nTo setup Gibbs sampling, let’s consider independent semi-conjugate priors, i.e. assume \\(p(\\beta, \\sigma^2) = p(\\beta) p(\\sigma^2)\\)\nBefore reading ahead, what do you think semi-conjugate priors will be for the parameters under the normal linear regression model?\n\nsemi-conjuate prior on \\(\\beta\\)\nIf \\[\n\\beta \\sim MVN(\\beta_0, \\Sigma_0)\n\\]\nthen\n\\[\n\\begin{aligned}\np(\\beta|\\mathbf{y}, X, \\sigma^2) &\\propto\np( \\mathbf{y} | X, \\beta, \\sigma^2) p(\\beta)\\\\\n&\\propto MVN(\\mathbf{m}, V)\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\nV = Var[\\beta | \\mathbf{y}, X, \\sigma^2] &=\n(\\Sigma_0^{-1} + X^TX / \\sigma^2)^{-1}\\\\\n\\mathbf{m} = E[\\beta | \\mathbf{y}, X, \\sigma^2] &= (\\Sigma_0^{-1} + X^T X/ \\sigma^2)^{-1}(\\Sigma_0^{-1} \\beta_0 + X^T\\mathbf{y} / \\sigma^2)\n\\end{aligned}\n\\]\n\n\nsemi-conjugate prior on \\(\\sigma^2\\)\nLet’s re-parameterize. Let \\(\\gamma = 1/\\sigma^2\\).\nIf \\[\n\\gamma \\sim \\text{gamma}(\\nu_0 /2, \\nu_0 \\sigma_0^2 / 2)\n\\]\nthen\n\\[\n\\begin{aligned}\np(\\gamma | \\mathbf{y}, X, \\beta) &\\propto p( \\mathbf{y} | X, \\beta, \\sigma^2) p(\\gamma)\\\\\n&\\propto\n\\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta)]/2)\n\\end{aligned}\n\\]\n\nExercise 5\n\n\nWrite out the pseudo-code of a Gibbs sampler that samples from \\(p(\\beta, \\sigma^2| \\mathbf{y}, X)\\)."
  },
  {
    "objectID": "slides/lab1.html#example-normal-likelihood",
    "href": "slides/lab1.html#example-normal-likelihood",
    "title": "Maximum likelihood estimator",
    "section": "Example: normal likelihood",
    "text": "Example: normal likelihood\nLet \\(X\\) be the resting heart rate (RHR) in beats per minute of a student in this class.\nAssume RHR is normally distributed with some mean \\(\\mu\\) and standard deviation \\(8\\).\n\n\\[\n\\textbf{Data-generative model: } X_i \\overset{\\mathrm{iid}}{\\sim} N(\\mu, 64)\n\\]\n\n\nIf we observe three student heart rates, {75, 58, 68} then our likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\nThat is, the joint density function of the observed data, viewed as a function of the parameter.\n\n\n\n\n\n\n\n\nImportant\n\n\nThe likelihood itself is not a density function. The integral with respect to the parameter does not need to equal 1."
  },
  {
    "objectID": "slides/lab1.html#visualizing-the-likelihood",
    "href": "slides/lab1.html#visualizing-the-likelihood",
    "title": "Maximum likelihood estimator",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\n\ndatalikelihood functionplotplot code\n\n\n\nx = c(75, 58, 68)\n\n\n\n\nL = function(mu, x) {\n  stopifnot(is.numeric(x))\n  n = length(x)\n  likelihood = 1\n  for(i in 1:n){\n    likelihood = likelihood * dnorm(x[i], mean = mu, sd = 8)\n  }\n  return(likelihood)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n  xlim(c(50, 83)) +\n  geom_function(fun = L, args = list(x = x)) +\n  theme_bw() +\n  labs(x = expression(mu), y = \"likelihood\") + \n  geom_vline(xintercept = 67, color = 'red')\n\n\n\n\n\nThe maximum likelihood estimate \\(\\hat{\\mu} = \\frac{75 + 58 + 68}{3} = 67\\).\nThe maximum likelihood estimate is the parameter value that maximizes the likelihood function."
  },
  {
    "objectID": "slides/lab1.html#the-log-likelihood",
    "href": "slides/lab1.html#the-log-likelihood",
    "title": "Maximum likelihood estimator",
    "section": "The log-likelihood",
    "text": "The log-likelihood\nNotice how small the y-axis is on the previous slide. What happens to the scale of the likelihood as we add additional data points?\n\\[\nL(\\mu) = \\prod_{i = 1}^{n} f_x(x_i |\\mu)\n\\]\n\nSince densities often evaluate between 0 and 1, multiplying many together (as we usually do in likelihoods) can quickly result in floating point underflow. That is, numbers smaller than the computer can actually represent in memory.\n\nNote: sometimes densities evaluate to greater than 1 (e.g. dnorm(0, 0, 0.001)) and multiplying several together can result in overflow.\n\n\n\nlog to the rescue!\n\nlog is a monotonic function, i.e. \\(x &gt; y\\) implies \\(\\log(x) &gt; \\log(y)\\), because of this the maximum of \\(f\\) is the same as the maximum of \\(\\log f\\).\nadditionally, log turns products into sums\n\nin practice, we always work with the log-likelihood,\n\\[\n\\log L(\\mu) = \\sum_{i = 1}^n \\log f_x(x_i | \\mu).\n\\]"
  },
  {
    "objectID": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "href": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "title": "Maximum likelihood estimator",
    "section": "Maximum likelihood estimation (MLE)",
    "text": "Maximum likelihood estimation (MLE)\nHow did we know to take the average of the values to find the maximum likelihood estimator \\(\\hat{\\mu}\\)?\n\nFrom calculus, we know that to maximize a function, we need to find where the slope equals zero (technically, to ensure we find some maxima and not a minima we need to also check that the second derivative is negative).\nExample: normal likelihood\nFor the normal likelihood example on the previous slide, we can see visually that the function is concave.\nTo find the maximum,\n\\[\n\\begin{aligned}\n\\frac{d}{d\\mu} \\log L(\\mu) &= \\sum_{i}\\frac{d}{d\\mu} \\log f_x(x_i |\\mu)\\\\\n&= \\sum_{i}\\frac{d}{d\\mu} \\left[ -\\frac{1}{2} \\log (2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} (x_i - \\mu)^2 \\right]\\\\\n&= \\sum_i \\frac{1}{\\sigma^2} (x_i - \\mu)\n\\end{aligned}\n\\]\nSetting the derivative equal to zero,\n\\[\n\\begin{aligned}\n\\sum_i \\left[ x_i - \\hat{\\mu} \\right] &= 0\\\\\nn \\hat{\\mu} &= \\sum_i x_i\\\\\n\\hat{\\mu} &= \\bar{x}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab1.html#exercise-binomial-mle",
    "href": "slides/lab1.html#exercise-binomial-mle",
    "title": "Maximum likelihood estimator",
    "section": "Exercise: binomial MLE",
    "text": "Exercise: binomial MLE\nLet \\(Y_1, Y_2,  \\ldots, Y_n \\sim \\text{iid } \\text{binary}(\\theta)\\). Here \\(\\theta\\) is the probability of a success, i.e. \\(prob(Y_i = 1)\\).\n\nNote: a “binary” distribution is equivalent to a “Bernoulli” distribution. Your book calls it “binary”, so we will as well for consistency.\n\n\nWrite down the likelihood, \\(p(y_1, \\ldots, y_n | \\theta)\\).\nWrite down the log-likelihood.\nCompute \\(\\hat{\\theta}_{MLE} = \\text{argmax}_{\\theta}~ \\log p(y_1, \\ldots, y_n | \\theta)\\)"
  },
  {
    "objectID": "slides/lab1.html#solution",
    "href": "slides/lab1.html#solution",
    "title": "Maximum likelihood estimator",
    "section": "Solution",
    "text": "Solution\n\nsolution 1solution 2solution 3\n\n\n\\[\n\\begin{aligned}\np(y_1, \\ldots, y_n | \\theta) &= \\prod_{i=1}^n p(y_i | \\theta)\\\\\n&= \\theta^{y_i}(1-\\theta)^{1-y_i}\\\\\n&= \\theta^{\\sum {y_i}}(1-\\theta)^{n - \\sum y_i}\n\\end{aligned}\n\\]\n\n\n\\[\n\\log \\left(\\theta^{\\sum {y_i}}(1-\\theta)^{n - \\sum y_i} \\right) =\nn \\bar{y} \\log \\theta + n(1-\\bar{y}) \\log(1 - \\theta)\n\\]\nwhere \\(\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\).\n\n\nTake the derivative\n\\[\n\\begin{aligned}\n\\frac{d}{d\\theta} \\log p(y_1, \\ldots, y_n | \\theta) &=\n\\frac{n\\bar{y}}{\\theta} - \\frac{n - n\\bar{y}}{1- \\theta}\n\\end{aligned}\n\\]\nand set equal to 0. After simplifying,\n\\[\n\\hat{\\theta}_{MLE} = \\bar{y}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/lec04-prediction.html",
    "href": "notes/lec04-prediction.html",
    "title": "Prediction and Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec04-prediction.html#prediction-example",
    "href": "notes/lec04-prediction.html#prediction-example",
    "title": "Prediction and Intro to Monte Carlo",
    "section": "Prediction example",
    "text": "Prediction example\nGeneral social survey (1998)\nSetup:\n\nSuppose \\(X_i = 1\\) if the ith person is happy. \\(X_i = 0\\) otherwise.\nLet \\(Y = \\sum_{i = 1}^{n} X_i\\), where \\(n\\) is the number of people sampled.\n\\(Y_i | \\theta \\sim \\text{binomial}(\\theta)\\) for some fixed \\(n\\).\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\n\nScenario: We sample \\(n = 10\\) people. \\(y = 6\\) are happy. If we sample another \\(n = 10\\), what is the probability that \\(\\tilde{y}\\) are happy?\nWe fundamentally want the posterior predictive distribution, \\(p(\\tilde{y} | y)\\).\nFollowing the offline notes, and given conditional independence, we want\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\int p(\\tilde{y} | \\theta) p(\\theta | y) d\\theta\n&=\n\\int {n \\choose \\tilde{y}}\n(\\theta)^\\tilde{y} (1-\\theta)^{n-\\tilde{y}}\n\\cdot\n\\frac{1}{\\text{B(y + 1, n - y + 1)}}\\theta^{y}(1-\\theta)^{n-y}\nd\\theta\\\\\n&= {n \\choose \\tilde{y}} \\frac{1}{\\text{B(y + 1, n - y + 1)}} \\int \\theta^{\\tilde{y}+y} \\cdot\n(1-\\theta)^{(n-\\tilde{y}) + (n - y)} d\\theta\\\\\n&= {n \\choose \\tilde{y}}\n\\frac{\\text{B}(\\tilde{y} + y + 1, 2n - y - \\tilde{y} + 1)}{\\text{B(y + 1, n - y + 1)}}\n\\end{aligned}\n\\] where \\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). We can of course simplify, since this is really a bunch of factorials, but we can also naively use the beta() function in R and push forward.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny = 6\nn = 10\n\n# posterior predictive probability of ytilde\nprobYT = function(ytilde) {\n  choose(n, ytilde) * \n    beta(ytilde + y + 1, (2*n) - y - ytilde + 1) / \n    beta(y + 1, n - y + 1)\n}\n\n# construct data frame\ndf = data.frame(ytilde = 0:10) %&gt;%\n  mutate(postPredict = probYT(ytilde))\n\n# plot data frame\ndf %&gt;%\n  ggplot(aes(x = ytilde, y = postPredict)) +\n  geom_bar(stat = 'identity') +\n  labs(x = TeX(\"$\\\\tilde{y}$\"), y = TeX(\"$p(\\\\tilde{y}|y)$\"),\n       title = \"Posterior predictive probability\") +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-motivation",
    "href": "notes/lec04-prediction.html#monte-carlo-motivation",
    "title": "Prediction and Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about…\n\n\\(p(\\theta \\in \\mathcal{A} | y)\\),\n\\(E~g(\\theta) | y\\),\n\\(Var~g(\\theta) | y\\)?\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-integration",
    "href": "notes/lec04-prediction.html#monte-carlo-integration",
    "title": "Prediction and Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(X\\), the sample mean \\(\\bar{x}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\] then the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) f_\\theta(\\theta | y)dx \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\n\\]\nwhere \\(f_x(x)\\) is the probability density function for a random variable \\(X\\).\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) to \\(E~\\theta|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/lec04-prediction.html#examples",
    "href": "notes/lec04-prediction.html#examples",
    "title": "Prediction and Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %&gt;%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(\\theta_1 - \\theta_2\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = theta1 - theta2)\n\ndf %&gt;%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1 - \\\\theta_2$\"),\n       y = TeX(\"$p(\\\\theta_1 - \\\\theta_2 | {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n\n\n\n\n(3) \\(p(\\theta_1 - \\theta_2&gt; .5)\\)\n\nmean(df$diff &gt; .5)\n\n[1] 0.4106\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta  \\sim \\text{uniform}(0, 1)\\)\nLet \\(\\gamma = \\log \\theta\\)\nVisualize \\(p(\\gamma)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000, 0, 2)\n\n# define transform function\nf = function(x) {\n  return(0.5 *exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(gamma = -7:0)\ndf2 = data.frame(gammaSamples = log(theta))\n\n# make plots\ndf %&gt;%\n  ggplot(aes(x = gamma)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = gammaSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000, 0, 2)\nphi = log(theta)\nhist(phi)"
  },
  {
    "objectID": "notes/lec10-gibbs-sampling.html",
    "href": "notes/lec10-gibbs-sampling.html",
    "title": "Gibbs sampling",
    "section": "",
    "text": "Introduction\nLet \\(\\theta_1, \\theta_2\\) be two unknown parameters that characterize the data generative model \\(p(\\mathbf{y} | \\theta_1, \\theta_2)\\), where \\(\\mathbf{y} = \\{y_1, \\ldots, y_n\\}\\).\nRecall the following definitions:\n\nThe full conditional posterior of \\(\\theta_1\\) is the density of \\(\\theta_1\\) conditional on all other parameters and the data. In the example above, \\(p(\\theta_1 |\\theta_2, \\mathbf{y})\\) is called “the full conditional posterior of theta 1”.\nThe marginal posterior of \\(\\theta_1\\) is the density of \\(\\theta\\) given the data, but unconditional on any other model parameters. In the example above, \\(p(\\theta_1 | \\mathbf{y})\\) is called “the marginal posterior of theta 1”.\n\nNotice that\n\\[\n\\underbrace{p(\\theta_1, \\theta_2 | \\mathbf{y})}_{\\text{joint posterior of } \\theta_1, \\theta_2} \\ \\ \\ \\ \\ = \\underbrace{p(\\theta_1 |\\theta_2, \\mathbf{y})}_{\\text{full cond'l posterior of }\\theta_1}\n\\cdot\n\\underbrace{p(\\theta_2 | \\mathbf{y})}_{\\text{marginal posterior of } \\theta_2}\n\\]\n\n\nGibbs sampler\nGibbs sampling is a special case of Metropolis-Hastings that proceeds as follows:\n\nsample \\(\\theta_1^{(s+1)}\\) from \\(p(\\theta_1 | \\theta_2^{(s)}, \\mathbf{y})\\)\nsample \\(\\theta_2^{(s+1)}\\) from \\(p(\\theta_2|\\theta_1^{(s+1)}, \\mathbf{y})\\)\n\niterate steps 1-2 a total of \\(S\\) times.\n\nExercise\n\n\nProve that the algorithm described above is in fact a Metropolis-Hastings algorithm where \\(J(\\theta_i | \\theta_i^{(s)}) = p(\\theta_i | \\theta_{j \\neq i}, \\mathbf{y})\\) with acceptance probability 1.\nHint: recall that the Metropolis-Hastings acceptance ratio \\(r\\) is computed as follows:\n\\[\nr = \\frac{\\pi(\\theta^*)}{\\pi(\\theta^{(s)})} \\times\n\\frac{J(\\theta^{(s)}| \\theta^*)}{\nJ(\\theta^{*}| \\theta^{(s)})\n}\n\\]\n\n\n\n\n\nExample\nImagine the following target distribution (the joint probability distribution of two variables, \\(\\theta\\) and \\(\\delta\\)).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nset.seed(360)\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\nsd = rep(sqrt(1 / 3), 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # number of samples\n\ndelta = sample(d, size = N, prob = c(.45, .1, .4), replace = TRUE)\ntheta = rnorm(N, mean = mu[delta], sd = sd[delta])\n\ndf = data.frame(delta, theta)\ndf %&gt;%\n  ggplot(aes(x = theta, y = delta)) + \n  geom_bin2d(bins = 25) +\n  theme_bw() + \n  labs(y = TeX(\"\\\\delta\"), \n       x = TeX(\"\\\\theta\"))\n\n\n\n\nIn this example,\n\\[\n\\begin{aligned}\np(\\delta = d) = \\begin{cases}\n&.45 &\\text{ if } d = 1\\\\\n&.10 &\\text{ if } d = 2\\\\\n&.45 &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\{\\theta | \\delta = d\\} \\sim\n\\begin{cases}\n&N(-3, 1/3) &\\text{ if } d = 1\\\\\n&N(0, 1/3) &\\text{ if } d = 2\\\\\n&N(3, 1/3) &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\n\nExerciseSolution\n\n\nWrite down the full conditional distributions necessary to Gibbs sample the target.\nNote: this is a toy example. We can sample from the target distribution directly as seen above. However, we will construct a Gibbs sampler for pedagogical purposes that will become apparent momentarily.\n\n\n\nTo construct a Gibbs sampler, we need the full conditional distributions.\n\n\\(p(\\theta | \\delta)\\) is given.\n\\(p(\\delta| \\theta) = \\frac{p(\\theta | \\delta = d) p(\\delta = d)}{ \\sum_{d=1}^3p(\\theta | \\delta = d)p(\\delta = d)}\\), for \\(d \\in \\{1, 2, 3\\}\\). \n\n\n\n\nBelow the sampler is implemented and a trace plot for \\(\\theta\\) reported.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\ns2 = rep(1 / 3, 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # chain length\nw = c(.45, .1, .4) # delta probabilities\n\n## Gibbs sampler ##\nset.seed(360)\nN = 1000 # number of Gibbs samples\n\ntheta = 0 # initial theta value\nthd.mcmc = NULL\nfor(i in 1:N) {\nd = sample(1:3 , 1, prob = w * dnorm(theta, mu, sqrt(s2))) \ntheta = rnorm(1, mu[d], sqrt(s2[d]))\nthd.mcmc = rbind(thd.mcmc, c(theta,d))\n}\n# note we take advantage that sample() in R does not require the probability\n# to add up to 1\n\ndf = data.frame(theta = thd.mcmc[,1],\n                delta = thd.mcmc[,2])\n\ndf %&gt;%\n  ggplot(aes(x = seq(1, nrow(df)), y = theta)) +\n  geom_line() +\n  theme_bw() +\n  labs(y = TeX(\"\\\\theta\"),\n       x = \"iteration\",\n       title = \"Traceplot of 1000 Gibbs samples\")\n\n\n\n\n\nExercise\n\n\n\ndescribe how we implement the conditional update for delta in the code above\nwhat do you notice from the traceplot above? Hint: you can imagine hopping from delta islands in the first figure of the joint target over parameter space.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe picture to visualize is that of a particle moving through parameter space.\n\n\nLet’s see how well our samples of \\(\\theta\\) approximate the true marginal \\(p(\\theta)\\)."
  },
  {
    "objectID": "notes/lec06-MonteCarloPredictionError.html",
    "href": "notes/lec06-MonteCarloPredictionError.html",
    "title": "Prediction checks and Monte Carlo Error",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec06-MonteCarloPredictionError.html#predictive-distributions-with-monte-carlo",
    "href": "notes/lec06-MonteCarloPredictionError.html#predictive-distributions-with-monte-carlo",
    "title": "Prediction checks and Monte Carlo Error",
    "section": "Predictive distributions with Monte Carlo",
    "text": "Predictive distributions with Monte Carlo\nGoal: evaluate our model both a priori and a posteriori i.e. before and after looking at the data.\n\nPrior predictive distribution\nWe can use Monte Carlo to sample new observation, \\(\\tilde{y}\\), from the prior predictive distribution\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta)p(\\theta) d\\theta,\n\\]\nwhere we proceed by following the iterative procedure below\n1. sample theta_i from the prior p(theta)\n2. sample ytilde from p(ytilde | theta_i)\n3. repeat steps 1 and 2\n\nthis can be useful to see if a prior for \\(p(\\theta)\\) actually translate to reasonable prior beliefs about the data.\n\n\nExercise\n\n\nFor \\(p(\\theta) = \\text{gamma}(8,2)\\), plot \\(p(\\tilde{y})\\) assuming \\(\\tilde{y} | \\theta \\sim \\text{Poisson}(\\theta)\\).\n\n\n\n\n\nPosterior predictive distribution\nWe can also sample \\(\\tilde{y}\\) from the posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta,\n\\]\nwhere the procedure is the same as before, except step 1 is replace with sampling \\(\\theta\\) from the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\).\nThe resulting sequence \\(\\{(\\theta^{(1)}, \\tilde{y}^{(1)}), \\ldots, (\\theta^{(S)}, \\tilde{y}^{(S)})\\}\\) constitutes \\(S\\) independent samples from the joint posterior of \\((\\theta, \\tilde{Y})\\). The sequence \\(\\{\\tilde{y}^{(1)}, \\ldots, \\tilde{y}^{(S)}\\}\\) constitutes \\(S\\) independent samples from the marginal posterior distribution of \\(\\tilde{Y}\\), aka the posterior predictive distribution."
  },
  {
    "objectID": "notes/lec06-MonteCarloPredictionError.html#posterior-predictive-model-checking",
    "href": "notes/lec06-MonteCarloPredictionError.html#posterior-predictive-model-checking",
    "title": "Prediction checks and Monte Carlo Error",
    "section": "Posterior predictive model checking",
    "text": "Posterior predictive model checking\nWe can assess the fit of a model by comparing the posterior predictive distribution to the empirical distribution.\n\nExample: is our Poisson model flawed?\n\n# load general social survey data\ngss = read_csv(\"https://sta360-fa23.github.io/data/gss.csv\")\n\n\ny1 = gss$CHILDS[gss$FEMALE == 1 &  gss$YEAR &gt;= 1990  & gss$AGE == 40 & \n                   gss$DEGREE &lt; 3 ]\ny1 = y1[!is.na(y1)]\nn = length(y1)\n\nWe are examining the number of children \\(Y_i\\) belonging to \\(n=\\) 111 40 year old women surveyed 1990 or later without a bachelor’s. These data come from the general social survey.\nSuppose\n\\[\n\\begin{aligned}\nY_i | \\theta & \\sim \\text{Poisson}(\\theta)\\\\\n\\theta & \\sim \\text{gamma}(2, 1).\n\\end{aligned}\n\\] The empirical and predictive distributions of the data are both plotted below.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\n# posterior predictive distribution\nytotal = sum(y1)\na = 2 ; b = 1\nN = 10000\ntheta.post.mc = rgamma(N, ytotal + a, b + n)\ny1.mc = rpois(N, theta.post.mc)\n\n# data\ndf = data.frame(y1) # empirical\ndf2 = data.frame(y1.mc) # post predictive\n  \n# make plot\ndf %&gt;%\n  ggplot(aes(x = y1)) +\n  geom_bar(aes(x = y1 + .15, y = (..count..)/sum(..count..),\n               fill = \"empirical\"), alpha = 0.6, width = 0.3) +\n  geom_bar(data = df2, \n                 aes(x = y1.mc -.15, y = (..count..) / sum(..count..),\n                     fill = \"predictive\"), alpha = 0.4, width = 0.3) +\n  labs(x = \"number of children\", \n       y = TeX(\"$p(Y_i = y_i)$\"),\n       fill = \"\") +\n  scale_x_continuous(breaks = c(0:7), labels = c(0:7),\n                     limits = c(-.5,7.5)) +\n  \n  theme_bw()\n\n\n\n\n\nExerciseSolution\n\n\nLet \\(\\mathbf{y}\\) be a vector of length 111. Let \\(t(\\mathbf{y})\\) be the ratio of \\(2\\)s to \\(1\\)s in \\(\\mathbf{y}\\). For our observed data, this test statistic \\(t(\\mathbf{y}_{obs}) = 38 / 19 = 2\\). What is the tail probability \\(p(t(\\tilde{\\mathbf{Y}}) \\geq t(\\mathbf{y}_{obs}))\\) under the posterior predictive distribution?\n\n\n\nset.seed(123)\n\nt.mc = NULL\nfor (i in 1:10000) {\n  theta1 = rgamma(1, ytotal + a, b + n) # draw 1 theta from posterior\n  y1.mc = rpois(n, theta1) # draw y from post pred of n = 111\n  t.mc = c(t.mc,\n           sum(y1.mc == 2) / sum(y1.mc == 1))# compute t\n}\nhist(t.mc)\n\n\n\n\n\n\n\nmean(t.mc &gt;= 2)\n\n[1] 0.0059"
  },
  {
    "objectID": "notes/lec06-MonteCarloPredictionError.html#monte-carlo-error",
    "href": "notes/lec06-MonteCarloPredictionError.html#monte-carlo-error",
    "title": "Prediction checks and Monte Carlo Error",
    "section": "Monte Carlo error",
    "text": "Monte Carlo error\n\nHow many values should we simulate?\nRecall: expected values are integrals, and integrals are expected values. Since central limit theorem (CLT) deals with expected values…\nRecall: CLT states that if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\n\nHow to remember this/show this? Offline notes.\n\nSo to estimate \\(\\theta\\), we can generate \\(\\bar{\\theta}\\) by Monte Carlo simulation and report a confidence interval using quantiles of the normal given above in conjunction with the Monte Carlo standard error \\(\\frac{\\hat{\\sigma}}{\\sqrt{N}}\\)\nThis means we get convergence at the rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\nRecall:\n\nsd1 = pnorm(1) - pnorm(-1)\nsd2 = pnorm(2) - pnorm(-2)\nsd3 = pnorm(3) - pnorm(-3)\n\n\na 0.6826895% confidence interval can be obtained using \\(\\pm 1\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9544997% confidence interval can be obtained using \\(\\pm 2\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9973002% confidence interval can be obtained using \\(\\pm 3\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\n\n\n\nToy example\nLet \\(\\phi\\) be the random variable of interest.\nAssume the posterior distribution \\(\\phi| data \\sim \\text{binomial}(20, 0.4)\\)\n\nset.seed(123)\n\n# binomial(n, p)\nn = 20\np = 0.4\n\n# exact posterior mean, variance, sd of a binomial(n, p)\nEPhi = n*p # 20*.4 = 8\nVarPhi = n*p*(1-p) # 20*.4*.6 = 4.8\nsdPhi = sqrt(VarPhi) # 2.19089\n\n# Monte Carlo sample of size N\nN = 100\nPhiSamples = rbinom(N, size = n, prob = p) \n\n# Empirical approximation of posterior mean, var, sd\nPhiBar = mean(PhiSamples)\nPhiVar = var(PhiSamples)\nPhiSigma = sd(PhiSamples) # = sqrt(sum((xSamples - xbar)^2) / (N -1))\n\nse = PhiSigma / sqrt(N)\n\nlb = round(PhiBar - (2*se), 3)\nub = round(PhiBar + (2*se), 3)\n\nFor N = 100 Monte Carlo samples, The posterior mean of \\(\\phi\\) is \\(\\bar{\\phi} =\\) 8.01 with 95% confidence interval (7.57 8.45).\n\nExercise\n\n\nAbove we estimate \\(Var(\\phi)\\) to be 4.838 and the standard error for \\(N = 100\\) was 0.22.\nIf you wanted to state \\(p(\\phi \\in (\\hat{\\phi} \\pm 0.01)) = 0.95\\), how large would \\(N\\) have to be?\nCheck your answer by adjusting \\(N\\) above."
  },
  {
    "objectID": "labs/lab0.html",
    "href": "labs/lab0.html",
    "title": "Hello R.",
    "section": "",
    "text": "This ‘lab 0’ will introduce you to the course computing workflow. The main goal of today is to get you setup in RStudio and play around with a few fundamental skills."
  },
  {
    "objectID": "labs/lab0.html#r-and-r-studio",
    "href": "labs/lab0.html#r-and-r-studio",
    "title": "Hello R.",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file. Note: this is essentially the same as an Rmarkdown (.Rmd) file, with a couple built-in quality of life additions."
  },
  {
    "objectID": "labs/lab0.html#yaml",
    "href": "labs/lab0.html#yaml",
    "title": "Hello R.",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto or R markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nGo to file &gt; new file, Quarto document. Input title “Lab 0”, and change the author name to your name. Select pdf output and press Create. Render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab0.html#latex",
    "href": "labs/lab0.html#latex",
    "title": "Hello R.",
    "section": "LaTeX",
    "text": "LaTeX\nAssignments in this course are not required to be written in LaTeX. You may write equations by hand and scan them as a pdf to submit to Gradescope. However, LaTeX is the typesetting system to communicate statistics and mathematics professionally. It’s worthwhile to use. Moreover, it’s fully supported within .Rmd and .qmd files.\nIf you’re using R on your local machine, you may need to install\n\nMiKTeX (if you’re using windows): https://miktex.org/\nMacTeX (if you’re using macOS): https://www.tug.org/mactex/\nTeXLive (if you’re using linux): https://tug.org/texlive/\n\nTo write a LaTeX equation within your markdown document, simply use $$ to surround blocks of math and $ to surround in-line math.\nExample: copy and paste the following and then render.\nWe can see that $\\beta_0 = 2$ and $\\beta_1 = 3$ is the OLS solution under our model\n\n$$\ny = \\beta_0 + \\beta_1 x\n$$\n\n\n\n\n\n\nNote\n\n\n\nThere is no space between $ and math. Whitespace may cause the document to fail to render.\n\n\nCheck out this LaTeX cheatsheet to typeset a variety of math."
  },
  {
    "objectID": "labs/lab0.html#exercises",
    "href": "labs/lab0.html#exercises",
    "title": "Hello R.",
    "section": "Exercises",
    "text": "Exercises\nThe following exercises are designed to help you gain basic familiarity with R as well as the quirks of floating point arithmetic.\n\nFloating point algebra.\n\nDo floating point numbers obey the rules of algebra? For example, one of the rules of algebra is additive association. (x + y) + z == x + (y + z). Check if this is true in R using \\(x = 0.1\\), \\(y = 0.1\\) and \\(z = 1\\). Explain what you find.\n\nAdditional examples of floating point pecularity are provided below.\n\n# example 1\n0.2 == 0.6 / 3\n# example 2\npoint3 &lt;- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\npoint3 == 0.3\n\nTo work around these issues, you could use all.equal() for checking the equality of two double quantities in R. What does all.equal() do?\n\n# example 1, all.equal()\nall.equal(0.2, 0.6 / 3)\n# example 2, all.equal()\npoint3 &lt;- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\nall.equal(point3, rep(.3, length(point3)))\n\n\nWhat do these functions do?\n\nUse ?rnorm to read the documentation and explain the output of each of the following:\n\nrnorm(10, mean = 1, sd = 2)\npnorm(0)\ndnorm(0.5)\nqnorm(0.5)\n\nHow is dnorm(0.5) computed? Can you compute it manually?\n\nShow it numerically\n\n\\(X \\sim N(\\mu, \\sigma^2)\\) means that \\(X\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Show, using rnorm that if \\(X \\sim N(0, 1)\\) and \\(Y \\sim N(1, 2)\\) that \\(\\mathbb{E}(X + Y) = 1\\) and \\(\\mathbb{V}(X + Y) = 3\\)\n\nControl flow\n\n\n# for loop example\nfor (i in 1:5) {\n  cat(\"Hello\", i, \"\\n\")\n}\n\n# if else example\nx = 1\nif(x &gt; 0) {\n  print(\"I'm positive x is greater than 0.\")\n} else {\n  print(\"I'm not so positive about x being positive\")\n}\n\nAssume there are 50 days of class. Suppose that, on any given day, there is a \\(X_i\\) probability student \\(i\\) will come to class. Every day you come to class, you obtain Y points towards your final grade. Every day that you don’t come to class, you obtain Z points towards your final grade.\nAssume \\(Y \\sim Uniform(1.9, 2)\\) and \\(Z \\sim Uniform(1, 2)\\).\nAssume student A has a 95% chance of coming to class any given day (X = 0.95) and student B has a 70% of coming to class any given day (X = 0.7). While there are more efficient ways to do this, practice using a for loop, a conditional if statement, rbinom and runif to simulate one possible final grade for each student.\n\nAn example of plotting pdfs and pmfs with ggplot (loaded via the tidyverse package.)\n\n\npdf (normal)pmf (Poisson)\n\n\n\nlibrary(tidyverse)\nx = c(-3, 3) # values over which to plot\ndf = data.frame(x) # create a data frame for ggplot purposes\ndf %&gt;%\n  ggplot(aes(x = x)) +\n  stat_function(fun = dnorm, args = c(mean = 0, sd = 3)) +\n  labs(title = \"Plot of a normal(0, 9) density\", y = \"f(x)\")\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\ndf2 = data.frame(x = 0:6)\ndf2 %&gt;%\n  mutate(y2 = dpois(x, 2)) %&gt;%\n  ggplot(aes(x = x, y = y2)) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Poisson(2) mass function\", y = \"f(x)\")"
  },
  {
    "objectID": "labs/lab0.html#style-guidelines",
    "href": "labs/lab0.html#style-guidelines",
    "title": "Hello R.",
    "section": "Style guidelines",
    "text": "Style guidelines\nAlthough coding is not the primary focus of this course, there are a short list below of fundamental principles we will follow. Note: some of these stylistic principles may not be followed in the text!\nFirst, it’s easy to write code that runs off the page when you render to pdf. This happens when you write more than 80 characters in a single line of code. To ensure this doesn’t happen, make sure your code doesn’t have 80 characters in a single line. To enable a vertical line in the RStudio IDE that helps you visually see the limit, go to Tools &gt; Global Options &gt; Code &gt; Display &gt; Show margin &gt; 80. This will enable a vertical line in your .qmd files that shows you where the 80 character cutoff is for code chunks. Instructions may vary slightly for local installs of RStudio.\n\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not.\nAny and all pipes %&gt;% or |&gt; as well as ggplot layers + should be followed by a new line.\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs &lt;- and %&gt;% vs |&gt;\nYour name should be at the top (in the YAML) of each document under “author:”\n\nIf you have any questions about style, please ask a member of the teaching team."
  },
  {
    "objectID": "notes/lec04-reliability.html",
    "href": "notes/lec04-reliability.html",
    "title": "Posterior summaries and reliability",
    "section": "",
    "text": "Show packages used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec04-reliability.html#confidence-regions",
    "href": "notes/lec04-reliability.html#confidence-regions",
    "title": "Posterior summaries and reliability",
    "section": "Confidence regions",
    "text": "Confidence regions\n\nBayesian confidence interval\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has \\(100 \\times (1-\\alpha)\\%\\) posterior coverage if\n\\[\np(l(y) &lt; \\theta &lt; u(y) | y ) = (1-\\alpha)\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is \\(100 \\times (1-\\alpha)\\%\\).\nIf \\(\\alpha = 0.05\\), such an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThis is a probability statement about \\(\\theta\\)!\n\n\n\n\nFrequentist confidence interval\nContrast posterior coverage to frequentist coverage:\n\n\n\n\n\n\nDefinition\n\n\n\nA random interval \\((l(Y), u(Y)\\)) has 95% frequentist coverage for \\(\\theta\\) if before data are observed,\n\\[\np(l(Y) &lt; \\theta &lt; u(Y) | \\theta) = 0.95\n\\]\nInterpretation: if \\(Y \\sim P_\\theta\\) then the probability that \\((l(Y), u(Y)\\) will cover \\(\\theta\\) is 0.95.\n\n\nIn practice, for many applied problems\n\\[\np(l(y) &lt; \\theta &lt; u(y) | y ) \\approx p(l(Y) &lt; \\theta &lt; u(Y) | \\theta)\n\\]\nsee section 3.1.2. in the book.\n\n\nExample: posterior CI for beta-binomial\nLet \\(Y_1, \\ldots Y_n\\) be binary random variables that are conditionally independent given \\(\\theta\\) so that \\(p(y_i | \\theta) = \\theta^{y_i} (1-\\theta)^{1-y_i}\\). Let \\(\\theta \\sim beta(a, b)\\).\nRecall that \\(\\theta | y_1,\\ldots y_n \\sim beta(a + \\sum{y_i}, b + n - \\sum y_i)\\).\nTherefore, a \\((1-\\alpha)\\) confidence interval can be computed for a given \\(a, b\\) and data \\(n, \\sum y_i\\), see coded example below:\n\n\nShow code\na = 6\nb = 6\nsumY = 8\nn = 10\n\nposteriorMean = (a + sumY) / (a + b + n)\n\nalpha = 0.05\nlower_q = alpha / 2\nupper_q = 1 - (alpha / 2)\ntheta_ci_95  = qbeta(p = c(lower_q, upper_q), a + sumY, b + n - sumY)\n\n\nThe posterior mean \\(E[\\theta | y_1,\\ldots y_n] =\\) 0.64 with 95% Bayesian CI (0.43,0.82).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata.frame(theta = c(0, 1)) %&gt;%\n  ggplot(aes(x = theta)) + \n  stat_function(fun = dbeta, args = list(a + sumY, b + n - sumY)) + \n  theme_bw() +\n  labs(y = \"\") +\n  geom_area(stat = \"function\", fun = dbeta, args = list(a + sumY, b +n - sumY),\n            fill = \"steelblue\", xlim = theta_ci_95, alpha = 0.5)"
  },
  {
    "objectID": "notes/lec04-reliability.html#high-posterior-density",
    "href": "notes/lec04-reliability.html#high-posterior-density",
    "title": "Posterior summaries and reliability",
    "section": "High posterior density",
    "text": "High posterior density\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) &gt; p(\\theta_b | Y = y)\\)\n\n\n\n\nNote: all points inside an HPD region have higher posterior density than points outside the region.\nNote: the HPD region is not always an interval.\n\n\nExample: HPD for a mixture of normals"
  },
  {
    "objectID": "notes/lec04-reliability.html#laplace-approximation",
    "href": "notes/lec04-reliability.html#laplace-approximation",
    "title": "Posterior summaries and reliability",
    "section": "Laplace approximation",
    "text": "Laplace approximation\nPosterior mode: sometimes called “MAP” or “maximum a posteriori” estimate, this quantity is given by \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y)\\).\n\nNotice this unwinds to be \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(y | \\theta) p(\\theta)\\).\n\nOne way to report the reliability of the posterior mode is to look at the width of the posterior near the mode, which we can sometimes approximate with a Gaussian distribution:\n\\[\np(\\theta | y) \\approx C e^{\\frac{1}{2} \\frac{d^2L}{d\\theta^2}|_{\\hat{\\theta}} (\\theta - \\hat{\\theta})^2}\n\\] where \\(C\\) is a normalization constant and \\(L\\) is the log-posterior, \\(\\log p(\\theta | y)\\).\nTaken together, the fitted Gaussian with a mean equal to the posterior mode is called the Laplace approximation.\n\nLet’s derive the Laplace approximation offline\n\n\nExercise\n\n\nFor the beta-binomial model above, compute the Laplace approximation.\n\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nalpha = a + sumY\nbeta = b + n - sumY\n\nd2posterior = function(theta) {\n  ( (1-alpha) / (theta^2) ) - \n    ((beta - 1) / (1 - theta)^2)\n}\n\nthetaHAT = (alpha - 1) / (beta - 2 + alpha)\nsdhat = sqrt(- 1 / d2posterior(thetaHAT))\n\ndata.frame(theta = c(0, 1)) %&gt;%\n  ggplot(aes(x = theta)) + \n  stat_function(aes(color = \"posterior\"),\n                fun = dbeta, args = list(alpha, beta)) + \n  theme_bw() +\n  labs(y = \"\") +\n  stat_function(aes(color = \"Laplace approx.\"), fun = dnorm,\n                args = list(mean = thetaHAT, sd = sdhat))"
  },
  {
    "objectID": "slides/lab-conf-band.html#setup",
    "href": "slides/lab-conf-band.html#setup",
    "title": "MCMC & confidence bands",
    "section": "Setup",
    "text": "Setup\nConsider the following data generative model and priors:\n\\[\n\\begin{aligned}\nY_i | \\beta_0, \\beta_1, x_i &\\sim N(\\beta_0 + \\beta_1x_i, \\sigma^2)\\\\\n\\beta_0, \\beta_1 &\\sim \\text{ iid } N(0, 2)\\\\\n\\sigma^2 &\\sim \\text{inverse-gamma}(2, 3)\n\\end{aligned}\n\\]\nTip: load library(invgamma) to use the dinvgamma function.\n\nlibrary(tidyverse)\nlibrary(invgamma)\n\n\n# load the data\nYX = readr::read_csv(\"https://sta602-sp25.github.io/data/simulatedXY.csv\")\ny = YX$y\nx = YX$x"
  },
  {
    "objectID": "slides/lab-conf-band.html#code",
    "href": "slides/lab-conf-band.html#code",
    "title": "MCMC & confidence bands",
    "section": "Code",
    "text": "Code\nBelow is code to sample from\n\\[\np(\\beta_1, \\beta_2, \\sigma^2 | y_1, \\ldots, y_n, x_1, \\ldots, x_n)\n\\].\n\nset.seed(360)\nlogLikelihood = function(beta0, beta1, sigma2) {\n  mu = beta0 + (beta1 * x)\n  sum(dnorm(y, mu, sqrt(sigma2), log = TRUE))\n}\n\nlogPrior = function(beta0, beta1, sigma2) {\n  dnorm(beta0, 0, sqrt(2), log = TRUE) + \n    dnorm(beta1, 0, sqrt(2), log = TRUE) +\n    dinvgamma(sigma2, 2, 3, log = TRUE)\n}\n\nlogPosterior = function(beta0, beta1, sigma2) {\n  logLikelihood(beta0, beta1, sigma2) + logPrior(beta0, beta1, sigma2)\n}\n\n\nBETA0 = NULL\nBETA1 = NULL\nSIGMA2 = NULL\n\naccept1 = 0\naccept2 = 0\naccept3 = 0\n\nS = 500\n\nbeta0_s = 0.1\nbeta1_s = 10\nsigma2_s = 1\nfor (s in 1:S) {\n  \n  ## propose and update beta0\n  beta0_proposal = rnorm(1, mean = beta0_s, .5)\n   log.r = logPosterior(beta0_proposal, beta1_s, sigma2_s) - \n     logPosterior(beta0_s, beta1_s, sigma2_s)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    beta0_s = beta0_proposal\n    accept1 = accept1 + 1 \n   }\n   \n   BETA0 = c(BETA0, beta0_s)\n   \n   ## propose and update beta1\n    beta1_proposal = rnorm(1, mean = beta1_s, .5)\n   log.r = logPosterior(beta0_s, beta1_proposal, sigma2_s) - \n     logPosterior(beta0_s, beta1_s, sigma2_s)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    beta1_s = beta1_proposal\n    accept2 = accept2 + 1 \n   }\n   \n   BETA1 = c(BETA1, beta1_s)\n   \n   ## propose and update sigma2\n   ### note: sigma2 is positive only, we want to only propose positive values\n   sigma2_proposal = 1 / rgamma(1, shape = 1, sigma2_s)\n   log.r = logPosterior(beta0_s, beta1_s, sigma2_proposal) - \n     logPosterior(beta0_s, beta1_s, sigma2_s) - \n     dinvgamma(sigma2_proposal, 1, sigma2_s, log = TRUE) +\n     dinvgamma(sigma2_s, 1, sigma2_proposal, log = TRUE) \n   \n   if(log(runif(1)) &lt; log.r)  {\n    sigma2_s = sigma2_proposal\n    accept3 = accept3 + 1 \n   }\n   \n   SIGMA2 = c(SIGMA2, sigma2_s)\n   \n}"
  },
  {
    "objectID": "slides/lab-conf-band.html#exercise-1",
    "href": "slides/lab-conf-band.html#exercise-1",
    "title": "MCMC & confidence bands",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nIs a Metropolis or Metropolis-Hastings algorithm used to sample \\(\\sigma^2\\)? Hint: What is the proposal distribution used to sample \\(\\sigma^2\\)? Is it symmetric? Can you show that it is or is not symmetric in R?\nCreate a trace plot for each parameter. How many iterations does it take for \\(\\beta_1\\) to converge to the posterior? What is going on with the \\(\\sigma^2\\) trace plot?\nReport the effective sample size of each parameter, \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2\\). Hint: load the coda package and check the lecture notes."
  },
  {
    "objectID": "slides/lab-conf-band.html#exercise-2",
    "href": "slides/lab-conf-band.html#exercise-2",
    "title": "MCMC & confidence bands",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nGo back and increase the length of the chain, \\(S\\), until you obtain approximately 200 ESS for each parameter. Re-examine your plots and discuss.\nReport the posterior median and a 90% confidence interval for each unknown. Why is the median a better summary than the mean for \\(\\sigma^2\\)?"
  },
  {
    "objectID": "slides/lab-conf-band.html#exercise-3",
    "href": "slides/lab-conf-band.html#exercise-3",
    "title": "MCMC & confidence bands",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nPlot the posterior mean \\(\\theta(x)\\) vs \\(x\\) where \\(\\theta(x) \\equiv \\beta_0 + \\beta_1 x\\).\nAdditionally, plot a 95% confidence band for \\(\\theta(x)\\) vs \\(x\\) and interpret your plot."
  },
  {
    "objectID": "slides/lab-conf-band.html#solution-1-2",
    "href": "slides/lab-conf-band.html#solution-1-2",
    "title": "MCMC & confidence bands",
    "section": "Solution 1, 2",
    "text": "Solution 1, 2\n\nAlgo.Trace plots (img)Trace plots (code)ESSLonger runPost medians\n\n\nA Metropolis-Hastings algorithm. inverse-gamma proposal is asymmetric.\nShowing with R code:\n\nsigma2_proposal = 1.5\nsigma2_s = 1\ndinvgamma(sigma2_proposal, 1, sigma2_s) == \n  dinvgamma(sigma2_s, 1, sigma2_proposal)\n\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\beta_1\\) converges to the target after about 50 iterations.\nSome samples from inv-gamma are huge, the huge variance results in a flatter likelihood and still get accepted.\n\n\n\n\nlibrary(patchwork)\nparameterDF = data.frame(BETA0, BETA1, SIGMA2)\nn = nrow(parameterDF)\n\np0 = parameterDF %&gt;%\n  ggplot(aes(x = 1:n)) +\n  geom_line(aes(y = BETA0)) +\n  theme_bw() +\n  labs(x = \"iteration\", y = \"beta0\")\n\np1 = parameterDF %&gt;%\n  ggplot(aes(x = 1:n)) +\n  geom_line(aes(y = BETA1)) +\n  theme_bw() +\n  labs(x = \"iteration\", y = \"beta1\")\n\np2 = parameterDF %&gt;%\n  ggplot(aes(x = 1:n)) +\n  geom_line(aes(y = SIGMA2)) +\n  theme_bw() +\n  labs(x = \"iteration\", y = \"sigma2\")\n\np0 + p1 + p2\n\n\n\n\nlibrary(coda) \n\nparameterDF = data.frame(BETA0, BETA1, SIGMA2)\napply(parameterDF, 2, effectiveSize)\n\n   BETA0    BETA1   SIGMA2 \n19.47526 11.66309 26.31348 \n\n\n\n\n\nset.seed(360)\nlogLikelihood = function(beta0, beta1, sigma2) {\n  mu = beta0 + (beta1 * x)\n  sum(dnorm(y, mu, sqrt(sigma2), log = TRUE))\n}\n\nlogPrior = function(beta0, beta1, sigma2) {\n  dnorm(beta0, 0, sqrt(2), log = TRUE) + \n    dnorm(beta1, 0, sqrt(2), log = TRUE) +\n    dinvgamma(sigma2, 2, 3, log = TRUE)\n}\n\nlogPosterior = function(beta0, beta1, sigma2) {\n  logLikelihood(beta0, beta1, sigma2) + logPrior(beta0, beta1, sigma2)\n}\n\n\nBETA0 = NULL\nBETA1 = NULL\nSIGMA2 = NULL\n\naccept1 = 0\naccept2 = 0\naccept3 = 0\n\nS = 10000\n\nbeta0_s = 0.1\nbeta1_s = 10\nsigma2_s = 1\nfor (s in 1:S) {\n  \n  ## propose and update beta0\n  beta0_proposal = rnorm(1, mean = beta0_s, .5)\n   log.r = logPosterior(beta0_proposal, beta1_s, sigma2_s) - \n     logPosterior(beta0_s, beta1_s, sigma2_s)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    beta0_s = beta0_proposal\n    accept1 = accept1 + 1 \n   }\n   \n   BETA0 = c(BETA0, beta0_s)\n   \n   ## propose and update beta1\n    beta1_proposal = rnorm(1, mean = beta1_s, .5)\n   log.r = logPosterior(beta0_s, beta1_proposal, sigma2_s) - \n     logPosterior(beta0_s, beta1_s, sigma2_s)\n   \n   if(log(runif(1)) &lt; log.r)  {\n    beta1_s = beta1_proposal\n    accept2 = accept2 + 1 \n   }\n   \n   BETA1 = c(BETA1, beta1_s)\n   \n   ## propose and update sigma2\n   ### note: sigma2 is positive only, we want to only propose positive values\n   sigma2_proposal = 1 / rgamma(1, shape = 1, sigma2_s)\n   log.r = logPosterior(beta0_s, beta1_s, sigma2_proposal) - \n     logPosterior(beta0_s, beta1_s, sigma2_s) - \n     dinvgamma(sigma2_proposal, 1, sigma2_s, log = TRUE) + \n     dinvgamma(sigma2_s, 1, sigma2_proposal, log = TRUE) \n   \n   if(log(runif(1)) &lt; log.r)  {\n    sigma2_s = sigma2_proposal\n    accept3 = accept3 + 1 \n   }\n   \n   SIGMA2 = c(SIGMA2, sigma2_s)\n   \n}\n\nparameterDF = data.frame(BETA0, BETA1, SIGMA2)\napply(parameterDF, 2, effectiveSize)\n\n   BETA0    BETA1   SIGMA2 \n939.9746 377.1986 580.0570 \n\n\n\n\n\n\n\n\n\n\npost. median\nCI\n\n\n\n\nbeta0\n0.6\n(-0.4, 1.5)\n\n\nbeta1\n2\n(1.9, 2.1)\n\n\nsigma2\n11.6\n(7.1, 20.6)"
  },
  {
    "objectID": "slides/lab-conf-band.html#solution-3",
    "href": "slides/lab-conf-band.html#solution-3",
    "title": "MCMC & confidence bands",
    "section": "Solution 3",
    "text": "Solution 3\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\nThe red line shows our posterior expectation of \\(\\theta(x)\\) for each \\(x\\). The black bands show our 95% confidence interval \\(\\theta(x)\\).\n\n\n\nget_theta_CI = function(X) {\n     f = BETA0 + (BETA1 * X)\n     return(quantile(f, c(0.025, 0.975)))\n}\n\nget_theta_mean = function(X) {\n  f = BETA0 + (BETA1 * X)\n  return(mean(f))\n}\n\nxlo = min(x)\nxhi = max(x)\nxVal = seq(xlo, xhi, by = 0.01)\nlower = NULL\nupper = NULL\nM = NULL\n   \nfor (i in seq_along(xVal)) {\n  theta_CI = get_theta_CI(xVal[i])\n  lower = c(lower, theta_CI[[1]])\n  upper = c(upper, theta_CI[[2]])\n  M = c(M, get_theta_mean(xVal[i]))\n}\n\ndf = data.frame(xVal, lower, upper, M)\ndf %&gt;%\n  ggplot(aes(x = xVal)) +\n  geom_line(aes(y = lower)) +\n  geom_line(aes(y = upper)) +\n  geom_line(aes(y = M), col = \"red\") +\n  theme_bw() +\n  labs(y = \"theta\",\n       x = \"x\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/BayesianModelAveraging.html",
    "href": "notes/BayesianModelAveraging.html",
    "title": "Bayesian model averaging",
    "section": "",
    "text": "Consider the standard regression problem,\n\\[\nY | \\beta, \\sigma^2 \\sim N_n(X\\beta, \\sigma^2 I_n)\n\\] where each term is of typical dimension,\n\n\\(Y \\in \\mathbb{R}^n\\) vector of observations,\n\\(X \\in \\mathbb{R}^{n \\times p}\\) matrix of predictors,\n\\(\\beta \\in \\mathbb{R}^p\\) vector of coefficients,\n\\(\\sigma^2 \\in \\mathbb{R}\\), and\n\\(I_n \\in \\mathbb{R}^{n \\times n}\\).\n\nOften, when we have many covariates, i.e. \\(p\\) is large, we believe that some do not really explain \\(Y\\). A particular subset of the explanatory variables is termed a model of \\(Y\\). Since each explanatory variable belongs in the model, or does not, there are \\(K = 2^p\\) total models we can consider.\nFor notational convenience, let \\(M_1, \\ldots, M_{K}\\) be the models under study.\n\n\n\n\n\n\nImportant\n\n\n\nFor even modestly large \\(p\\), such as \\(p=64\\) in the example below, there are more possible models \\(2^{64} \\approx 1.8 \\times 10^{19}\\) than there are grains of sand on earth (about \\(7.5 \\times 10^{18}\\)).\nFor this reason, we will never be able to sample a substantial proportion of all the models.\n\n\nThere are many different questions one might answer with a regression model. Sometimes, the model itself is of interest i.e. we wish to select a single model \\(M_j\\). Other times, we may care about estimating a particular coefficient \\(\\beta_i\\) to understand how a single predictor relates to \\(Y\\). Alternatively, we may really care about making predictions for new data.\nThese tasks are not mutually exclusive, but might direct our approach differently.\nIn particular, if we are interested in prediction, or estimating a particular coefficient, then it’s important to realize that estimates such as \\(\\hat{\\beta}\\) or a function thereof, \\(\\hat{Y} = X \\hat{\\beta}\\) are implicitly conditioned on a specific model.\n\nHow can we address uncertainty in the model itself?"
  },
  {
    "objectID": "notes/BayesianModelAveraging.html#motivation",
    "href": "notes/BayesianModelAveraging.html#motivation",
    "title": "Bayesian model averaging",
    "section": "",
    "text": "Consider the standard regression problem,\n\\[\nY | \\beta, \\sigma^2 \\sim N_n(X\\beta, \\sigma^2 I_n)\n\\] where each term is of typical dimension,\n\n\\(Y \\in \\mathbb{R}^n\\) vector of observations,\n\\(X \\in \\mathbb{R}^{n \\times p}\\) matrix of predictors,\n\\(\\beta \\in \\mathbb{R}^p\\) vector of coefficients,\n\\(\\sigma^2 \\in \\mathbb{R}\\), and\n\\(I_n \\in \\mathbb{R}^{n \\times n}\\).\n\nOften, when we have many covariates, i.e. \\(p\\) is large, we believe that some do not really explain \\(Y\\). A particular subset of the explanatory variables is termed a model of \\(Y\\). Since each explanatory variable belongs in the model, or does not, there are \\(K = 2^p\\) total models we can consider.\nFor notational convenience, let \\(M_1, \\ldots, M_{K}\\) be the models under study.\n\n\n\n\n\n\nImportant\n\n\n\nFor even modestly large \\(p\\), such as \\(p=64\\) in the example below, there are more possible models \\(2^{64} \\approx 1.8 \\times 10^{19}\\) than there are grains of sand on earth (about \\(7.5 \\times 10^{18}\\)).\nFor this reason, we will never be able to sample a substantial proportion of all the models.\n\n\nThere are many different questions one might answer with a regression model. Sometimes, the model itself is of interest i.e. we wish to select a single model \\(M_j\\). Other times, we may care about estimating a particular coefficient \\(\\beta_i\\) to understand how a single predictor relates to \\(Y\\). Alternatively, we may really care about making predictions for new data.\nThese tasks are not mutually exclusive, but might direct our approach differently.\nIn particular, if we are interested in prediction, or estimating a particular coefficient, then it’s important to realize that estimates such as \\(\\hat{\\beta}\\) or a function thereof, \\(\\hat{Y} = X \\hat{\\beta}\\) are implicitly conditioned on a specific model.\n\nHow can we address uncertainty in the model itself?"
  },
  {
    "objectID": "notes/BayesianModelAveraging.html#model-averaging-setup",
    "href": "notes/BayesianModelAveraging.html#model-averaging-setup",
    "title": "Bayesian model averaging",
    "section": "Model averaging setup",
    "text": "Model averaging setup\nLet \\(z \\in \\mathbb{R}^p\\) be a vector of indicator variables \\(z_1, \\ldots, z_p\\), where \\(z_j = 1\\) means the \\(j\\)th predictor is in the model, and \\(z_j = 0\\) means it is not. Conceptually, \\(z\\) tells us which regression coefficients are non-zero.\n\\[\ny_i = z_1 \\beta_1 x_{i, 1} + \\ldots + z_p \\beta_p x_{i,p} + \\epsilon\n\\]\nwhere \\(\\epsilon \\sim N(0, \\sigma^2)\\).\nIn matrix form,\n\\[\nY|\\beta, z, \\sigma^2 \\sim N_n(XZ\\beta, \\sigma^2 I_n)\n\\]\nwhere \\(Z = z I_p\\) is a diagonal matrix.\n\n\n\n\n\n\nNote\n\n\n\nEach separate “model” \\(M\\) is equivalent to a different vector \\(z\\).\n\n\nOnce we’ve setup our likelihood to explicitly condition on the model, \\(z\\), we continue our usual Bayesian practice: we make inferences about all unknowns: \\(\\beta, \\sigma^2\\), and \\(z\\).\nNow, however we can differentiate between estimates of \\(\\beta\\) conditional on a model,\n\\[\nE[\\beta | y, z] = \\int \\beta p(\\beta | y, z) d\\beta\n\\]\nversus estimates of \\(\\beta\\) that account for model uncertainty:\n\\[\n\\begin{aligned}\nE[\\beta | y] = \\sum_{z} \\int \\beta p(\\beta, z | y) d\\beta\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/BayesianModelAveraging.html#complete-bayesian-model",
    "href": "notes/BayesianModelAveraging.html#complete-bayesian-model",
    "title": "Bayesian model averaging",
    "section": "Complete Bayesian model",
    "text": "Complete Bayesian model\n\nModelGibbs updates\n\n\nData generative model:\n\\[\nY|\\beta, z, \\sigma^2 \\sim N_n(X_z\\beta_z, \\sigma^2 I_n)\n\\] Common prior specification:\n\\[\n\\begin{aligned}\n\\beta_z | \\sigma^2 &\\sim N_z \\left(0, g \\sigma^2 (X_z^TX_z)^{-1}\\right)\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\\\\\np(z_i = 1) &= \\frac{1}{2} \\text{ for all i}\n\\end{aligned}\n\\] where \\(g\\) is some fixed constant and \\(\\beta_z\\) is the set of \\(\\beta\\) corresponding to non-zero entries of \\(z\\) (\\(X_z\\) is constructed similarly). The prior on \\(\\beta\\) is known as Zellner’s \\(g\\) prior 1. The \\(g\\) prior is mathematically convenient and leads to nice marginal distributions for our Gibbs sampler.\nWhere does the prior variance of \\(\\beta\\) come from? Recall: \\(Var[\\hat{\\beta}_{OLS}] = \\sigma^2 (X^TX)^{-1}\\). So a priori we expect the variance of \\(\\beta\\) to look like the OLS variance and \\(g\\) controls the weight of this prior variance (or \\(1/g\\) controls the weight of the precision). Small \\(g\\) implies more prior precision relative to the data.\n\nQuestion: what should \\(g\\) be equal to for unit precision?\n\n\n\n\n\nBeta\n\\[\n\\beta_z | X_z, \\sigma^2, y \\sim N_z\\left( A^{-1}b,\nA^{-1}\n\\right)\n\\] where \\(A^{-1} = \\sigma^2 \\left( \\frac{g}{g+1}\\right)(X_z^TX_z)^{-1}\\) and \\(b = \\frac{1}{\\sigma^2} X_z^Ty\\).\nWe can simplify the full conditional notation,\n\\[\n\\beta_z | X_z, \\sigma^2, y \\sim N_z\\left(\n\\left(\\frac{g}{g+1}\\right)\\hat{\\beta}_{z(OLS)},~\n\\left(\\frac{g}{g+1}\\right)  \\sigma^2 \\left[X_z^TX_z\\right]^{-1}\n\\right)\n\\]\n\n\nsigma-squared\nWe can integrate out \\(\\beta\\) analytically, for a more efficient sampler,\n\\[\n1/\\sigma^2 | X_z, y \\sim \\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR_g^z]/2)\n\\] where \\(SSR_g^z = y^T(I - \\frac{g}{g+1} X_z (X_z^T X_z)^{-1} X_z^T)y\\)\n\n\nz\n\\[\nz_j \\sim \\text{binary}(o_j/(1 + o_j))\n\\] where \\(p_j\\) is the probability that \\(z_j = 1\\), and is given by\n\\[\no_j = \\frac\n{Pr(z_j = 1 | y, X, z_{-j})}\n{Pr(z_j = 0 | y, X, z_{-j})}\n= \\frac{p(y|X, z_{-j}, z_j = 1) p(z_j = 1)}\n{p(y|X, z_{-j}, z_j = 0) p(z_j = 0)}\n\\] See page 165 of the book for details on how to compute the marginal likelihood \\(p(y|X, z)\\)."
  },
  {
    "objectID": "notes/BayesianModelAveraging.html#example-diabetes",
    "href": "notes/BayesianModelAveraging.html#example-diabetes",
    "title": "Bayesian model averaging",
    "section": "Example: Diabetes",
    "text": "Example: Diabetes\nThis example comes from Hoff Ch 9.\nThe data below contains our outcome variable, diabetes progression (first column) and 64 predictors. This example and data set appeared on a previous homework.\n\n\nload libraries\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(latex2exp)\nlibrary(coda)\n\n\n\n\ndata load and setup\nyX.diabetes.train&lt;-dget(url(\"https://sta360-fa24.github.io/data/yX.diabetes.train\"))\n\nX = yX.diabetes.train[,-1]\ny = yX.diabetes.train[,1]\n\n\n\n\nuseful functions\n# log-probability of y given x\nlpyx = function(y, X, g=length(y), \n                nu0=1, s20 = try(summary(lm(y~1+X))$sigma^2, silent = TRUE)) {\n  n=nrow(X)\n  p=ncol(X)\n  if(p==0) {\n    Hg = 0\n    s20 =mean(y^2)\n  }\n  if(p&gt;0) {\n    Hg = (g / (g + 1)) * X %*% solve(t(X) %*% X) %*% t(X)\n  }\n  \n  SSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*%y\n  -.5 *(n *log(pi) + p * log(1 + g) + (nu0 + n) * log(nu0 *s20 + SSRg)- nu0 *log(nu0 *s20)) +\n    lgamma((nu0 + n) / 2) - lgamma(nu0 / 2\n    )\n}\n\nSSR = function(y, X, g = length(y)) {\n  n=nrow(X)\n  p=ncol(X)\n  Hg = (g/(g+1)) * X %*% solve(t(X) %*% X) %*% t(X) \n  return(t(y) %*% (diag(1,nrow=n) - Hg) %*% y)\n}\n\ngetVarianceBeta = function(X, s2, g = length(y)) {\n  (g / (g+1)) * s2 * solve(t(X) %*% X)\n}\n\ngetOLS_mean = function(y, X, varBeta, g = length(y)) {\n  varBeta %*%  t(X) %*% y\n}\n\n\n\n\nMCMC\n# setup\nS = 200 # num iterations\n\n# fixed quantities\nnu0 = 1\nsigma02 = 1\nalpha_n = (nu0 + n)/2\nbeta_const = nu0 * sigma02\ng = length(y)\n# objects to fill\nZ = matrix(NA, S, p)\nBETA = matrix(NA, S, p)\nSIGMA2 = matrix(NA, S, 1)\n\n## starting values ##\nz = rep(1, ncol(X))\nlpy.c = lpyx(y , X[,z==1, drop=FALSE])\ngamma = 1\n## Gibbs sampler\nfor(s in 1:S) {\n  # update z\n  for (j in sample(1:ncol(X))) {\n    zp = z\n    zp[j] = 1 - zp[j]\n    lpy.p = lpyx(y, X[,zp==1, drop = FALSE])\n    r = (lpy.p - lpy.c) * (-1)^(zp[j]==0)\n    z[j] = rbinom(1, 1, 1 / (1+exp(-r)))\n    if(z[j] == zp[j]) {\n      lpy.c = lpy.p\n    }\n  }\n  Z[s,] = z\n  \n  ## update sigma^2\n  s2 = 1 / rgamma(1, alpha_n, (beta_const + \n                                 SSR(y, X[,z==1, drop = FALSE]))/2)\n  \n  SIGMA2[s] = s2\n  \n  ## update beta\n  \n  varBeta = getVarianceBeta(X[,z==1, drop = FALSE], s2)\n  meanBeta = getOLS_mean(y, X[,z==1, drop = FALSE], varBeta / s2)\n  \n  beta = rmvnorm(1, mean = meanBeta,\n                 sigma = varBeta)\n  BETA[s,z==1] = beta\n}\n\n\n\nProbability of regressorsDiagnosticsPosterior summaries\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrace plots\n\n\nCode\ndata.frame(sigma2 = SIGMA2[,1]) %&gt;%\n  ggplot(aes(x = 1:S)) +\n  geom_line(aes(y = sigma2)) +\n  theme_bw() +\n  labs(x = \"iteration\", y = TeX(r'($\\sigma^2$)'))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndata.frame(beta2 = BETA[,2]) %&gt;%\n  mutate_at(1, ~ replace(., is.na(.), 0)) %&gt;%\n  ggplot(aes(x = 1:S)) +\n  geom_line(aes(y = beta2)) +\n  theme_bw() +\n  labs(x = \"iteration\", y = TeX(r'($\\beta_2$)'))\n\n\n\n\n\n\n\n\n\n\n\neffective size\n\napply(Z, 2, effectiveSize)\n\n       V1        V2        V3        V4        V5        V6        V7        V8 \n200.00000 122.61862   0.00000 103.73609  46.31771  27.11704  36.39864 103.84635 \n       V9       V10       V11       V12       V13       V14       V15       V16 \n200.00000 200.00000 200.00000 131.97829 200.00000 200.00000 200.00000 105.30279 \n      V17       V18       V19       V20       V21       V22       V23       V24 \n200.00000 109.46251 200.00000 125.03977 200.00000 133.38260 141.21845 200.00000 \n      V25       V26       V27       V28       V29       V30       V31       V32 \n200.00000 200.00000  87.26784 156.01952 200.00000 200.00000 200.00000 200.00000 \n      V33       V34       V35       V36       V37       V38       V39       V40 \n200.00000 200.00000 200.00000 157.92121 200.00000 200.00000 200.00000 159.02378 \n      V41       V42       V43       V44       V45       V46       V47       V48 \n200.00000 154.07992  86.32241 200.00000 200.00000 200.00000 200.00000 124.12176 \n      V49       V50       V51       V52       V53       V54       V55       V56 \n200.00000 200.00000 200.00000 200.00000  98.08846 200.00000 200.00000 112.44715 \n      V57       V58       V59       V60       V61       V62       V63       V64 \n147.64897 200.00000 200.00000 200.00000 200.00000 117.52886 200.00000 200.00000 \n\napply(SIGMA2, 2, effectiveSize)\n\n V1 \n200 \n\n\n\n\n\n\n\nCode\nyX.diabetes.test&lt;-dget(\n  url(\"https://sta360-fa24.github.io/data/yX.diabetes.test\"))\nXtest = yX.diabetes.test[,-1]\nytest = yX.diabetes.test[,1]\n\nbetaHat = as.vector(colSums(BETA, na.rm = TRUE) / S)\nyHat = Xtest %*% betaHat\n\ndata.frame(yHat, ytest) %&gt;%\n  ggplot(aes(x = yHat, y = ytest)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  theme_bw() +\n  labs(x = TeX(r'($\\hat{y}$)'), y = \"y\")\n\n\n\n\n\n\n\n\n\nThe predictive sum of squared error is\n\nsum((yHat - ytest)^2)\n\n[1] 45.2647\n\n\nCompare this to the predictive sum of squared error from ridge regression on the homework."
  },
  {
    "objectID": "notes/BayesianModelAveraging.html#footnotes",
    "href": "notes/BayesianModelAveraging.html#footnotes",
    "title": "Bayesian model averaging",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nZellner, Arnold. “On assessing prior distributions and Bayesian regression analysis with g-prior distributions.” Bayesian inference and decision techniques (1986).↩︎"
  },
  {
    "objectID": "slides/lab8-rstan.html#download",
    "href": "slides/lab8-rstan.html#download",
    "title": "Easy Bayesian linear modeling",
    "section": "Download",
    "text": "Download\nTo download rstanarm and bayesplot run the code below\n\ninstall.packages(\"rstanarm\", \"bayesplot\")\n\nTo load the packages, run\n\nlibrary(rstanarm)\nlibrary(bayesplot)"
  },
  {
    "objectID": "slides/lab8-rstan.html#overview",
    "href": "slides/lab8-rstan.html#overview",
    "title": "Easy Bayesian linear modeling",
    "section": "Overview",
    "text": "Overview\n\nrstanarm contains a host of functions to make Bayesian linear modeling in R easy. See https://mc-stan.org/rstanarm/articles/ for a variety of tutorials.\n\npros: easy to test Bayesian linear models, can be fast (uses Hamiltonian Monte Carlo proposals)\ncons: limited in scope, e.g. requires differentiable objective and small model adjustments can be cumbersome to implement, e.g. placing a prior on variance versus standard deviation of normal model.\n\nbayesplot contains many useful plotting wrappers that work out of the box with objects created by rstanarm in an intuitive way."
  },
  {
    "objectID": "slides/lab8-rstan.html#example",
    "href": "slides/lab8-rstan.html#example",
    "title": "Easy Bayesian linear modeling",
    "section": "Example",
    "text": "Example\n\nLoad dataGlimpse data\n\n\n\nlibrary(tidyverse)\nspam = read_csv(\n  \"https://sta602-sp25.github.io/data/spam.csv\")\n\n\n\n\nglimpse(spam)\n\nRows: 4,601\nColumns: 58\n$ make              &lt;dbl&gt; 0.00, 0.21, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15…\n$ address           &lt;dbl&gt; 0.64, 0.28, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ all               &lt;dbl&gt; 0.64, 0.50, 0.71, 0.00, 0.00, 0.00, 0.00, 0.00, 0.46…\n$ num3d             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ our               &lt;dbl&gt; 0.32, 0.14, 1.23, 0.63, 0.63, 1.85, 1.92, 1.88, 0.61…\n$ over              &lt;dbl&gt; 0.00, 0.28, 0.19, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ remove            &lt;dbl&gt; 0.00, 0.21, 0.19, 0.31, 0.31, 0.00, 0.00, 0.00, 0.30…\n$ internet          &lt;dbl&gt; 0.00, 0.07, 0.12, 0.63, 0.63, 1.85, 0.00, 1.88, 0.00…\n$ order             &lt;dbl&gt; 0.00, 0.00, 0.64, 0.31, 0.31, 0.00, 0.00, 0.00, 0.92…\n$ mail              &lt;dbl&gt; 0.00, 0.94, 0.25, 0.63, 0.63, 0.00, 0.64, 0.00, 0.76…\n$ receive           &lt;dbl&gt; 0.00, 0.21, 0.38, 0.31, 0.31, 0.00, 0.96, 0.00, 0.76…\n$ will              &lt;dbl&gt; 0.64, 0.79, 0.45, 0.31, 0.31, 0.00, 1.28, 0.00, 0.92…\n$ people            &lt;dbl&gt; 0.00, 0.65, 0.12, 0.31, 0.31, 0.00, 0.00, 0.00, 0.00…\n$ report            &lt;dbl&gt; 0.00, 0.21, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ addresses         &lt;dbl&gt; 0.00, 0.14, 1.75, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ free              &lt;dbl&gt; 0.32, 0.14, 0.06, 0.31, 0.31, 0.00, 0.96, 0.00, 0.00…\n$ business          &lt;dbl&gt; 0.00, 0.07, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ email             &lt;dbl&gt; 1.29, 0.28, 1.03, 0.00, 0.00, 0.00, 0.32, 0.00, 0.15…\n$ you               &lt;dbl&gt; 1.93, 3.47, 1.36, 3.18, 3.18, 0.00, 3.85, 0.00, 1.23…\n$ credit            &lt;dbl&gt; 0.00, 0.00, 0.32, 0.00, 0.00, 0.00, 0.00, 0.00, 3.53…\n$ your              &lt;dbl&gt; 0.96, 1.59, 0.51, 0.31, 0.31, 0.00, 0.64, 0.00, 2.00…\n$ font              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num000            &lt;dbl&gt; 0.00, 0.43, 1.16, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ money             &lt;dbl&gt; 0.00, 0.43, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15…\n$ hp                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ hpl               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ george            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num650            &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ lab               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ labs              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ telnet            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num857            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ data              &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15…\n$ num415            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num85             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ technology        &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ num1999           &lt;dbl&gt; 0.00, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ parts             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pm                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ direct            &lt;dbl&gt; 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ cs                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ meeting           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ original          &lt;dbl&gt; 0.00, 0.00, 0.12, 0.00, 0.00, 0.00, 0.00, 0.00, 0.30…\n$ project           &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ re                &lt;dbl&gt; 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ edu               &lt;dbl&gt; 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ table             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ conference        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ charSemicolon     &lt;dbl&gt; 0.000, 0.000, 0.010, 0.000, 0.000, 0.000, 0.000, 0.0…\n$ charRoundbracket  &lt;dbl&gt; 0.000, 0.132, 0.143, 0.137, 0.135, 0.223, 0.054, 0.2…\n$ charSquarebracket &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.0…\n$ charExclamation   &lt;dbl&gt; 0.778, 0.372, 0.276, 0.137, 0.135, 0.000, 0.164, 0.0…\n$ charDollar        &lt;dbl&gt; 0.000, 0.180, 0.184, 0.000, 0.000, 0.000, 0.054, 0.0…\n$ charHash          &lt;dbl&gt; 0.000, 0.048, 0.010, 0.000, 0.000, 0.000, 0.000, 0.0…\n$ capitalAve        &lt;dbl&gt; 3.756, 5.114, 9.821, 3.537, 3.537, 3.000, 1.671, 2.4…\n$ capitalLong       &lt;dbl&gt; 61, 101, 485, 40, 40, 15, 4, 11, 445, 43, 6, 11, 61,…\n$ capitalTotal      &lt;dbl&gt; 278, 1028, 2259, 191, 191, 54, 112, 49, 1257, 749, 2…\n$ type              &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\n\n\nDescription\n4601 emails sent to the inbox of someone named “George” that are classified as type = 1 (spam) or 0 (non-spam). The data was collected at Hewlett-Packard labs and contains 58 variables. The first 48 variables are specific keywords and each observation is the percentage of appearance (frequency) of that word in the message. Click here to read more."
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-overview",
    "href": "slides/lab8-rstan.html#exercise-overview",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise Overview",
    "text": "Exercise Overview\nYou want to build a spam filter that blocks emails that have a high probability of being spam.\nIn statistical terms, your outcome \\(Y\\) is the type of the email (spam or not). The 57 predictors from the data set are contained in \\(x\\) and include: the frequency of certain words, the occurrence of certain symbols and the use of capital letters in each email.\nLet \\(X = \\{x_1, \\ldots, x_n\\}\\) where \\(x_i \\in \\mathbb{R}^{58}\\) (number of predictors + 1 for intercept) and \\(n =\\) the number of emails in the data set. \\(Y \\in \\mathbb{R}^n\\).\n\\[\n\\begin{aligned}\np(y_i =1 | x_i, \\beta) = \\theta_i\\\\\n\\text{logit}(\\theta_i) = X\\beta\n\\end{aligned}\n\\]\nA priori, you believe that many of the predictors included in the data set do not in fact help you predict whether the email is spam. You express your beliefs with the prior designated below:\n\nPrior on interceptPrior on the rest\n\n\nLet \\(\\beta_0\\) be the intercept term.\n\\[\n\\beta_0 \\sim Normal(0, 100)\n\\]\n\n\nFor each \\(\\beta\\) associated with the 57 predictors:\n\\[\n\\beta_i \\sim \\text{iid}~Laplace(0, .5) \\ \\ \\text{for }i \\in \\{1, 57\\}{}\n\\]"
  },
  {
    "objectID": "slides/lab8-rstan.html#standardize-the-data",
    "href": "slides/lab8-rstan.html#standardize-the-data",
    "title": "Easy Bayesian linear modeling",
    "section": "Standardize the data",
    "text": "Standardize the data\n\nStandardize dataTraining set\n\n\n\nBefore we fit our model to the data, we need to standardize the predictors (columns of \\(X\\)). Why is this important? Discuss.\n\n\n# scale functions re-scales columns of a df\nspam2 = cbind(\"type\" = spam$type, \n              scale(select(spam, -\"type\"))) %&gt;%\n  data.frame()\n\n\n\nTo validate our model we will separate it into non-overlapping sets – a training set and a testing set.\n\nset.seed(360) # ensures we get the same subset\nN = nrow(spam2)\nindices = sample(N, size = 0.8 * N)\nspam_train = spam2[indices,]\nspam_test = spam2[-indices,]\n# sanity check \nnrow(spam_train) + nrow(spam_test) == N\n\n[1] TRUE"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-1",
    "href": "slides/lab8-rstan.html#exercise-1",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 1",
    "text": "Exercise 1\nRead about how to fit Bayesian logistic regression using rstanarm here: https://mc-stan.org/rstanarm/articles/binomial.html and write code to fit the spam_train data set.\nHint: use the stan_glm function. If you set arguments chains = 1, this will run 1 Markov chain instead of the default 4. You can use the argument iter=2000 to manually set the number of iterations in your Markov chain to 2000. This may take anywhere from 1-4 minutes to run locally on your machine. If you are pressed for time, you can load the resulting object directly from the website using the code below.\n\nfit1 = readRDS(url(\"https://sta602-sp25.github.io/data/spam-train-fit.rds\"))"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-2",
    "href": "slides/lab8-rstan.html#exercise-2",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 2",
    "text": "Exercise 2\nExamining the output\n\nDid stan_glm do what we think it did? Did the Markov chain converge? Which parameters, if any, have a 90% credible interval that covers 0?\n\n\nquick lookcheck priorstrace plotsmarginal posteriorsplotting tipsget chainsummarize\n\n\nNotice sample: 1000 since half get thrown away by stan and is called “burn-in” i.e. a period that the chain spends reaching the target distribution gets discarded.\n\nsummary(fit1)\n\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      type ~ .\n algorithm:    sampling\n sample:       1000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 3680\n predictors:   58\n\nEstimates:\n                    mean   sd    10%   50%   90%\n(Intercept)        -3.9    0.5  -4.5  -3.9  -3.4\nmake               -0.1    0.1  -0.2  -0.1   0.0\naddress            -0.2    0.1  -0.4  -0.2  -0.1\nall                 0.1    0.1   0.0   0.1   0.1\nnum3d               0.9    0.7   0.2   0.7   1.7\nour                 0.4    0.1   0.3   0.4   0.5\nover                0.2    0.1   0.1   0.2   0.3\nremove              0.9    0.1   0.7   0.9   1.1\ninternet            0.2    0.1   0.1   0.2   0.3\norder               0.1    0.1   0.0   0.1   0.2\nmail                0.1    0.0   0.0   0.1   0.1\nreceive             0.0    0.1  -0.1   0.0   0.0\nwill               -0.2    0.1  -0.3  -0.2  -0.1\npeople             -0.1    0.1  -0.1   0.0   0.0\nreport              0.0    0.1  -0.1   0.0   0.1\naddresses           0.3    0.2   0.1   0.3   0.5\nfree                1.0    0.1   0.8   1.0   1.1\nbusiness            0.5    0.1   0.3   0.5   0.6\nemail               0.1    0.1   0.0   0.1   0.2\nyou                 0.1    0.1   0.0   0.1   0.2\ncredit              0.6    0.2   0.3   0.6   0.9\nyour                0.3    0.1   0.2   0.3   0.4\nfont                0.2    0.2   0.1   0.2   0.4\nnum000              0.7    0.2   0.5   0.7   0.9\nmoney               0.2    0.1   0.1   0.2   0.3\nhp                 -3.1    0.5  -3.8  -3.1  -2.5\nhpl                -1.0    0.4  -1.5  -1.0  -0.5\ngeorge             -8.5    1.8 -10.9  -8.5  -6.3\nnum650              0.2    0.1   0.1   0.2   0.4\nlab                -1.1    0.5  -1.8  -1.0  -0.5\nlabs               -0.1    0.1  -0.3  -0.1   0.0\ntelnet             -0.3    0.3  -0.8  -0.3   0.0\nnum857             -0.2    0.6  -1.0  -0.2   0.4\ndata               -0.7    0.2  -1.0  -0.7  -0.5\nnum415             -0.6    0.8  -1.7  -0.5   0.2\nnum85              -0.8    0.4  -1.3  -0.8  -0.3\ntechnology          0.4    0.1   0.2   0.4   0.6\nnum1999             0.0    0.1  -0.1   0.0   0.1\nparts              -0.2    0.1  -0.4  -0.2  -0.1\npm                 -0.4    0.2  -0.6  -0.4  -0.2\ndirect             -0.2    0.1  -0.3  -0.1   0.0\ncs                 -1.4    0.8  -2.4  -1.2  -0.5\nmeeting            -1.5    0.5  -2.2  -1.5  -1.0\noriginal           -0.4    0.2  -0.8  -0.4  -0.1\nproject            -1.3    0.4  -1.8  -1.3  -0.8\nre                 -0.7    0.2  -0.9  -0.7  -0.5\nedu                -1.5    0.3  -1.9  -1.5  -1.1\ntable              -0.3    0.1  -0.5  -0.3  -0.1\nconference         -1.1    0.4  -1.7  -1.1  -0.6\ncharSemicolon      -0.3    0.1  -0.5  -0.3  -0.2\ncharRoundbracket   -0.1    0.1  -0.2  -0.1   0.0\ncharSquarebracket  -0.1    0.1  -0.3  -0.1   0.0\ncharExclamation     0.2    0.1   0.2   0.2   0.3\ncharDollar          1.2    0.2   1.0   1.3   1.5\ncharHash            0.7    0.4   0.2   0.7   1.2\ncapitalAve          0.0    0.3  -0.3   0.0   0.4\ncapitalLong         0.9    0.4   0.4   0.8   1.3\ncapitalTotal        0.7    0.1   0.5   0.7   0.8\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.4    0.0  0.4   0.4   0.4  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                  mcse Rhat n_eff\n(Intercept)       0.0  1.0   740 \nmake              0.0  1.0  1161 \naddress           0.0  1.0  1156 \nall               0.0  1.0   907 \nnum3d             0.0  1.0   958 \nour               0.0  1.0   973 \nover              0.0  1.0  1022 \nremove            0.0  1.0   909 \ninternet          0.0  1.0  1188 \norder             0.0  1.0  1064 \nmail              0.0  1.0  1022 \nreceive           0.0  1.0  1171 \nwill              0.0  1.0  1022 \npeople            0.0  1.0  1307 \nreport            0.0  1.0   935 \naddresses         0.0  1.0  1115 \nfree              0.0  1.0   830 \nbusiness          0.0  1.0  1059 \nemail             0.0  1.0   895 \nyou               0.0  1.0  1026 \ncredit            0.0  1.0  1328 \nyour              0.0  1.0  1077 \nfont              0.0  1.0  1226 \nnum000            0.0  1.0  1124 \nmoney             0.0  1.0   910 \nhp                0.0  1.0  1161 \nhpl               0.0  1.0  1422 \ngeorge            0.1  1.0   779 \nnum650            0.0  1.0  1017 \nlab               0.0  1.0  1477 \nlabs              0.0  1.0  1317 \ntelnet            0.0  1.0  1002 \nnum857            0.0  1.0  1388 \ndata              0.0  1.0  1265 \nnum415            0.0  1.0  1427 \nnum85             0.0  1.0  1247 \ntechnology        0.0  1.0  1021 \nnum1999           0.0  1.0   834 \nparts             0.0  1.0  1227 \npm                0.0  1.0  1135 \ndirect            0.0  1.0   793 \ncs                0.0  1.0  1293 \nmeeting           0.0  1.0  1547 \noriginal          0.0  1.0  1805 \nproject           0.0  1.0  1432 \nre                0.0  1.0  1027 \nedu               0.0  1.0  1048 \ntable             0.0  1.0  1082 \nconference        0.0  1.0  1492 \ncharSemicolon     0.0  1.0  1308 \ncharRoundbracket  0.0  1.0   906 \ncharSquarebracket 0.0  1.0  1286 \ncharExclamation   0.0  1.0  1070 \ncharDollar        0.0  1.0  1147 \ncharHash          0.0  1.0  1111 \ncapitalAve        0.0  1.0  1165 \ncapitalLong       0.0  1.0  1421 \ncapitalTotal      0.0  1.0  1312 \nmean_PPD          0.0  1.0   909 \nlog-posterior     0.5  1.0   338 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\n\n\n\n\nprior_summary(fit1)\n\nPriors for model 'fit1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 0, scale = 10)\n\nCoefficients\n ~ laplace(location = [0,0,0,...], scale = [0.5,0.5,0.5,...])\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\n\n\nbetaNames = names(spam_train)[2:7]\nbetaNames\n\n[1] \"make\"    \"address\" \"all\"     \"num3d\"   \"our\"     \"over\"   \n\nmcmc_trace(fit1, pars = betaNames)\n\n\n\n\n\n\n\n\n\n\n\nbetaNames = names(spam_train)[2:7]\nbetaNames\n\n[1] \"make\"    \"address\" \"all\"     \"num3d\"   \"our\"     \"over\"   \n\nmcmc_hist(fit1, pars = c(betaNames))\n\n\n\n\n\n\n\n\n\n\nTo plot specific parameters, use the arguemnt pars, e.g.\n\nmcmc_trace(fit1, pars = c(\"internet\", \"george\")\nmcmc_hist(fit1, pars = \"make\")\n\nTo read more about bayesplot functionality, see https://mc-stan.org/bayesplot/articles/plotting-mcmc-draws.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nchain_draws = as_draws(fit1)\nchain_draws$george[1:5] # first 5 samples of the first chain run by stan\n\n[1]  -8.657706  -8.058416  -7.542682  -5.875524 -10.805427\n\n\n\ntry the following command: View(chain_draws)\n\n\n\nReport posterior mean, posterior median and 90% posterior CI.\n\nposteriorMean = apply(chain_draws, 2, mean)\nposteriorMedian = fit1$coefficients\nposteriorCI = posterior_interval(fit1, prob = 0.9)\ncbind(posteriorMean, posteriorMedian, posteriorCI)\n\n                  posteriorMean posteriorMedian            5%          95%\n(Intercept)         -3.92819676     -3.89842329  -4.688486640 -3.214996079\nmake                -0.10511093     -0.10291579  -0.234925630  0.007473911\naddress             -0.23994990     -0.22496984  -0.459838123 -0.079085239\nall                  0.06181680      0.06204777  -0.032348802  0.162371165\nnum3d                0.86239227      0.69068831   0.094477008  2.262920466\nour                  0.36326097      0.36517847   0.252660614  0.482222431\nover                 0.22388788      0.22526813   0.104903413  0.345376589\nremove               0.89046939      0.88519560   0.660560624  1.124715173\ninternet             0.19219955      0.18873972   0.084482068  0.313373050\norder                0.14088547      0.14175852   0.022540540  0.262790934\nmail                 0.07091792      0.07049483  -0.004812217  0.148380741\nreceive             -0.04641076     -0.04704090  -0.155648064  0.056349226\nwill                -0.19669579     -0.19506749  -0.323302246 -0.079179801\npeople              -0.05080340     -0.04939546  -0.170276558  0.067469609\nreport              -0.01152332     -0.01105396  -0.102076144  0.078218538\naddresses            0.27381609      0.26410052   0.016663808  0.554382803\nfree                 0.95909363      0.95496752   0.738679361  1.184988932\nbusiness             0.46684266      0.46497563   0.276894271  0.663670058\nemail                0.10488455      0.10024984   0.001909845  0.222419640\nyou                  0.10146793      0.10210904  -0.005066755  0.212057793\ncredit               0.60260737      0.58770051   0.245466733  1.011651069\nyour                 0.29510195      0.29496631   0.185160138  0.408134909\nfont                 0.23712284      0.22816521   0.014405002  0.514370136\nnum000               0.71052738      0.69647322   0.470113449  0.973663603\nmoney                0.20621767      0.19864778   0.101091758  0.340661983\nhp                  -3.12311740     -3.10880324  -4.016671505 -2.304686191\nhpl                 -1.03485238     -1.03298227  -1.697441864 -0.401214421\ngeorge              -8.54020532     -8.47338329 -11.651960267 -5.719147532\nnum650               0.23079106      0.22722517   0.066179720  0.417323354\nlab                 -1.06217022     -0.98480464  -2.007243002 -0.334531315\nlabs                -0.12552567     -0.11162875  -0.398538494  0.091786582\ntelnet              -0.34336793     -0.26439840  -0.971412117  0.026123689\nnum857              -0.24559769     -0.15437261  -1.410789083  0.608907729\ndata                -0.73133589     -0.71699338  -1.108487928 -0.382954624\nnum415              -0.64101304     -0.47534569  -2.093090996  0.285482781\nnum85               -0.79569146     -0.76847847  -1.439452875 -0.215331103\ntechnology           0.39271940      0.38676108   0.173703662  0.625821033\nnum1999             -0.01626319     -0.01501346  -0.146351106  0.113311375\nparts               -0.19387536     -0.17594695  -0.420298806 -0.034525634\npm                  -0.36307678     -0.35286882  -0.654982493 -0.099008434\ndirect              -0.16079193     -0.14842066  -0.405108058  0.023707001\ncs                  -1.35347826     -1.21771081  -2.748096259 -0.377142268\nmeeting             -1.54394154     -1.48634297  -2.451147222 -0.853955898\noriginal            -0.44492327     -0.43068267  -0.889558420 -0.068304526\nproject             -1.27091449     -1.25700373  -1.901896255 -0.691331691\nre                  -0.68897480     -0.68667471  -0.941480034 -0.439694059\nedu                 -1.52342346     -1.51146322  -2.056088445 -1.041884151\ntable               -0.27888780     -0.25736694  -0.549891396 -0.077155657\nconference          -1.10733935     -1.06265166  -1.864536810 -0.460671052\ncharSemicolon       -0.32588657     -0.31416332  -0.514101364 -0.166688438\ncharRoundbracket    -0.08698799     -0.08292353  -0.212643020  0.023441788\ncharSquarebracket   -0.14980893     -0.13280261  -0.342135625 -0.004178006\ncharExclamation      0.23238206      0.22752584   0.137507390  0.351658871\ncharDollar           1.24928427      1.25351495   0.944702156  1.558125382\ncharHash             0.71795213      0.70213467   0.122922001  1.368832748\ncapitalAve          -0.01033156     -0.03262611  -0.401092859  0.470713740\ncapitalLong          0.85197631      0.82214223   0.303300262  1.493571408\ncapitalTotal         0.67337732      0.67245181   0.471182694  0.893198052"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-3",
    "href": "slides/lab8-rstan.html#exercise-3",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nTest your spam filter on the spam_test data set.\nMake a table showing correct and incorrect number of classifications."
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-1-solution",
    "href": "slides/lab8-rstan.html#exercise-1-solution",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 1 solution",
    "text": "Exercise 1 solution\n\nfit1 = stan_glm(type ~ ., data = spam_train,\n                 family = binomial(link = \"logit\"),\n                 prior = laplace(0, 0.5),\n                 prior_intercept = normal(0, 10),\n                 cores = 2, seed = 360,\n                chains = 1, iter = 2000)"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-2-solution",
    "href": "slides/lab8-rstan.html#exercise-2-solution",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 2 Solution",
    "text": "Exercise 2 Solution\n\nTrace plots look good, can look through more by subsetting others.\nESS is high\n\n\nwhich(sign(posteriorCI[,1]) != sign(posteriorCI[,2]))\n\n            make              all             mail          receive \n               2                4               11               12 \n          people           report              you             labs \n              14               15               20               31 \n          telnet           num857           num415          num1999 \n              32               33               35               38 \n          direct charRoundbracket       capitalAve \n              41               51               56"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-3-solution",
    "href": "slides/lab8-rstan.html#exercise-3-solution",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise 3 Solution",
    "text": "Exercise 3 Solution\n\n\ndata.frame(y = spam_test$type, \n           yhat = predict(object = fit1, newdata = spam_test[,-1], type = \"response\")) %&gt;%\n  mutate(yhat = ifelse(yhat &gt;= 0.5, 1, 0)) %&gt;%\n  count(y, yhat)\n\n  y yhat   n\n1 0    0 529\n2 0    1  26\n3 1    0  31\n4 1    1 335\n\n\n856/921 classifications correct with a cutoff of 0.5.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html",
    "href": "notes/lec08-Metropolis-algorithm.html",
    "title": "Metropolis Algorithm",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(patchwork)\nlibrary(tidymodels)\nlibrary(mvtnorm)\nlibrary(coda)\nlibrary(animation)"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#the-bayesian-statistical-procedure",
    "href": "notes/lec08-Metropolis-algorithm.html#the-bayesian-statistical-procedure",
    "title": "Metropolis Algorithm",
    "section": "The Bayesian statistical procedure",
    "text": "The Bayesian statistical procedure\n\nWe setup a data generative model, \\(p(y | \\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots \\theta_n\\}\\).\nNext, we choose a prior distribution for the unknown model parameters \\(p(\\boldsymbol{\\theta})\\).\nWe wish to make inferences using the data we collect \\(\\boldsymbol{y} = \\{y_1,\\ldots y_n\\}\\). All inferences we make require the posterior \\(p(\\boldsymbol{\\theta}| \\boldsymbol{y})\\), which we obtain from the data generative model and the prior via Bayes’ rule.\n\nIn general, the inferences we wish to make, e.g. \\(p(g(\\boldsymbol{\\theta}) \\in A |~\\boldsymbol{y})\\), are complicated or impossible to compute analytically. Here, Monte Carlo approximation helps. The key idea is that we sample from the posterior and then use the samples an an empirical approximation to make inference.\nQuestion: What do we do when we can’t sample directly from the posterior?"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#example-sparrows",
    "href": "notes/lec08-Metropolis-algorithm.html#example-sparrows",
    "title": "Metropolis Algorithm",
    "section": "Example: Sparrows",
    "text": "Example: Sparrows\nIdea: the number of fledglings a sparrow has in a mating season depends on the age of the sparrow.\nLet \\(Y\\) be the number of fledglings (offspring) of a sparrow.\nLet \\(X\\) be the age of the sparrow.\nLet \\(Y|X\\) be conditionally iid.\n\nStep 1: data generative model\n\nExercise 1.1Solution (1.1)\n\n\nWrite down a data generative model for the data.\n\n\n\\[\nY | X \\sim Poisson(\\theta_x)\n\\]\nwhere \\(\\theta_x\\) is the age-specific expected number of off-spring. Note that \\(Y \\in \\{0, 1, 2, \\ldots\\}\\).\n\n\n\n\nExercise 1.2Poor solutionFalse solutionSolution (1.2)\n\n\nHow can we specify \\(\\theta_x\\)?\n\n\nLet each \\(\\theta_i\\) be unique and specific to age \\(i\\) of the sparrow.\nProblem: if we don’t collect much data on sparrows of a certain age \\(i\\), then our estimates for \\(\\theta_i\\) will be poor.\n\n\nLet \\(\\theta_x = f(x) = \\beta_1 + \\beta_2 x + \\beta_3 x^2\\).\nHere we have a way of relating ages to the expected number of fledglings and admit an \\(x^2\\) term to model the fact that the relationship between number of fledglings and age may not be a linear function of age.\nProblem: \\(\\theta_x\\) must be positive! The equation above can evaluate to negative values.\n\n\nLog-transform!\n\\(\\log \\mathbb{E}~Y|X = \\log \\theta_x = \\beta_1 + \\beta_2 x + \\beta_3 x^2\\)\nIn other words,\n\\(\\theta_x = e^{\\beta_1 + \\beta_2x + \\beta_3 x^2}\\) &gt; 0\n\n\n\nSome terminology that will be useful in the future: \\(Y|X \\sim Poisson(e^{\\beta^T \\mathbf{x}})\\) is “Poisson regression”. Where \\(\\beta^T \\mathbf{x} = \\beta_1 + \\beta_2 x + \\beta_2 x^2\\).\n\\(\\beta^T \\mathbf{x}\\) is called the “linear predictor”.\n\nExercise 1.3Solution (1.3)\n\n\nWrite down \\(p(y_1,\\ldots y_n | x_1, \\ldots, x_n, \\beta_1, \\beta_2, \\beta_3)\\).\n\n\n\\[\n\\begin{aligned}\np(y_1,\\ldots y_n | x_1, \\ldots, x_n, \\beta_1, \\beta_2, \\beta_3) &= \\prod_{i = 1}^n p(y_i|x_i, \\beta_1, \\beta_2, \\beta_3) \\text{ by conditionally iid}\\\\\n&= \\prod_{i=1}^n \\theta_{x_i}^{y_i} e^{- \\theta_{x_i}}\\frac{1}{y_i!}\\\\\n&= \\prod_{i=1}^n e^{(\\beta^T \\mathbf{x}_i) y_i - e^{(\\beta^T \\mathbf{x}_i)}} \\frac{1}{y_i!}\\\\\n&= e^{\\sum_{i=1}^n \\left[(\\beta^T \\mathbf{x}_i) y_i - e^{(\\beta^T \\mathbf{x}_i)} \\right]} \\cdot\n\\prod_{i=1}^n \\frac{1}{y_i!}\n\\end{aligned}\n\\]\n\n\n\n\n\nStep 2: prior\n\nExercise 2.1Solution (2.1)\n\n\nWhat’s unknown?\n\n\n\\[\n\\beta_1, \\beta_2, \\beta_3\n\\]\n\n\n\n\nExercise 2.2Solution (2.2)\n\n\nWrite down a prior distribution for the unknowns\n\n\nOne possible prior: independent normals on each \\(\\beta_i\\).\n\\[\n\\begin{aligned}\n\\beta_i &\\sim N(0, 10)\\\\\np(\\beta_1, \\beta_2, \\beta_3) &= \\text{dnorm}(\\beta_1; 0, \\sqrt{10}) \\cdot \\text{dnorm}(\\beta_2; 0, \\sqrt{10}) \\cdot \\text{dnorm}(\\beta_3; 0, \\sqrt{10})\n\\end{aligned}\n\\]\n\n\n\n\n\nStep 3: posterior sampling\nThe posterior, given by\n\\[\np(\\beta_1, \\beta_2, \\beta_3 | y_1,\\ldots, y_n, x_1,\\ldots, x_n) =\n\\frac{p(\\beta_1, \\beta_2,\\beta_3) p(y_1,\\ldots y_n | x_1, \\ldots, x_n, \\beta_1, \\beta_2, \\beta_3)}{\n\\int \\int \\int p(\\beta_1, \\beta_2,\\beta_3) p(y_1,\\ldots y_n | x_1, \\ldots, x_n, \\beta_1, \\beta_2, \\beta_3)~d\\beta_1 d\\beta_2 d\\beta_3\n}\n\\]\nis too complicated to write down a closed form expression for due to the denominator “\\(p(y)\\)”.\nOur goal: generate a series of dependent samples from the posterior as an empirical approximation to make inference.\nThe Metropolis algorithm is one of many methods (but not the only method) to construct a Markov chain comprised of dependent samples from the target distribution.\nMore broadly, constructing a Markov chain of dependent samples and using these samples to approximate the target distribution is called Markov chain Monte Carlo (MCMC).\n\nMarkov chainMarkov propertyExample\n\n\nDefinition: a sequence of random variables \\(\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots\\) satisfying the “Markov property”.\n\n\n\\[\np(\\theta^{(s+1)}| \\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{(s)}) = p(\\theta^{(s+1)}| \\theta^{(s)})\n\\]\nFor all states \\(s\\).\nThis is also called the “memoryless property”. In other words, “What happens next depends only on the state of affairs now”.\n\n\n\nset.seed(360)\nS = 10\ntheta_s = 0 # starting point for the Markov chain\nTHETA = NULL\nfor(i in 1:S) {\n  THETA = c(THETA, theta_s)\n  theta_s = rnorm(1, theta_s, 3)\n}\nTHETA\n\n [1]  0.0000000  4.3124838  5.2802035  4.6673136  1.6700287  1.5575283\n [7] -0.6967649 -2.6485497 -3.1040911 -5.6181892\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nMCMC sampling algorithms are not models. They do not generate more information than is in the data and the prior. They are simply ways of “looking at” the posterior."
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#metropolis-algorithm",
    "href": "notes/lec08-Metropolis-algorithm.html#metropolis-algorithm",
    "title": "Metropolis Algorithm",
    "section": "Metropolis Algorithm",
    "text": "Metropolis Algorithm\n\n\n\n\n\n\n\n\\(\\theta\\)\nVector of unknown parameters.\n\n\n\\(\\theta^{(s)}\\)\nCurrent state of \\(\\theta\\) in the Markov chain.\n\n\n\\(J(\\theta | \\theta^{(s)})\\)\nProposal distribution. Note: for this to be a “Metropolis algorithm”, J needs to be symmetric, i.e. \\(J(\\theta_a | \\theta_b) = J(\\theta_b | \\theta_a)\\) for all \\(\\{\\theta_a, \\theta_b\\}\\).\n\n\n\\(\\pi(\\theta)\\)\nTarget distribution that we wish to sample from (in our cases, this is the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\)).\n\n\n\nThe Metropolis algorithm proceeds:\n\nSample \\(\\theta^* | \\theta^{(s)} \\sim J(\\theta | \\theta^{(s)})\\)\nCompute the acceptance ratio \\(r = \\frac{\\pi(\\theta^*)}{\\pi(\\theta^{(s)})}\\)\nLet \\[\n\\theta^{(s+1)} =\n\\begin{cases}\n\\theta^* \\text{ with probability } \\min(r, 1)\\\\\n\\theta^{(s)} \\text{ with probability } 1 - \\min(r, 1)\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nBig idea\n\n\n\n\nOur target distribution, \\(\\pi(\\theta)\\), is the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\). So the acceptance ratio in the algorithm is a ratio of posteriors.\nWhen we evaluate the ratio of posteriors at different \\(\\theta\\), the high dimensional integral in the denominator of the posterior, \\(p(y_1,\\ldots,y_n)\\), cancels out! We don’t have to compute it!"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#finishing-step-3",
    "href": "notes/lec08-Metropolis-algorithm.html#finishing-step-3",
    "title": "Metropolis Algorithm",
    "section": "Finishing step (3)",
    "text": "Finishing step (3)\nThe fledglings of female song sparrows. To begin, let’s load the data.\n\n\nLoad the data\nyX = structure(c(3, 1, 1, 2, 0, 0, 6, 3, 4, 2, 1, 6, 2, 3, 3, 4, 7, \n2, 2, 1, 1, 3, 5, 5, 0, 2, 1, 2, 6, 6, 2, 2, 0, 2, 4, 1, 2, 5, \n1, 2, 1, 0, 0, 2, 4, 2, 2, 2, 2, 0, 3, 2, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, \n2, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, \n5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 6, 1, 1, 9, 9, 1, 1, 1, 1, 1, 1, \n1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 25, 16, 16, 16, 16, 16, \n16, 16, 16, 16, 16, 16, 16, 25, 16, 16, 16, 16, 25, 25, 25, 25, \n9, 9, 9, 9, 9, 9, 9, 36, 1, 1), .Dim = c(52L, 4L), .Dimnames = list(\n    NULL, c(\"fledged\", \"intercept\", \"age\", \"age2\")))\n\n\n\nyX %&gt;%\n  head(n = 5)\n\n     fledged intercept age age2\n[1,]       3         1   3    9\n[2,]       1         1   3    9\n[3,]       1         1   1    1\n[4,]       2         1   1    1\n[5,]       0         1   1    1\n\ny = yX[,1]\nX = yX[,-1]\n\nThe model:\n\\[\n\\begin{aligned}\nY | X &\\sim \\text{Poisson}(\\exp[ \\beta^T \\boldsymbol{x}])\\\\\n\\beta &\\sim MVN(0, \\sqrt{10})\n\\end{aligned}\n\\]\nThe Metropolis algorithm with\n\\[\nJ(\\beta | \\beta^{(s)}) = MVN(\\beta^{(s)}, \\hat{\\sigma}^2(X^TX)^{-1})\n\\]\nwhere \\(\\hat{\\sigma}^2\\) is the sample variance of \\(\\{\\log(y_1 + 1/2), \\ldots, \\log(y_n + 1/2)\\}\\).\n\n\n\n\n\n\nNote\n\n\n\n\nThis variance is intuitively useful choice for \\(\\delta\\) since the posterior variance would be \\(\\sigma^2 (X^TX)^{-1}\\) in a normal regression problem.\nWe use \\(\\log(y + 1/2)\\) instead of \\(\\log y\\) because if \\(y=0\\), \\(\\log y\\) would be \\(-\\infty\\).\n\n\n\n\nset.seed(360)\nn = length(y)\np = ncol(X)\n\npmn.beta = rep(0, p) # prior mean beta\npsd.beta = rep(10, p) # prior sd beta\n\nvar.prop = var(log(y + 1/2)) * solve(t(X) %*% X) # proposal variance\n\nS = 10000\nbeta = rep(0, p); accepts = 0\nBETA = matrix(0, nrow = S, ncol = p)\nset.seed(1)\n\nfor (s in 1:S) {\n  # multivariate proposal of beta\n  beta.p = t(rmvnorm(1, beta, var.prop))\n  \n  # log ratio\n  lhr = sum(dpois(y, exp(X %*%beta.p), log = TRUE)) -\n    sum(dpois(y, exp(X %*% beta), log = TRUE)) + \n    sum(dnorm(beta.p, pmn.beta, psd.beta, log = TRUE)) -\n    sum(dnorm(beta, pmn.beta, psd.beta, log = TRUE)) \n  \n  if (log(runif(1)) &lt; lhr) {\n    beta = beta.p ; accepts = accepts + 1\n  }\n  \n  BETA[s,] = beta\n}\n\nThe acceptance ratio is 0.428\nLet’s examine convergence.\n\ntrace plotsplot codeESSacf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalue = c(BETA[,1], BETA[,2], BETA[,3])\nn = length(value)\nbeta = c(rep(\"beta1\", n/3), rep(\"beta2\", n/3), rep(\"beta3\", n/3))\ndf = data.frame(value = value,\n                beta = beta) \n\ndf %&gt;%\n  ggplot(aes(x = 1:nrow(df), y = value)) + \n  geom_line() + \n  facet_wrap(~ beta, scales = \"free_x\") +\n  theme_bw() +\n  labs(x = \"iteration\")\n\n\n\n\n# effective sample size\nBETA %&gt;%\n  apply(2, effectiveSize)\n\n[1] 867.4750 825.6214 692.0495\n\n\n\n\n\npar(mfrow=c(1,3))\nacf(BETA[,1])\nacf(BETA[,2])\nacf(BETA[,3])"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#another-example",
    "href": "notes/lec08-Metropolis-algorithm.html#another-example",
    "title": "Metropolis Algorithm",
    "section": "Another example",
    "text": "Another example\nLet \\(\\pi(\\theta) = \\text{dnorm}(\\theta, 10, 1)\\) and let \\(J(\\theta | \\theta^{(s)}) = \\text{normal}(\\theta^{(s)},\\delta^2)\\).\nWe have to choose \\(\\delta\\). How should we choose it? Let’s gain some intuition by trying out three different values of \\(\\delta\\).\n\nset.seed(360)\ntheta_s = 0 # starting point\nTHETA = NULL # empty object to save iterations in\nS = 10000 # number of iterations\ndelta = 1 # proposal sd\naccept = 0 # keep track of acceptance rate\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ### generate proposal and compute ratio r ###\n  theta_proposal = rnorm(1, mean = theta_s, sd = delta) \n  log.r = dnorm(theta_proposal, mean = 10, sd = 1, log = TRUE) - \n    dnorm(theta_s, mean = 10, sd = 1, log = TRUE)\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) &lt; log.r)  {\n    theta_s = theta_proposal\n    accept = accept + 1 \n  }\n  THETA = c(THETA, theta_s)\n}\n\nLet’s look at how various \\(\\delta\\) let us sample the target:\n\n\\(\\delta = 0.1\\)\\(\\delta = 1\\)\\(\\delta = 4\\)\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s look at the trace plots for each \\(\\delta\\).\n\n\n\n\n\n\n\n\n\n\n\n\nAcceptance rate for each delta\n\n\n0.1\n1\n4\n\n\n\n\n0.96\n0.7\n0.29"
  },
  {
    "objectID": "notes/lec08-Metropolis-algorithm.html#the-blind-monkey-on-an-island",
    "href": "notes/lec08-Metropolis-algorithm.html#the-blind-monkey-on-an-island",
    "title": "Metropolis Algorithm",
    "section": "The blind monkey on an island",
    "text": "The blind monkey on an island"
  },
  {
    "objectID": "quizzes/quiz03.html",
    "href": "quizzes/quiz03.html",
    "title": "Quiz 3",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nWrite “posterior” or “prior” in the blank below:\n\\(\\int p(\\tilde{y}|\\theta) p(\\theta | y_1,\\ldots y_n)d\\theta\\) is a ___ predictive distribution.\n\n\nExercise 2\nAssume \\(Y | \\theta \\sim \\text{Poisson}(\\theta)\\) and \\(\\theta\\) has some prior distribution \\(p(\\theta)\\) with positive finite mean and variance.\nWrite \\(&gt;\\), \\(&lt;\\) or \\(=\\) in the blank below:\n\\(Var[Y]\\) ____ \\(Var[\\theta]\\).\n\n\nExercise 3\nThe vertical line on the following plot is best described as the posterior ____.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "quizzes/quiz07.html",
    "href": "quizzes/quiz07.html",
    "title": "Quiz 7",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nLet \\(\\hat{\\theta}\\) be an estimator of \\(\\theta\\). What does it mean for \\(\\hat{\\theta}\\) to be unbiased?\n\n\nExercise 2\nTRUE or FALSE: Bayes factors do not depend on priors.\n\n\nExercise 3\nTRUE or FALSE: \\(\\theta \\sim N(\\bar{y}, 1)\\) is a proper prior.\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "quizzes/quiz04.html",
    "href": "quizzes/quiz04.html",
    "title": "Quiz 4",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nTRUE or FALSE: for any valid proposal distribution J, \\(J(\\theta^* | \\theta^{(1)}, \\ldots, \\theta^{(s)}) = J(\\theta^* | \\theta^{(s)})\\).\n\n\nExercise 2\nTRUE or FALSE: the Metropolis algorithm requires symmetric proposal \\(J(\\theta^* | \\theta^{(s)})\\).\n\n\nExercise 3\nSuppose you are sampling \\(\\theta\\) from some target distribution \\(\\pi(\\theta)\\) using the Metropolis algorithm. Write the probability of accepting a new state \\(\\theta^{*}\\) given that the current state of the chain is \\(\\theta^{(s)}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "quizzes/quiz02.html",
    "href": "quizzes/quiz02.html",
    "title": "Quiz 2",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nTRUE or FALSE: this is a 95% Bayesian confidence interval:\n\\[\np(l(y) &lt; \\theta &lt; u(y) | y) = 0.95\n\\]\n\n\nExercise 2\nWrite “equals” or “does not equal” in the blank below:\nIf\n\\[\nY | \\theta \\sim \\text{binomial}(n, \\theta),\n\\] then \\(\\hat{\\theta}_{MLE}\\) ___ \\(\\hat{\\theta}_{MAP}\\) when \\(\\theta \\sim \\text{beta}(1, 1)\\).\n\n\nExercise 3\nTRUE or FALSE: high posterior density regions are always intervals.\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "quizzes/quiz06.html",
    "href": "quizzes/quiz06.html",
    "title": "Quiz 5",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nLet \\(\\mathbf{y} =  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\n  \\end{array} } \\right]\\), \\(\\boldsymbol{\\theta} =  \\left[ {\\begin{array}{cc}\n   4 \\\\\n   8\n  \\end{array} } \\right]\\), \\(\\Sigma =  \\left[ {\\begin{array}{cc}\n   1 & .2 \\\\\n   .2 & 1.3\\\\\n  \\end{array} } \\right]\\).\nIf \\(\\mathbf{y} | \\boldsymbol{\\theta}, \\Sigma \\sim MVN(\\boldsymbol{\\theta}, \\Sigma)\\), then \\(y_1 \\sim N(a, b)\\). What is \\(a\\) and \\(b\\)?\n\n\nExercise 2\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(\\mathbf{x}^T \\Sigma \\mathbf{x}\\)?\n\n\nExercise 3\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(Var[\\mathbf{x}]\\)?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "quizzes/quiz05.html",
    "href": "quizzes/quiz05.html",
    "title": "Quiz 5",
    "section": "",
    "text": "To receive credit for this assignment, write your full name at the top of your paper.\n\nExercise 1\nLet \\(\\mathbf{y} =  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\n  \\end{array} } \\right]\\), \\(\\boldsymbol{\\theta} =  \\left[ {\\begin{array}{cc}\n   4 \\\\\n   8\n  \\end{array} } \\right]\\), \\(\\Sigma =  \\left[ {\\begin{array}{cc}\n   1 & .2 \\\\\n   .2 & 1.3\\\\\n  \\end{array} } \\right]\\).\nIf \\(\\mathbf{y} | \\boldsymbol{\\theta}, \\Sigma \\sim MVN(\\boldsymbol{\\theta}, \\Sigma)\\), then \\(y_1 \\sim N(a, b)\\). What is \\(a\\) and \\(b\\)?\n\n\nExercise 2\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(\\mathbf{x}^T \\Sigma \\mathbf{x}\\)?\n\n\nExercise 3\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(Var[\\mathbf{x}]\\)?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-normal.html#exercise",
    "href": "slides/lab-normal.html#exercise",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise",
    "text": "Exercise\nLibraries used:\n\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "slides/lab-normal.html#exercise-1-estimators",
    "href": "slides/lab-normal.html#exercise-1-estimators",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise 1: estimators",
    "text": "Exercise 1: estimators\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\)."
  },
  {
    "objectID": "slides/lab-normal.html#exercise-2-estimators",
    "href": "slides/lab-normal.html#exercise-2-estimators",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise 2: estimators",
    "text": "Exercise 2: estimators\n\\[\n\\begin{aligned}\nY_1, \\ldots, Y_n &\\sim \\text{ i.i.d. binary}(\\theta)\\\\\n\\theta &\\sim \\text{beta}(a, b)\n\\end{aligned}\n\\]\n\nCompute \\(\\hat{\\theta}_{MLE}\\)\nCompute \\(\\hat{\\theta}_{B} = E[\\theta | y_1,\\ldots y_n]\\).\nCompare \\(MSE(\\hat{\\theta}_{MLE})\\) to \\(MSE(\\hat{\\theta}_{B})\\)). Under what conditions is the MSE of \\(\\hat{\\theta}_B\\) smaller?"
  },
  {
    "objectID": "slides/lab-normal.html#exercises",
    "href": "slides/lab-normal.html#exercises",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "slides/lab-normal.html#solution-1",
    "href": "slides/lab-normal.html#solution-1",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution 1",
    "text": "Solution 1\nLet \\(\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\).\n\\[\n\\begin{aligned}\nBias(\\hat{\\sigma}^2 | \\sigma^2 = \\sigma_0^2) &= E[\\hat{\\sigma}^2|\\sigma_0^2] - \\sigma_0^2\\\\\n&=  - \\sigma_0^2 + \\frac{1}{n} \\sum_{i = 1}^n E[(Y_i -\\bar{Y})^2|\\sigma_0^2]\\\\\n&= - \\sigma_0^2 + \\frac{1}{n} \\sum_{i=1}^n \\left[\nE[Y_i^2 |\\sigma_0^2] - 2E[Y_i \\bar{Y}|\\sigma_0^2] + E[\\bar{Y}^2 | \\sigma_0^2]\n\\right]\n\\end{aligned}\n\\]\nRecall that for any random variable X, \\(Var(X) = E[X^2] - E[X]^2\\). Using this fact, we continue our proof above:\n\\[\n\\begin{aligned}\n&= -\\sigma_0^2 +(\\sigma_0^2  + \\theta^2)\n-2 \\frac{1}{n} \\sum_{i=1}^n \\left[  E~\\left(Y_i \\frac{1}{n}\\sum_j Y_j\\right) | \\sigma_0^2    \\right]\n+ \\left(\\frac{\\sigma_0^2}{n} + \\theta^2\\right)\\\\\n&= 2\\theta^2 + \\frac{\\sigma_0^2}{n} - \\frac{2}{n}\n\\left(n\\theta^2  - \\sigma_0^2\n\\right)\\\\\n&= \\frac{(n-1)\\sigma_0^2}{n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab-normal.html#solution-2",
    "href": "slides/lab-normal.html#solution-2",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution 2",
    "text": "Solution 2\n\\[\n\\begin{aligned}\n\\hat{\\theta}_{MLE} &= \\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i\\\\\n\\hat{\\theta}_B &= \\frac{n\\bar{y}+a}{n+a+b} =\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}_{MLE}|\\theta) &= \\frac{\\theta(1-\\theta)}{n}\\\\\nMSE(\\hat{\\theta}_B|\\theta) &= \\frac{n}{n + a + b}\\bar{Y} + \\frac{a + b}{n + a + b} \\frac{a}{a + b} =  w \\bar{Y} + (1-w)\\frac{a}{a+b}\\\\\n&= w^2Var(\\bar{Y} | \\theta) +  (1-w)^2 \\left(\\frac{a}{a+b} - \\theta\\right)^2\\\\\n&= {w^2} \\frac{\\theta(1-\\theta)}{n} + (1-w)^2  \\left(\\frac{a}{a+b} - \\theta\\right)^2\n\\end{aligned}\n\\] For the Bayesian estimator to have smaller MSE than the MLE, we need\n\\[\n\\begin{aligned}\n\\left(\\frac{a}{a+b} - \\theta\\right)^2 &\\leq \\frac{\\theta(1 - \\theta)}{n} \\frac{1 + w}{1 - w}\\\\\n&\\leq \\frac{\\theta(1 - \\theta) (2n + a + b)}{n^2}\n\\end{aligned}\n\\]\nIn words, if our prior guess \\(a / (a+b)\\) is “close enough” to \\(\\theta\\), where “close enough” is defined by the inequality above and is proportional to the variance of the estimator, then the MSE of the Bayesian estimator is smaller.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#exercise",
    "href": "slides/lab-normal-and-estimators.html#exercise",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise",
    "text": "Exercise\nLibraries used:\n\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#data",
    "href": "slides/lab-normal-and-estimators.html#data",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Data",
    "text": "Data\n\nbass = read_csv(\"https://sta360-sp25.github.io/data/bass.csv\")\n\n\nglimpse(bass)\n\nRows: 171\nColumns: 5\n$ river   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ station &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ length  &lt;dbl&gt; 47.0, 48.7, 55.7, 45.2, 44.7, 43.8, 38.5, 45.8, 44.0, 40.4, 47…\n$ weight  &lt;dbl&gt; 1.616, 1.862, 2.855, 1.199, 1.320, 1.225, 0.870, 1.455, 1.220,…\n$ mercury &lt;dbl&gt; 1.60, 1.50, 1.70, 0.73, 0.56, 0.51, 0.48, 0.95, 1.40, 0.50, 0.…\n\n\nMercury, is a naturally occurring element that can have toxic effects on the nervous, digestive and immune systems of humans. Bass from the Waccamaw and Lumber Rivers (NC) were caught randomly, weighed, and measured. In addition, a filet from each fish caught was sent to the lab so that the tissue concentration of mercury could be determined for each fish. Each fish caught corresponds to a single row of the data frame. Today we will examine two columns from the data set: mercury (concentration of mercury in ppm) and weight (weight of the fish in kg). We’ll model the mercury content \\(y\\) of each fish as a function of the fish’s weight \\(x\\)."
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#model",
    "href": "slides/lab-normal-and-estimators.html#model",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Model",
    "text": "Model\nLet\n\\[\n\\begin{aligned}\nY_i | \\theta &\\sim \\text{ iid  } N(\\theta x_i, 1)\\\\\n\\theta &\\sim N(\\mu_0, 1 / \\kappa_0)\n\\end{aligned}\n\\]\nLet \\(\\mu_0 = 0\\), \\(\\kappa_0 = 1\\).\n(a). Suppose you observe data \\(y_1,\\ldots y_n\\). Write out the formula for \\(p(\\theta | y_1, \\ldots y_n)\\).\n(b). Given the data on the previous slide, use Monte Carlo simulation to plot \\(p(\\theta | y_1, \\ldots, y_n)\\). Additionally, report \\(E[\\theta | y_1,\\ldots y_n]\\) together with a 95% posterior confidence interval.\n(c). If you caught a new fish with weight 4kg, what would you predict the mercury content to be? In other words, let x = 4 and compute \\(E[\\tilde{y}|y_1,\\ldots, y_n, x = 4]\\). Additionally, plot the the posterior predictive density \\(p(\\tilde{y} | y_1, \\ldots y_n, x = 4)\\).\n(d). Critique your model. Hint: compare to the models below:\n\nlm(mercury ~ weight, data = bass)\nlm(mercury ~ 0 + weight, data = bass)"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-a",
    "href": "slides/lab-normal-and-estimators.html#solution-a",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (a)",
    "text": "Solution (a)\na\n\\[\n\\theta |  y_1, \\ldots y_n \\sim N(\\mu_n, \\tau_n^2)\n\\] \nwhere\n\n\n\n\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0 \\mu_0 + \\sum y_i x_i}{\\kappa_0 + \\sum x_i^2}\\\\\n\\tau_n^2 &= \\frac{1}{\\kappa_0 + \\sum x_i^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-b",
    "href": "slides/lab-normal-and-estimators.html#solution-b",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (b)",
    "text": "Solution (b)\nb\n\ndemodemo plotsolution codesolution plotsummary\n\n\nDemo with simulated data to make sure code works:\n\n# simulated data\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\nN = 10\nx = seq(from = 1, to = 10, length = N)\ny = rnorm(N, true.theta * x, true.sigma)\n\n# prior parameters\nk0 = 1\nmu0 = 0\n\nsumYX = sum(y * x)\nd = (k0 + sum(x^2))\nmun = ((k0 * mu0) + sumYX) / d\ntn = sqrt(1 / d)\n\ntheta.postsample = rnorm(10000, mun, tn)\nhist(theta.postsample)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = bass$weight\ny = bass$mercury\n\n# prior parameters\nk0 = 1\nmu0 = 0\n\nsumYX = sum(y * x)\nd = (k0 + sum(x^2))\nmun = ((k0 * mu0) + sumYX) / d\ntn = sqrt(1 / d)\n\ntheta.postsample = rnorm(10000, mun, tn)\nhist(theta.postsample)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean(theta.postsample)\n\n[1] 0.8314533\n\nquantile(theta.postsample, c(0.025, 0.975))\n\n     2.5%     97.5% \n0.7284780 0.9356104"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-c",
    "href": "slides/lab-normal-and-estimators.html#solution-c",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (c)",
    "text": "Solution (c)\n\n# use posterior samples of theta and x = 4 to simulate ytilde\n\nytilde = rnorm(10000, theta.postsample * 4, 1)\nhist(ytilde)\n\nmean(ytilde)\n\n[1] 3.319342\n\n\nThis matches intuition (law of total expectation gives the closed form solution: 4 * 0.838 = 3.352)."
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-d",
    "href": "slides/lab-normal-and-estimators.html#solution-d",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution (d)",
    "text": "Solution (d)\nWe have no intercept term. We are assuming that our regression line goes through the origin. This is a strong assumption. Our model will be most similar to the lm model without an intercept term:\n\nlm(mercury ~ 0 + weight, data = bass)\n\n\nCall:\nlm(formula = mercury ~ 0 + weight, data = bass)\n\nCoefficients:\nweight  \n0.8343  \n\n\nHowever, we’ll get a different estimate of \\(\\hat{\\theta}\\) if we include an intercept term,\n\nlm(mercury ~ weight, data = bass)\n\n\nCall:\nlm(formula = mercury ~ weight, data = bass)\n\nCoefficients:\n(Intercept)       weight  \n     0.6387       0.4818"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#exercises",
    "href": "slides/lab-normal-and-estimators.html#exercises",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#exercise-1-estimators",
    "href": "slides/lab-normal-and-estimators.html#exercise-1-estimators",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise 1: estimators",
    "text": "Exercise 1: estimators\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\)."
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#exercise-2-estimators",
    "href": "slides/lab-normal-and-estimators.html#exercise-2-estimators",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Exercise 2: estimators",
    "text": "Exercise 2: estimators\n\\[\n\\begin{aligned}\nY_1, \\ldots, Y_n &\\sim \\text{ i.i.d. binary}(\\theta)\\\\\n\\theta &\\sim \\text{beta}(a, b)\n\\end{aligned}\n\\]\n\nCompute \\(\\hat{\\theta}_{MLE}\\)\nCompute \\(\\hat{\\theta}_{B} = E[\\theta | y_1,\\ldots y_n]\\).\nCompare \\(MSE(\\hat{\\theta}_{MLE})\\) to \\(MSE(\\hat{\\theta}_{B})\\)). Under what conditions is the MSE of \\(\\hat{\\theta}_B\\) smaller?"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-1",
    "href": "slides/lab-normal-and-estimators.html#solution-1",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution 1",
    "text": "Solution 1\nLet \\(\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\).\n\\[\n\\begin{aligned}\nBias(\\hat{\\sigma}^2 | \\sigma^2 = \\sigma_0^2) &= E[\\hat{\\sigma}^2|\\sigma_0^2] - \\sigma_0^2\\\\\n&=  - \\sigma_0^2 + \\frac{1}{n} \\sum_{i = 1}^n E[(Y_i -\\bar{Y})^2|\\sigma_0^2]\\\\\n&= - \\sigma_0^2 + \\frac{1}{n} \\sum_{i=1}^n \\left[\nE[Y_i^2 |\\sigma_0^2] - 2E[Y_i \\bar{Y}|\\sigma_0^2] + E[\\bar{Y}^2 | \\sigma_0^2]\n\\right]\n\\end{aligned}\n\\]\nRecall that for any random variable X, \\(Var(X) = E[X^2] - E[X]^2\\). Using this fact, we continue our proof above:\n\\[\n\\begin{aligned}\n&= -\\sigma_0^2 +(\\sigma_0^2  + \\theta^2)\n-2 \\frac{1}{n} \\sum_{i=1}^n \\left[  E~\\left(Y_i \\frac{1}{n}\\sum_j Y_j\\right) | \\sigma_0^2    \\right]\n+ \\left(\\frac{\\sigma_0^2}{n} + \\theta^2\\right)\\\\\n&= 2\\theta^2 + \\frac{\\sigma_0^2}{n} - \\frac{2}{n}\n\\left(n\\theta^2  - \\sigma_0^2\n\\right)\\\\\n&= \\frac{(n-1)\\sigma_0^2}{n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab-normal-and-estimators.html#solution-2",
    "href": "slides/lab-normal-and-estimators.html#solution-2",
    "title": "Normal modeling &\nBayesian estimators",
    "section": "Solution 2",
    "text": "Solution 2\n\\[\n\\begin{aligned}\n\\hat{\\theta}_{MLE} &= \\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i\\\\\n\\hat{\\theta}_B &= \\frac{n\\bar{y}+a}{n+a+b} =\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}_{MLE}|\\theta) &= \\frac{\\theta(1-\\theta)}{n}\\\\\nMSE(\\hat{\\theta}_B|\\theta) &= \\frac{n}{n + a + b}\\bar{Y} + \\frac{a + b}{n + a + b} \\frac{a}{a + b} =  w \\bar{Y} + (1-w)\\frac{a}{a+b}\\\\\n&= w^2Var(\\bar{Y} | \\theta) +  (1-w)^2 \\left(\\frac{a}{a+b} - \\theta\\right)^2\\\\\n&= {w^2} \\frac{\\theta(1-\\theta)}{n} + (1-w)^2  \\left(\\frac{a}{a+b} - \\theta\\right)^2\n\\end{aligned}\n\\] For the Bayesian estimator to have smaller MSE than the MLE, we need\n\\[\n\\begin{aligned}\n\\left(\\frac{a}{a+b} - \\theta\\right)^2 &\\leq \\frac{\\theta(1 - \\theta)}{n} \\frac{1 + w}{1 - w}\\\\\n&\\leq \\frac{\\theta(1 - \\theta) (2n + a + b)}{n(a+b)}\n\\end{aligned}\n\\]\nIn words, if our prior guess \\(a / (a+b)\\) is “close enough” to \\(\\theta\\), where “close enough” is defined by the inequality above and is proportional to the variance of the estimator, then the MSE of the Bayesian estimator is smaller.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "slides/jeffreys-prior-lab.html#exercise",
    "href": "slides/jeffreys-prior-lab.html#exercise",
    "title": "Jeffreys prior",
    "section": "Exercise",
    "text": "Exercise\nShow that the Jeffreys prior for the normal model is \\(p_J(\\theta, \\sigma^2) \\propto (\\sigma^2)^{-3/2}\\).\nNote: our sampling model has two unknowns. Let \\(\\Psi = (\\theta, \\sigma^2)\\). Then \\(p_J(\\Psi) \\propto \\sqrt{|I(\\Psi)|}\\) where \\(|I(\\Psi)|\\) is the determinant of the \\(2 \\times 2\\) Hessian matrix."
  },
  {
    "objectID": "slides/jeffreys-prior-lab.html#solution",
    "href": "slides/jeffreys-prior-lab.html#solution",
    "title": "Jeffreys prior",
    "section": "Solution",
    "text": "Solution\nIn lab."
  },
  {
    "objectID": "slides/jeffreys-prior-lab.html#exam-prep",
    "href": "slides/jeffreys-prior-lab.html#exam-prep",
    "title": "Jeffreys prior",
    "section": "Exam prep",
    "text": "Exam prep\nReview chapter summaries.\n\n\n\n🔗 sta602-sp25.github.io"
  },
  {
    "objectID": "notes/lec11-mvn.html#key-facts",
    "href": "notes/lec11-mvn.html#key-facts",
    "title": "Multivariate normal",
    "section": "Key facts",
    "text": "Key facts\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma &gt; 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] =  \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\nsampling from a mvt norm\nlibrary(mvtnorm) contains functions we need.\n\nrmvnorm() to sample from a multivariate normal\ndmvnorm() to compute the density\npmvnorm() to compute the distribution function\nqmvnorm() to compute quantiles of the multivariate normal"
  },
  {
    "objectID": "slides/mcmc-transform.html#exercise-1",
    "href": "slides/mcmc-transform.html#exercise-1",
    "title": "MCMC and parameter transformations",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nglimpse(df)\n\nRows: 31\nColumns: 2\n$ group &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3…\n$ y     &lt;dbl&gt; -1.32196275, -0.06394777, -1.01787434, -0.84159001, -0.75015035,…\n\ndf %&gt;%\n  count(group)\n\n  group  n\n1     1 10\n2     2  8\n3     3 13"
  },
  {
    "objectID": "slides/mcmc-transform.html",
    "href": "slides/mcmc-transform.html",
    "title": "MCMC and parameter transformations",
    "section": "",
    "text": "# S = 100\n# MU0\n# TAU\n# SIGMA2\n# SIGMA02\n# for (s in 1:S) {\n#   \n# }"
  }
]